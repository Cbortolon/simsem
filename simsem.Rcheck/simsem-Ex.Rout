
R version 2.15.0 (2012-03-30)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: i386-pc-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "simsem"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> options(pager = "console")
> library('simsem')
Loading required package: lavaan
This is lavaan 0.4-14
lavaan is BETA software! Please report any bugs.
Loading required package: MASS
 
###############################################################################################
This is simsem 0.2-0
simsem is BETA software! Please report any bugs.
simsem was developed at the University of Kansas Center for Research Methods and Data Analysis.
###############################################################################################
> 
> assign(".oldSearch", search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("MatrixSet-class")
> ### * MatrixSet-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MatrixSet-class
> ### Title: Class '"MatrixSet"'
> ### Aliases: MatrixSet-class MisspecSet-class summary,MatrixSet-method
> ###   summary,MisspecSet-method
> 
> ### ** Examples
> 
> showClass("SimSet")
Class "SimSet" [package "simsem"]

Slots:
                                                                            
Name:  modelType        LY        TE       RTE       VTE        PS       RPS
Class: character SimMatrix SymMatrix SymMatrix SimVector SymMatrix SymMatrix
                                                                            
Name:        VPS        BE        TY        AL        ME        MY        VE
Class: SimVector SimMatrix SimVector SimVector SimVector SimVector SimVector
                                                                            
Name:         VY        LX        TD       RTD       VTD        PH       RPH
Class: SimVector SimMatrix SymMatrix SymMatrix SimVector SymMatrix SymMatrix
                                                                            
Name:        VPH        GA        TX        KA        MX        VX        TH
Class: SimVector SimMatrix SimVector SimVector SimVector SimVector SimMatrix
                
Name:        RTH
Class: SimMatrix

Known Subclasses: 
Class "NullSimSet", directly
Class "SimMisspec", directly
Class "NullSimMisspec", by class "SimMisspec", distance 2
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LX = LX, RPH = RPH, RTD = RTD)
> MatrixSet <- run(CFA.Model)
> summary(MatrixSet)
RANDOM NUMBERS OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1] [,2]
[1,]  0.7  0.0
[2,]  0.7  0.0
[3,]  0.7  0.0
[4,]  0.0  0.7
[5,]  0.0  0.7
[6,]  0.0  0.7

TE: Covariance of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.51 0.00 0.00 0.00 0.00 0.00
[2,] 0.00 0.51 0.00 0.00 0.00 0.00
[3,] 0.00 0.00 0.51 0.00 0.00 0.00
[4,] 0.00 0.00 0.00 0.51 0.00 0.00
[5,] 0.00 0.00 0.00 0.00 0.51 0.00
[6,] 0.00 0.00 0.00 0.00 0.00 0.51

VTE: Variance of Measurement.Error.EPSILON 
[1] 0.51 0.51 0.51 0.51 0.51 0.51

RTE: Correlation of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    0    0    0    0    0
[2,]    0    1    0    0    0    0
[3,]    0    0    1    0    0    0
[4,]    0    0    0    1    0    0
[5,]    0    0    0    0    1    0
[6,]    0    0    0    0    0    1

VY: Variance of Indicator.Y 
[1] 1 1 1 1 1 1

TY: Measurement Intercept of Indicator.Y 
[1] 0 0 0 0 0 0

MY: mean of Indicator.Y 
[1] 0 0 0 0 0 0

PS: Covariance of Regression.Residual.PSI 
     [,1] [,2]
[1,]  1.0  0.5
[2,]  0.5  1.0

VPS: Variance of Regression.Residual.PSI 
[1] 1 1

RPS: Correlation of Regression.Residual.PSI 
     [,1] [,2]
[1,]  1.0  0.5
[2,]  0.5  1.0

VE: Variance of Factor.ETA 
[1] 1 1

AL: Regression Intercept of Factor.ETA 
[1] 0 0

ME: mean of Factor.ETA 
[1] 0 0
------------------------------------------------- 
> 
> 
> 
> cleanEx()
> nameEx("Null-class")
> ### * Null-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Nullclass
> ### Title: Null Objects
> ### Aliases: NullDataFrame-class NullVector-class NullMatrix-class
> ###   NullSimMatrix-class NullSymMatrix-class NullSimVector-class
> ###   NullSimSet-class NullSimEqualCon-class NullSimREqualCon-class
> ###   NullRSet-class NullSimMisspec-class NullSimDataDist-class
> ###   NullSimMissing-class NullSimFunction-class
> ### Keywords: classes
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("SimData-class")
> ### * SimData-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimData-class
> ### Title: Class '"SimData"'
> ### Aliases: SimData-class run,SimData-method summary,SimData-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimData")
Class "SimData" [package "simsem"]

Slots:
                                                                              
Name:    modelType           n       param     misspec    equalCon     maxDraw
Class:   character     numeric      SimSet  SimMisspec SimEqualCon     numeric
                                                                              
Name:   sequential     facDist   errorDist     indDist      indLab   modelBoot
Class:     logical SimDataDist SimDataDist SimDataDist      vector     logical
                  
Name:     realData
Class:  data.frame
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 200)
> summary(SimData)
DATA OBJECT
Model Type
[1] "CFA"
Sample Size
[1] 200
========= Parameters Set ============
SET OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]     [,2]    
[1,] "NA:0.7" "0"     
[2,] "NA:0.7" "0"     
[3,] "NA:0.7" "0"     
[4,] "0"      "NA:0.7"
[5,] "0"      "NA:0.7"
[6,] "0"      "NA:0.7"

RTE: Correlation of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] "1"  "0"  "0"  "0"  "0"  "0" 
[2,] "0"  "1"  "0"  "0"  "0"  "0" 
[3,] "0"  "0"  "1"  "0"  "0"  "0" 
[4,] "0"  "0"  "0"  "1"  "0"  "0" 
[5,] "0"  "0"  "0"  "0"  "1"  "0" 
[6,] "0"  "0"  "0"  "0"  "0"  "1" 

VY: Variance of Indicator.Y 
[1] "NA:1" "NA:1" "NA:1" "NA:1" "NA:1" "NA:1"

TY: Measurement Intercept of Indicator.Y 
[1] "NA:0" "NA:0" "NA:0" "NA:0" "NA:0" "NA:0"

VPS: Variance of Regression.Residual.PSI 
[1] "1" "1"

RPS: Correlation of Regression.Residual.PSI 
     [,1]     [,2]    
[1,] "1"      "NA:0.5"
[2,] "NA:0.5" "1"     

VE: Variance of Factor.ETA 
[1] "1" "1"

AL: Regression Intercept of Factor.ETA 
[1] "0" "0"

ME: mean of Factor.ETA 
[1] "0" "0"
-------------------------- 
Number of free parameters =  19 
=====================================
Adding Misspecification?
[1] "No"
Adding Constraint?
[1] "No"
Maximum Random Sampling Parameters
[1] 100
> run(SimData)
               y1          y2           y3           y4           y5
1   -0.8045405678 -1.07615375  0.057008974 -0.902462922 -0.420303205
2    0.1846928903 -1.52519893 -0.596848908 -0.360271862  0.655075424
3   -0.9818489653 -1.00020156 -1.872460732  0.547424678  0.455643551
4    1.5595324860  0.98242927  1.129591494  1.133175506  0.771936669
5    1.1845695532  1.29080775  1.312506730 -0.614798923 -1.246842377
6   -2.4256570718 -0.52391592 -2.119384992  0.801634881  0.447980202
7   -0.8026409861 -0.01211317  0.886817943  0.874982013  0.264254397
8    0.0563541774  1.26607638 -0.572218116  0.960753031  1.193425123
9    1.4677564715  0.51392041 -0.801413687 -0.485506296  1.285396956
10  -0.2799641994 -0.93132978 -0.102089434  0.318816637 -1.065786453
11   1.1792430190  1.32162096  0.774606605  1.177173143  0.997041766
12   0.2512034453  0.06410751 -0.103496897  0.112998515  1.030275697
13  -0.5563709849  0.67445625 -0.824812638 -1.216554530  0.178167961
14  -1.7843904375  0.36259070 -1.175083029 -1.812722455 -3.445337824
15   1.8844962672 -0.52205666 -0.442225197  1.403045471  0.909652448
16  -0.9452810102 -0.62387834 -0.598349054  0.507410773  1.772555524
17  -0.0831099570  0.47046975  0.001881615 -0.684020271  0.600954470
18   0.0667599058  2.43207667  1.118568015  0.128168047 -0.759673520
19   0.0624300206  0.98647272 -0.269307069  1.547295847 -0.375973318
20   0.3418543450 -0.62490267  1.542665030 -0.535117264  1.106608185
21   1.1985632899  1.64210058  1.382428213 -1.009453441  0.262620519
22  -0.4294336414  0.51578927  1.489116211  1.073752569  0.686141945
23   1.4200746408 -0.52870595  0.120453095 -0.224536426 -0.155962968
24  -0.0705158002 -2.01187265 -1.466254278 -0.516334770 -2.101005185
25   1.3465994213  0.60673251  0.878034808 -0.444133582  0.161716811
26  -1.6017729664  0.05337596 -1.028983927 -0.120399156  1.479385138
27   0.4261412395  0.47207405 -0.760103948  0.564006789 -1.367508121
28  -0.2861057055 -0.70022762  0.212329374 -1.088102173 -0.935558478
29  -0.6774881190  0.42716566 -0.984082865  0.031142318 -1.051034032
30   0.9965878126 -0.44682030 -0.065989857  0.757599491  0.133966644
31   0.6690459148  1.98420225  1.435822722  1.633619512 -0.474452981
32   0.9584993506  1.49351309  1.288455423 -1.539705118 -0.355642036
33   0.1559852255  1.10912317  0.392489723  0.935602005 -0.058764218
34  -0.3086738117 -0.15275306 -0.426789831  0.194940236 -0.036323861
35  -1.7789568229 -0.98729507  0.068901395 -1.217656769 -0.696235716
36  -0.5865292974 -0.35461815  0.237837966 -0.099006066  0.126147956
37  -0.0900499230 -0.68642407 -0.785618330 -0.397217992  1.353802246
38   0.8217290574 -0.08617487  0.766121687 -0.546177050 -0.488701706
39  -0.2473621503 -0.33824834  1.306692499  1.598719049  0.448719261
40   0.7983910651  0.42456011  0.324473731  0.051228612  0.280284611
41  -1.7603689925 -0.17502680  0.636793969  0.686794776  0.965569964
42  -0.9235552750 -0.61617026 -0.384744863 -0.851671459 -0.058583975
43   0.8035345795  0.56088663 -0.263319249  0.754475137  2.033251767
44   0.3159403170  1.43200531  0.576236087 -0.529733049  0.192023403
45  -0.9343279406 -1.97436664 -0.070511142 -0.052742647 -0.164001262
46  -0.3556720991  0.37385555  1.287415951  0.427171005 -2.407145230
47   1.0826342292 -0.14211513  0.539715172  0.835172718 -0.077930462
48  -0.4128817647  0.99913523  1.314070137  0.728565750  0.382448273
49  -0.2157477195 -0.08399579  0.300039152 -0.405477056 -1.002169861
50   0.0619598370  0.10797140  0.213652275  2.446380196  0.397848746
51   0.2265662511  0.14138723  0.249285474 -0.196041332  0.872641544
52  -1.0308668478 -0.53998194 -0.220668169  0.198722579 -0.142478281
53   1.2684252196  0.39667291 -0.881515883  0.486765092 -0.492598325
54  -1.3671094745 -1.43683369  0.863288621 -0.054377978 -2.633850400
55   0.8681587718  0.18662850  0.886601631  2.102684710  0.585945042
56  -0.9306844795  1.71026113  1.650561104  1.847472340  1.439959863
57   0.8775331332  0.24194873  1.423436446 -1.670377316 -1.577584671
58  -0.6623350406 -0.70034460 -1.527115423  0.678702769 -1.585447109
59  -0.3114747365 -0.39640737  1.345515884  1.168227022 -0.064305301
60   0.4693003554  0.14868310 -0.309373532 -0.644550315 -0.222430918
61   1.2892242893  2.28783246 -0.030108233  2.319081697  2.371326500
62   0.7473376784 -0.86750928  0.572901489 -1.397225560  0.947577450
63   0.1075219190  0.23528599  1.437672545 -0.395683617  0.343749379
64  -0.9973491594  0.28584536 -0.403692843  0.063307132  0.507613256
65  -2.3728066858 -0.12220489 -1.354928719  0.340955897  0.515665189
66  -0.2500954183  0.98076769 -0.718728765  0.167447035  1.083731310
67  -1.7929149185 -0.54390514 -0.728723259 -0.963357244 -1.668881689
68   1.7769347604  2.40088430  0.404735210 -0.086789607 -0.039117880
69   0.2179779459  0.64516450 -0.101492435 -0.901905282  0.614526647
70   3.1339534228  1.26386491  1.270944654  0.330862280  1.352746038
71  -0.1259520428  0.19267403  1.246725188  0.845079971  0.699984832
72   0.0405485247 -0.52290120 -1.489294968  0.610526395 -0.661020996
73   0.4754008366  1.02404482  0.897144876  0.058166975 -0.300577340
74  -2.6895868084 -1.59264220 -1.223079580  0.344187484  0.512318372
75  -0.5459615881 -1.94432565 -0.252799729 -1.579852478 -0.616204573
76  -1.1562860290  0.53758634 -0.337650835  1.517225228  0.379865088
77   0.0461554357  1.83816492  0.349334111 -1.529994006 -1.058638868
78  -0.8395362886  0.77015046 -0.941009799  0.261897908  0.930996729
79   0.7735181418  0.28267314  0.892567365 -1.215600937 -0.010304868
80  -1.4055208647 -0.52048203 -0.520647633  0.044516709 -0.157260934
81   0.0877875454 -1.18856748 -0.590889118 -0.082663679 -0.797156263
82  -0.5602149639  0.44049776  0.403835171  0.466589138 -0.377065078
83   0.3477175853 -0.06490563  0.284933429  1.689456383  1.168282918
84  -0.5967279049 -0.86522915 -0.654388508 -1.123550593 -1.395703886
85   0.0067799214  0.84708257  1.138194028 -1.112129607  1.463993425
86   0.3721907535  1.01516030  0.652587552 -1.520379797  1.463838250
87   0.6847116122  0.56301423  1.810765506  0.481769335 -0.151947621
88  -0.0312676297 -0.72967448 -1.144571021  0.905538519  0.648209062
89   1.0223588579 -0.62933490 -0.238992060  1.486648564 -0.672133513
90  -0.8816612780 -0.12459415  0.171656989  0.394706171  0.930677659
91   0.4776656414 -1.35812046  0.318748265  0.100394651 -0.901169766
92   0.5619667249  0.28464579  1.076582903 -0.342022673  1.617624464
93  -0.4304015712  1.27001996  1.168457444  1.558340293  1.243160740
94   0.6634143823  1.34224632  1.356474398 -0.264195189 -0.447691467
95   0.4262455962  0.15540357  0.190310662 -0.295421796  3.519532872
96   0.3247077982  1.38678797 -0.768177285  1.039855697  0.143230420
97  -2.5688579778 -1.45764532  0.404043730 -0.647108311 -0.921581685
98  -0.3711483431 -1.57481049 -0.516172155  0.770821178  0.179842312
99  -0.5181913491 -0.46087164 -1.423157350 -1.225169114 -1.659354417
100 -0.3241931735 -0.27499555  0.061762260  0.026207235 -1.025488759
101 -1.2608123820 -0.70465244 -0.507725421 -0.134951402 -0.713208467
102  1.6045847696  0.60919145 -0.697583513 -0.344886746 -0.403963584
103 -1.4485685714 -2.27845518 -0.805216609  1.013183871 -0.074574886
104  0.2339305241  0.46845124  0.140785418 -0.155752781 -0.573181480
105 -1.8487178826 -1.05105968 -0.681699931 -0.175699031  0.950311805
106 -0.3282497066  0.65716891  1.171006577  0.934752511  1.930606581
107 -0.4343939862  1.31928628  0.448076578  1.392597949  0.391587472
108  0.0674125565  1.01929513 -0.025080675  1.028205339  0.944496848
109  1.4957467584  0.37478111  0.304887067 -0.873472484  0.533807642
110  2.0396040925  0.30108835  0.612602853  1.809915796  0.430701475
111  0.0836251337 -1.31710167 -1.475631644  1.465978243 -0.789000308
112  0.4471490248 -1.01867806 -0.495487362  0.212428221 -0.837182507
113  1.0422762097  1.12828005  1.340459378  1.226758030 -0.279993309
114 -0.8191229322 -0.13248823  0.534646102 -0.705367653 -0.677337795
115 -0.3305742687  0.61397339 -0.652812183  0.189087390  0.593848304
116 -2.1377059370 -0.48465132  0.368575054  0.132528125 -0.035314889
117 -0.2090894150  0.51027631 -0.285563244 -0.207521468 -0.639311014
118  0.8119503946 -0.33094260 -0.878902424 -0.472169073  0.233768693
119  1.0037904106  0.94540176  0.816627915 -0.048920330 -0.362574437
120  0.2201993071  0.15363391 -1.407204502 -0.508200123  1.504739911
121 -0.6192998951 -1.03481872 -1.154258093  0.715174505  0.347166193
122 -0.2059414972  0.53231605  0.338132464  1.596363103  2.785334795
123  0.4925457037 -0.57747645 -1.461444127  0.694848527  0.118499613
124  0.6252206657  1.09499760  0.472616815 -1.177192123 -1.401456154
125 -0.7788719599 -0.72244028  0.640398289  0.259634607  0.270596332
126  0.2753483074  0.97121188 -0.431707474  1.574931372 -0.270360531
127 -0.7992852453  0.64738850  0.486385041 -0.151085350 -0.722390099
128  0.2360446187  0.98780741 -1.532784374 -0.708819152  0.493995339
129  0.1946726104  0.11794660 -0.507478459 -1.207877217 -0.147378071
130 -0.7543560973 -0.19358829 -0.634660190  0.036005974  0.323987148
131  0.0364199431 -0.53394647  1.065937731  0.676364897 -0.219239440
132  0.8016260454  0.54404162 -0.389829562 -1.768305517 -0.230229594
133 -0.1410602527  1.25318139  0.462606717  0.153329550  0.176545122
134 -2.3269769264 -0.54785558 -2.053942030 -0.294801011 -1.610932747
135  0.5857480462  0.11162428  0.378092033 -0.850793701  0.988828103
136 -1.4985027092 -1.96261898 -0.640851643 -0.072579774 -0.014489374
137 -0.1646307300 -0.23488959 -1.501433465  0.009095024  0.420191131
138 -0.5618487081 -0.02751099 -0.482743297 -1.187932677 -0.517261379
139  0.4574846794 -1.27755036 -0.014418680 -0.990067363 -0.621959638
140  0.4427581879  0.48773647 -0.321451474 -0.193359071 -0.787832290
141 -2.8811023589 -1.42864914 -0.564206074 -0.628869108 -1.153407685
142  0.5270371745  1.36502363  1.935619345  0.197721738  0.723895619
143 -0.5481022617 -0.90491534 -2.243432508 -1.306192600 -0.361475697
144  0.2865956512 -1.00185782  0.175457323 -0.441685344 -0.383632346
145 -0.2988841089  0.13693426  1.005093026 -2.565371307 -1.796977620
146 -0.6471168107  0.68646757  0.370749527 -1.016599170 -0.771521601
147  1.5920708177  1.14827500  0.219847298  2.271895307  2.249293223
148 -0.3537815508  0.39353090  0.256750895 -0.209955942  1.175782254
149 -0.0951342086 -2.06625826 -1.532156850  0.693221919 -1.530572183
150 -0.9645588686 -2.12716027 -2.798450984 -0.503440256  0.143875513
151 -1.2920054024  0.91615740 -0.729809290  0.787663374  1.787693060
152 -0.8148269475 -0.03079735 -0.117361701  0.443020711  0.168357382
153 -1.0294529925 -0.50403937  0.372372788  0.693288619 -0.225272356
154 -0.1924206082 -0.09913424 -1.320466904 -0.509336732 -0.694754938
155 -2.5265702502 -1.27944370 -1.352037582 -1.148718189  0.204044661
156 -2.2110491362  0.14570621 -0.919234698  0.036490939 -0.579347648
157  2.4735564571  0.61652626  0.531788231  1.488814554 -0.226698058
158  0.2162123854 -0.54914264 -0.708117382 -0.964431035 -0.007118478
159  0.4181098432 -0.21523175 -0.374396776 -1.574864931 -2.193600951
160  0.8921263490  1.94720865  1.199808905  1.320595024 -0.023451999
161  1.4403901104  1.88825753  1.071807815 -0.258173610 -1.654814358
162 -0.3559374303 -1.36924575 -0.552086500  0.443121082  0.381188528
163  0.1852145141  1.37703245  1.442328834 -0.113670391 -0.510448063
164  0.7791536668  0.81928588  0.777994066  0.893991156  1.232566848
165 -0.4164688586  1.38355608 -1.985362180 -0.301342496 -1.245670312
166  2.0643736589  1.50892036  0.042081009  0.974514474  1.669113883
167 -0.0288257864 -1.10816814 -0.304657714  0.372368640  0.694684849
168 -0.5407691203 -1.21291136 -1.897155155 -0.806299057 -1.751715398
169  0.2195516909  0.73376002 -0.462299695  0.031618946 -0.174979246
170  0.0600798631  1.27659313  0.945174591 -0.996394346 -0.309409682
171  1.5526031710  1.99516318  1.641048935  1.986685756  1.257980323
172 -1.0491658530  0.57119059  0.311701320 -0.186224123  0.922032974
173  1.2005481525  0.23320060  0.613288649 -0.621743377 -0.253861583
174  0.8738445025 -1.13335374  0.197886868  0.115849461 -0.643024436
175  0.2261905333 -0.05979957  0.755267281 -1.436909836 -1.901562877
176 -0.5761764146 -0.39440018  0.911852765 -0.612949986 -0.191230765
177  1.0775405715  0.35572783 -0.019866615  0.242001452  0.983951606
178  1.5401987455  0.94737101  1.899713702  0.202911743  2.230571411
179  0.5955688479  1.29250324  0.409245640  1.887993553  0.920794012
180  0.6880648895 -0.19001521 -0.470446371  2.255087920  1.249070024
181 -1.4568256022 -2.15306330  0.082900476  0.404880890 -0.849702160
182  0.8180751554 -0.12494065 -0.226433199  1.039108508  1.264534294
183  0.0085438960  0.95015610  0.746740187 -1.199500750  0.065679066
184 -0.8940668214 -0.89639078 -1.395100746 -1.851574470  0.049340769
185  0.3770063973 -0.82598548 -0.077718026  0.609599278  1.228258471
186 -0.7713336559 -0.87279879  1.400998933 -0.555717355  0.131552517
187  2.1916399164  1.67997412  1.993896837  0.036039639 -0.433074625
188 -0.7644027282 -0.50832439 -0.744513922 -0.632456117 -0.201423058
189  1.0818416884 -0.71917476  1.372392496 -1.310306184 -0.758836981
190 -0.7123867784  0.32291498 -0.370940781 -0.492459708 -0.908119073
191 -0.7189526528 -1.27177778 -0.176011101  0.640347511  0.103736091
192  0.7583885763 -0.09557949 -0.692839578  0.531354179  0.215634518
193 -0.9704287286 -0.52589547 -1.472212149 -0.786149409  0.777841368
194  1.0111685017 -0.46876166  0.714326936  1.362278118  0.769143961
195 -0.9182525115  0.24633169 -1.615503809  0.346701771 -1.458981555
196 -0.9252375184  0.14194143 -0.068448638 -1.563162896 -0.991772639
197  0.2406860576  0.28524346  0.205569334  2.106344888  1.000259344
198 -1.4337577825 -0.14697860 -0.530798010 -0.407106864 -0.991733735
199 -1.0447500775  2.16919283  0.684209652 -0.615469883 -0.351618750
200  0.0003911315 -0.56261685 -1.389186009  0.482855829 -0.419598035
               y6
1    0.6180292594
2    2.3837518591
3   -0.5212269270
4    0.8620270188
5   -0.5963206302
6    0.5078609421
7    0.7560059736
8    0.0755523079
9    0.3437498957
10   0.8277790695
11   0.6519951487
12   0.2183530296
13  -0.7622672194
14  -1.0837788485
15   1.3074069668
16  -0.2938138623
17  -0.3715209234
18   0.8235061437
19   1.3636021679
20   0.5659299001
21   0.2328136550
22  -0.1785960274
23  -0.3303716169
24  -1.8632142568
25  -0.0472791943
26   0.9918544612
27   0.0365857421
28  -3.1384202905
29   0.3244417113
30   0.3115047955
31   0.2355117511
32  -2.2599809462
33  -0.9697594710
34   0.5124384949
35  -0.9466894918
36  -0.9987866543
37  -0.9858805748
38  -0.7061911584
39   1.6712780213
40   1.2013057555
41  -1.0177945028
42   1.8121359903
43  -1.0758238986
44   0.2602691534
45   0.4160715843
46  -2.1811373349
47  -0.7659919354
48   0.0905282800
49   0.9539121615
50   0.3284151719
51   0.3129508912
52  -0.7349192375
53   0.5990398139
54   0.0706749722
55   1.1537899816
56   2.2754967491
57  -0.7770942330
58  -0.4176790163
59   0.5578826036
60   0.0132791538
61   1.4557820236
62  -0.1614578505
63   1.0553020077
64   0.6572954141
65  -0.0065962895
66  -0.5011396666
67  -1.5871881961
68   1.4584604520
69   0.1442724592
70   1.4164788765
71  -0.9393140531
72  -0.8432634726
73   0.3107646599
74   0.8787032268
75  -0.1206297159
76   0.2355626325
77  -1.4341862530
78  -0.1780377153
79  -0.4228047777
80   0.1800367947
81   0.2762923915
82  -0.9192347075
83   1.3293771747
84  -1.5136484447
85   0.0532982808
86  -0.6395803272
87   0.9024505935
88  -0.8759472927
89   0.5248812368
90   0.5872486206
91  -0.8271764917
92   1.6762625941
93  -0.1260907029
94   0.1758749166
95   2.4085273170
96   0.1276953164
97   0.0387120748
98  -0.8022817056
99   0.3441005526
100 -0.3739782644
101  0.8174960980
102 -0.5973590354
103 -0.0829278468
104  0.5235849919
105  0.1649040059
106  2.7676406794
107 -0.2244604105
108  0.6392133680
109 -0.2851444833
110  1.5954968076
111 -0.5337575235
112 -0.1714677143
113  1.3230356725
114 -0.8265967191
115 -1.2505294045
116  0.5711619042
117 -0.4603102987
118 -0.4902306235
119 -0.3597381126
120 -0.6788897951
121 -0.2960524307
122  0.3744169193
123 -0.1330344756
124 -0.3388926172
125 -0.0736955572
126  0.7569598115
127  0.2420747996
128  0.3718613643
129 -1.2011266096
130 -0.0861716439
131 -0.7827238749
132 -1.3341324966
133  0.2405624650
134  0.7061373572
135  0.0237955037
136 -2.0122030071
137  0.2569017365
138  0.6451132878
139 -0.1854000475
140  0.1425078194
141 -1.0702872302
142 -0.0005046481
143 -1.3558555533
144 -0.5057265862
145 -0.9847451137
146 -1.6523504906
147  0.9426045614
148 -1.1921163188
149 -0.6607215400
150 -0.3718921579
151  0.3472952580
152  0.2766987981
153 -0.5906483904
154 -0.9348732590
155  0.0992055180
156 -0.8121355435
157 -0.8477839774
158 -0.4948894153
159 -1.6476829367
160  2.2083330530
161 -0.7717252908
162  0.4897595541
163  1.8916725586
164 -0.9253124870
165  0.0659688199
166  2.6450185696
167 -0.6547131876
168  0.4594654416
169 -0.9304610979
170 -0.1384007199
171  0.8817207466
172 -0.1425073228
173  0.6730545945
174  0.2774013733
175  1.0687579388
176  0.7227473027
177  0.5396272999
178  1.5551032352
179 -0.9594598042
180  1.3434623849
181 -0.9979190227
182  1.2007442189
183  0.3160171841
184 -0.9341570305
185  0.7917325900
186  0.0265509200
187  0.4427262353
188 -0.2408535448
189 -1.4022884237
190 -1.5768673396
191  0.7078508957
192  0.9055963979
193  0.0234449447
194 -0.0366973321
195 -1.4762230728
196 -0.8230762289
197  1.9785351080
198 -0.5896739751
199  0.8212020981
200  0.3500977547
> 
> 
> 
> cleanEx()
> nameEx("SimDataDist-class")
> ### * SimDataDist-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimDataDist-class
> ### Title: Class '"SimDataDist"'
> ### Aliases: SimDataDist-class summary,SimDataDist-method
> ###   run,SimDataDist-method plotDist,SimDataDist-method
> ###   extract,SimDataDist-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimDataDist")
Class "SimDataDist" [package "simsem"]

Slots:
                                              
Name:          p      dist keepScale   reverse
Class:   numeric      list   logical    vector

Known Subclasses: "NullSimDataDist"
> 
> chisq3 <- simChisq(3)
> chisq8 <- simChisq(8)
> dist <- simDataDist(chisq3, chisq8)
> dist2 <- extract(dist, 2)
> 
> m <- c(0, 0)
> cm <- matrix(c(1, 0.5, 0.5, 1), 2, 2)
> n <- 20
> dat <- run(dist, n, m, cm)
Loading required package: pspline
> 
> plotDist(dist, r=0.2)
> 
> 
> 
> 
> cleanEx()

detaching 'package:copula', 'package:pspline'

> nameEx("SimDataOut-class")
> ### * SimDataOut-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimDataOut-class
> ### Title: Class '"SimDataOut"'
> ### Aliases: SimDataOut-class summary,SimDataOut-method
> ###   createImpliedMACS,SimDataOut-method
> ###   summaryPopulation,SimDataOut-method getPopulation,SimDataOut-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimDataOut")
Class "SimDataOut" [package "simsem"]

Slots:
                                                                              
Name:    modelType        data       param    paramOut  misspecOut    equalCon
Class:   character  data.frame    SimParam     SimRSet     SimRSet SimEqualCon
                  
Name:            n
Class:     numeric
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> Data <- run(SimData, dataOnly=FALSE)
> Result <- run(SimModel, Data)
> summary(Data)
DATA RESULT OBJECT
Model Type
[1] "CFA"
Sample Size
[1] 500
Data Summary       y1                  y2                 y3                  y4          
 Min.   :-2.828607   Min.   :-3.37032   Min.   :-2.475905   Min.   :-2.75821  
 1st Qu.:-0.625083   1st Qu.:-0.66606   1st Qu.:-0.716538   1st Qu.:-0.64799  
 Median :-0.018824   Median : 0.04373   Median :-0.077007   Median : 0.06414  
 Mean   : 0.002646   Mean   : 0.01874   Mean   :-0.009583   Mean   : 0.03211  
 3rd Qu.: 0.623182   3rd Qu.: 0.66428   3rd Qu.: 0.793210   3rd Qu.: 0.64480  
 Max.   : 3.523274   Max.   : 2.76574   Max.   : 3.186076   Max.   : 3.85754  
       y5                 y6          
 Min.   :-3.06740   Min.   :-2.64395  
 1st Qu.:-0.65420   1st Qu.:-0.63098  
 Median : 0.03630   Median :-0.01769  
 Mean   : 0.04269   Mean   : 0.01642  
 3rd Qu.: 0.76295   3rd Qu.: 0.71683  
 Max.   : 2.90336   Max.   : 2.95779  
============Parameter Values================
RANDOM NUMBERS OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]
[1,]  0.7
[2,]  0.7
[3,]  0.7
[4,]  0.7
[5,]  0.7
[6,]  0.7

TE: Covariance of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.51 0.00 0.00 0.00 0.00 0.00
[2,] 0.00 0.51 0.00 0.00 0.00 0.00
[3,] 0.00 0.00 0.51 0.00 0.00 0.00
[4,] 0.00 0.00 0.00 0.51 0.00 0.00
[5,] 0.00 0.00 0.00 0.00 0.51 0.00
[6,] 0.00 0.00 0.00 0.00 0.00 0.51

TY: Measurement Intercept of Indicator.Y 
[1] 0 0 0 0 0 0

PS: Covariance of Regression.Residual.PSI 
     [,1]
[1,]    1

AL: Regression Intercept of Factor.ETA 
[1] 0
------------------------------------------------- 
============================================
> summaryPopulation(Data)
======== Real Parameters =========
RANDOM NUMBERS OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]
[1,]  0.7
[2,]  0.7
[3,]  0.7
[4,]  0.7
[5,]  0.7
[6,]  0.7

TE: Covariance of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] 0.51 0.00 0.00 0.00 0.00 0.00
[2,] 0.00 0.51 0.00 0.00 0.00 0.00
[3,] 0.00 0.00 0.51 0.00 0.00 0.00
[4,] 0.00 0.00 0.00 0.51 0.00 0.00
[5,] 0.00 0.00 0.00 0.00 0.51 0.00
[6,] 0.00 0.00 0.00 0.00 0.00 0.51

TY: Measurement Intercept of Indicator.Y 
[1] 0 0 0 0 0 0

PS: Covariance of Regression.Residual.PSI 
     [,1]
[1,]    1

AL: Regression Intercept of Factor.ETA 
[1] 0
------------------------------------------------- 
> mis <- getPopulation(Data, misspec=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("SimEqualCon-class")
> ### * SimEqualCon-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimEqualCon-class
> ### Title: Class '"SimEqualCon"'
> ### Aliases: SimEqualCon-class summary,SimEqualCon-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimEqualCon")
Class "SimEqualCon" [package "simsem"]

Slots:
                                                
Name:            con     modelType conBeforeFill
Class:          list     character       logical

Known Subclasses: "NullSimEqualCon"
> constraint1 <- matrix(1, 3, 2)
> constraint1[,1] <- 1:3
> rownames(constraint1) <- rep("LY", 3)
> constraint2 <- matrix(2, 3, 2)
> constraint2[,1] <- 4:6
> rownames(constraint2) <- rep("LY", 3)
> constraint3 <- matrix(3, 2, 2)
> constraint3[,1] <- 7:8
> rownames(constraint3) <- rep("LY", 2)
> equal.loading <- simEqualCon(constraint1, constraint2, constraint3, modelType="SEM")
> summary(equal.loading)
CONSTRAINT OBJECT
Model Type
[1] "SEM"
-------------Constraint----------------
1.
   Group Row Column
LY    NA   1      1
LY    NA   2      1
LY    NA   3      1
---------------------------------------
2.
   Group Row Column
LY    NA   4      2
LY    NA   5      2
LY    NA   6      2
---------------------------------------
3.
   Group Row Column
LY    NA   7      3
LY    NA   8      3
---------------------------------------
> 
> 
> 
> cleanEx()
> nameEx("SimFunction-class")
> ### * SimFunction-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimFunction-class
> ### Title: Class '"SimFunction"'
> ### Aliases: SimFunction-class summary,SimFunction-method
> ###   run,SimFunction-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimFunction")
Class "SimFunction" [package "simsem"]

Slots:
                                    
Name:        fun attribute   callfun
Class:  function      list      call

Known Subclasses: "NullSimFunction"
> 
> n65 <- simNorm(0.6, 0.05)
> u35 <- simUnif(0.3, 0.5)
> u68 <- simUnif(0.6, 0.8)
> u2 <- simUnif(-0.2, 0.2)
> n1 <- simNorm(0, 0.1)
> 
> loading <- matrix(0, 9, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 3] <- NA
> loading.start <- matrix("", 9, 3)
> loading.start[1:3, 1] <- 0.7
> loading.start[4:6, 2] <- 0.7
> loading.start[7:9, 3] <- "u68"
> LY <- simMatrix(loading, loading.start)
> 
> RTE <- symMatrix(diag(9))
> 
> factor.cor <- diag(3)
> factor.cor[1, 2] <- factor.cor[2, 1] <- NA
> RPS <- symMatrix(factor.cor, 0.5)
> 
> path <- matrix(0, 3, 3)
> path[3, 1:2] <- NA
> path.start <- matrix(0, 3, 3)
> path.start[3, 1] <- "n65"
> path.start[3, 2] <- "u35"
> BE <- simMatrix(path, path.start)
> 
> datGen <- simSetSEM(BE=BE, LY=LY, RPS=RPS, RTE=RTE)
> 
> loading.trivial <- matrix(NA, 9, 3)
> loading.trivial[is.na(loading)] <- 0
> LY.trivial <- simMatrix(loading.trivial, "u2")
> 
> error.cor.trivial <- matrix(NA, 9, 9)
> diag(error.cor.trivial) <- 0
> RTE.trivial <- symMatrix(error.cor.trivial, "n1")
> 
> misGen <- simMisspecSEM(LY = LY.trivial, RTE = RTE.trivial)
> 
> Data.Mis <- simData(datGen, 300, misspec=misGen)
> 
> loading <- matrix(0, 12, 4)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 4] <- NA
> loading[10:12, 3] <- NA
> 
> path <- matrix(0, 4, 4)
> path[4, 1:3] <- NA
> 
> analysis <- simParamSEM(BE=path, LY=loading)
> 
> Model <- simModel(analysis)
> 
> fun <- simFunction(indProd, var1=paste("y", 1:3, sep=""), var2=paste("y", 4:6, sep=""), namesProd=paste("y", 10:12, sep=""))
> 
> # Real simulation will need more than just 10 replications
> Output <- simResult(10, Data.Mis, Model, objFunction=fun)
Error in solve.default(E) : 
  system is computationally singular: reciprocal condition number = 2.80345e-26
Warning in estimateVCOV(lavaanModel, samplestats = lavaanSampleStats, options = lavaanOptions,  :
  lavaan WARNING: could not compute standard errors!

> summary(Output)
RESULT OBJECT
Model Type
[1] "SEM"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi    178.213  178.550  178.820  178.881
      AIC   9519.072 9634.792 9727.367 9748.197
      BIC   9674.631 9790.351 9882.926 9903.756
      RMSEA    0.095    0.095    0.095    0.095
      CFI      0.897    0.897    0.897    0.897
      TLI      0.859    0.858    0.858    0.858
      SRMR     0.065    0.065    0.066    0.066
========= Parameter Estimates and Standard Errors ============
        Estimate Average Estimate SD Average SE Power (Not equal 0) Std Est
LY1_1              0.674       0.136      0.056               1.000   0.677
LY2_1              0.771       0.144      0.055               1.000   0.766
LY3_1              0.601       0.122      0.056               1.000   0.613
LY4_2              0.728       0.226      0.056               1.000   0.718
LY5_2              0.718       0.185      0.055               1.000   0.719
LY6_2              0.638       0.185      0.056               1.000   0.634
LY10_3             0.573       0.187      0.118               1.000   0.538
LY11_3             0.627       0.233      0.108               1.000   0.575
LY12_3             0.494       0.203      0.089               1.000   0.481
LY7_4              0.291       0.117      0.076               0.889   0.762
LY8_4              0.293       0.173      0.063               0.889   0.700
LY9_4              0.278       0.163      0.072               0.889   0.683
BE4_1              2.298       2.483      4.082               0.889   0.606
BE4_2              1.688       1.803      2.818               0.778   0.413
BE4_3             -0.023       0.146      0.302               0.000  -0.001
PS2_1              0.496       0.122      0.058               1.000   0.496
PS3_1              0.068       0.162      0.084               0.333   0.068
PS3_2              0.097       0.137      0.079               0.556   0.097
TE1_1              0.516       0.164      0.055               1.000   0.529
TE2_2              0.402       0.226      0.051               0.889   0.395
TE3_3              0.588       0.155      0.056               1.000   0.611
TE4_4              0.451       0.318      0.062               0.667   0.446
TE5_5              0.453       0.279      0.058               0.889   0.451
TE6_6              0.571       0.233      0.057               1.000   0.569
TE7_7              0.395       0.264      0.043               0.889   0.394
TE8_8              0.471       0.239      0.049               0.889   0.484
TE9_9              0.500       0.255      0.050               1.000   0.504
TE10_10            0.773       0.217      0.156               0.889   0.689
TE11_11            0.723       0.235      0.140               0.889   0.637
TE12_12            0.753       0.171      0.097               1.000   0.738
TY1               -0.003       0.052      0.057               0.111  -0.002
TY2                0.037       0.049      0.058               0.111   0.037
TY3                0.008       0.057      0.057               0.000   0.009
TY4               -0.005       0.054      0.058               0.000  -0.004
TY5                0.009       0.071      0.058               0.111   0.010
TY6               -0.013       0.061      0.058               0.000  -0.013
TY7               -0.020       0.042      0.058               0.000  -0.021
TY8                0.023       0.057      0.057               0.000   0.024
TY9               -0.026       0.063      0.058               0.111  -0.026
TY10               0.000       0.000      0.061               0.000   0.000
TY11               0.000       0.000      0.062               0.000   0.000
TY12               0.000       0.000      0.059               0.000   0.000
        Std Est SD
LY1_1        0.121
LY2_1        0.145
LY3_1        0.122
LY4_2        0.210
LY5_2        0.189
LY6_2        0.180
LY10_3       0.155
LY11_3       0.191
LY12_3       0.186
LY7_4        0.172
LY8_4        0.170
LY9_4        0.181
BE4_1        0.099
BE4_2        0.181
BE4_3        0.049
PS2_1        0.122
PS3_1        0.162
PS3_2        0.137
TE1_1        0.176
TE2_2        0.226
TE3_3        0.152
TE4_4        0.306
TE5_5        0.273
TE6_6        0.241
TE7_7        0.257
TE8_8        0.251
TE9_9        0.255
TE10_10      0.173
TE11_11      0.227
TE12_12      0.180
TY1          0.051
TY2          0.049
TY3          0.058
TY4          0.054
TY5          0.070
TY6          0.061
TY7          0.043
TY8          0.057
TY9          0.063
TY10         0.000
TY11         0.000
TY12         0.000
========= Correlation between Fit Indices ============
         Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR
Chi    1.000 -0.588 -0.588  0.996 -0.666 -0.666  0.712
AIC   -0.588  1.000  1.000 -0.573 -0.117 -0.117 -0.419
BIC   -0.588  1.000  1.000 -0.573 -0.117 -0.117 -0.419
RMSEA  0.996 -0.573 -0.573  1.000 -0.676 -0.676  0.678
CFI   -0.666 -0.117 -0.117 -0.676  1.000  1.000 -0.354
TLI   -0.666 -0.117 -0.117 -0.676  1.000  1.000 -0.354
SRMR   0.712 -0.419 -0.419  0.678 -0.354 -0.354  1.000
================== Replications =====================
Number of Replications
[1] 10
Number of Converged Replications
[1] 9
NOTE: The data generation model is not the same as the analysis model. See the summary of the population underlying data generation by the summaryPopulation function.
> 
> # Example of using the simfunction
> mc <- simFunction(indProd, var1=1:3, var2=4:6)
> run(mc, attitude[,-1])
   complaints privileges learning raises critical advance complaints.raises
1          51         30       39     61       92      45        -32.873333
2          64         51       54     63       73      47        -85.306667
3          70         68       69     76       86      48        -50.906667
4          63         45       47     54       84      35        -51.273333
5          78         56       66     71       83      47        -16.973333
6          55         49       44     54       49      34         33.793333
7          67         42       56     66       68      35        -89.006667
8          75         50       55     70       66      41        -44.473333
9          82         72       67     71       83      31          8.493333
10         61         45       47     62       80      41        -74.806667
11         53         53       58     58       67      34          0.660000
12         60         47       39     59       74      41        -52.373333
13         62         57       42     55       63      25        -45.240000
14         83         83       45     59       77      35       -181.940000
15         77         54       72     79       77      46         59.860000
16         90         50       72     60       54      36       -197.973333
17         85         64       69     79       79      63        174.793333
18         60         65       75     55       80      60        -25.973333
19         70         46       57     75       85      46        -54.306667
20         58         68       54     64       78      52        -84.106667
21         40         33       34     43       64      33        485.893333
22         61         52       62     66       80      41        -97.206667
23         66         52       50     63       80      37        -88.573333
24         37         42       58     50       57      49        343.593333
25         54         42       48     66       75      33       -106.773333
26         77         66       63     88       76      72        153.460000
27         75         58       74     80       78      49         39.526667
28         57         44       45     51       83      38         41.326667
29         85         71       71     77       74      55        137.993333
30         82         39       59     64       78      39        -99.306667
   privileges.critical learning.advance
1          -415.895556       -97.948889
2           -13.462222       -71.682222
3           149.771111         1.951111
4           -92.328889        12.251111
5             6.371111       -22.882222
6            89.271111        48.417778
7            58.104444       -59.148889
8            10.237778       -59.415556
9           138.104444      -188.948889
10          -59.795556       -43.948889
11          -16.195556       -76.648889
12          -12.528889       -28.482222
13          -62.728889       195.584444
14           49.471111        28.117778
15          -15.295556       -14.115556
16           47.837778      -170.448889
17           28.771111       191.451111
18           44.871111       255.951111
19          -90.228889       -60.115556
20           30.837778       -83.515556
21          199.537778       160.117778
22          -23.162222       -72.948889
23          -23.162222       -24.282222
24          180.571111       -52.148889
25          -19.828889        21.051111
26           -1.362222       130.751111
27           -1.495556        44.917778
28          -92.428889        -5.982222
29          -30.928889       114.517778
30          -62.928889       -72.415556
> summary(mc)
FUNCTION OBJECT
Function Name =  indProd 
Addition attributes =  var1, var2 
> 
> 
> 
> cleanEx()
> nameEx("SimGenLabels-class")
> ### * SimGenLabels-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimGenLabels-class
> ### Title: Class '"SimGenLabels"'
> ### Aliases: SimGenLabels-class run,SimGenLabels-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("SimMatrix-class")
> ### * SimMatrix-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimMatrix-class
> ### Title: Matrix object: Random parameters matrix
> ### Aliases: SimMatrix-class run,SimMatrix-method
> ###   summaryShort,SimMatrix-method summary,SimMatrix-method
> ###   extract,SimMatrix-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimMatrix")
Class "SimMatrix" [package "simsem"]

Slots:
                    
Name:    free  value
Class: matrix matrix

Known Subclasses: 
Class "SymMatrix", directly
Class "NullSimMatrix", directly
Class "NullSymMatrix", by class "SymMatrix", distance 2
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]  [,2] 
[1,] "0.7" ""   
[2,] "0.7" ""   
[3,] "0.7" ""   
[4,] ""    "0.7"
[5,] ""    "0.7"
[6,] ""    "0.7"
> run(LX)
     [,1] [,2]
[1,]  0.7  0.0
[2,]  0.7  0.0
[3,]  0.7  0.0
[4,]  0.0  0.7
[5,]  0.0  0.7
[6,]  0.0  0.7
> 
> n65 <- simNorm(0.6, 0.05)
> LY <- simMatrix(loading, "n65")
> summary(LY)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]                  [,2]                 
[1,] "rnorm(1, 0.6, 0.05)" ""                   
[2,] "rnorm(1, 0.6, 0.05)" ""                   
[3,] "rnorm(1, 0.6, 0.05)" ""                   
[4,] ""                    "rnorm(1, 0.6, 0.05)"
[5,] ""                    "rnorm(1, 0.6, 0.05)"
[6,] ""                    "rnorm(1, 0.6, 0.05)"
> run(LY)
          [,1]      [,2]
[1,] 0.5686773 0.0000000
[2,] 0.6091822 0.0000000
[3,] 0.5582186 0.0000000
[4,] 0.0000000 0.6797640
[5,] 0.0000000 0.6164754
[6,] 0.0000000 0.5589766
> 
> u34 <- simUnif(0.3, 0.4)
> LY <- adjust(LY, "u34", c(2, 1))
> summary(LY)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]                  [,2]                 
[1,] "rnorm(1, 0.6, 0.05)" ""                   
[2,] "runif(1, 0.3, 0.4)"  ""                   
[3,] "rnorm(1, 0.6, 0.05)" ""                   
[4,] ""                    "rnorm(1, 0.6, 0.05)"
[5,] ""                    "rnorm(1, 0.6, 0.05)"
[6,] ""                    "rnorm(1, 0.6, 0.05)"
> run(LY)
          [,1]      [,2]
[1,] 0.6243715 0.0000000
[2,] 0.3769841 0.0000000
[3,] 0.5997116 0.0000000
[4,] 0.0000000 0.7202327
[5,] 0.0000000 0.6381797
[6,] 0.0000000 0.5600495
> summaryShort(LY)
     [,1]                     [,2]                    
[1,] "NA:rnorm(1, 0.6, 0.05)" "0"                     
[2,] "NA:runif(1, 0.3, 0.4)"  "0"                     
[3,] "NA:rnorm(1, 0.6, 0.05)" "0"                     
[4,] "0"                      "NA:rnorm(1, 0.6, 0.05)"
[5,] "0"                      "NA:rnorm(1, 0.6, 0.05)"
[6,] "0"                      "NA:rnorm(1, 0.6, 0.05)"
> 
> LY <- extract(LY, 1:3, 1)
> summary(LY)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1]
[1,]   NA
[2,]   NA
[3,]   NA
[1] "Parameter/Starting Values:"
     [,1]                 
[1,] "rnorm(1, 0.6, 0.05)"
[2,] "runif(1, 0.3, 0.4)" 
[3,] "rnorm(1, 0.6, 0.05)"
> 
> 
> 
> cleanEx()
> nameEx("SimMissing-class")
> ### * SimMissing-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimMissing-class
> ### Title: Class '"SimMissing"'
> ### Aliases: SimMissing-class summary,SimMissing-method
> ###   run,SimMissing-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> # No Example
> 
> 
> 
> cleanEx()
> nameEx("SimMisspec-class")
> ### * SimMisspec-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimMisspec-class
> ### Title: Class '"SimMisspec"'
> ### Aliases: SimMisspec-class run,SimMisspec-method
> ###   summary,SimMisspec-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimMisspec")
Class "SimMisspec" [package "simsem"]

Slots:
                                                                              
Name:       conBeforeMis     misBeforeFill        misfitType       misfitBound
Class:           logical           logical         character            vector
                                                                              
Name:  averageNumMisspec         optMisfit           numIter         modelType
Class:           logical         character           numeric         character
                                                                              
Name:                 LY                TE               RTE               VTE
Class:         SimMatrix         SymMatrix         SymMatrix         SimVector
                                                                              
Name:                 PS               RPS               VPS                BE
Class:         SymMatrix         SymMatrix         SimVector         SimMatrix
                                                                              
Name:                 TY                AL                ME                MY
Class:         SimVector         SimVector         SimVector         SimVector
                                                                              
Name:                 VE                VY                LX                TD
Class:         SimVector         SimVector         SimMatrix         SymMatrix
                                                                              
Name:                RTD               VTD                PH               RPH
Class:         SymMatrix         SimVector         SymMatrix         SymMatrix
                                                                              
Name:                VPH                GA                TX                KA
Class:         SimVector         SimMatrix         SimVector         SimVector
                                                                              
Name:                 MX                VX                TH               RTH
Class:         SimVector         SimVector         SimMatrix         SimMatrix

Extends: "SimSet"

Known Subclasses: "NullSimMisspec"
> n01 <- simNorm(0, 0.1)
> error.cor.Mis <- matrix(NA, 6, 6)
> diag(error.cor.Mis) <- 1
> RTD.Mis <- symMatrix(error.cor.Mis, "n01")
> CFA.Model.Mis <- simMisspecCFA(RTD=RTD.Mis)
> 
> 
> 
> cleanEx()
> nameEx("SimModel-class")
> ### * SimModel-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimModel-class
> ### Title: Class '"SimModel"'
> ### Aliases: SimModel-class run,SimModel-method summary,SimModel-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimModel")
Class "SimModel" [package "simsem"]

Slots:
                                                                              
Name:    modelType       param       start    equalCon     package   estimator
Class:   character    SimParam     SimRSet SimEqualCon   character   character
                                          
Name:    auxiliary      indLab   factorLab
Class:      vector      vector      vector
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LX = LX, RPH = RPH, RTD = RTD)
> SimModel <- simModel(CFA.Model)
> summary(SimModel)
MODEL OBJECT
Model Type
[1] "CFA"
========= Parameters Set ============
SET OF ESTIMATED PARAMETERS
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA

TE: Covariance of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]   NA    0    0    0    0    0
[2,]    0   NA    0    0    0    0
[3,]    0    0   NA    0    0    0
[4,]    0    0    0   NA    0    0
[5,]    0    0    0    0   NA    0
[6,]    0    0    0    0    0   NA

TY: Measurement Intercept of Indicator.Y 
[1] NA NA NA NA NA NA

PS: Covariance of Regression.Residual.PSI 
     [,1] [,2]
[1,]    1   NA
[2,]   NA    1

AL: Regression Intercept of Factor.ETA 
[1] 0 0
------------------------------------------------- 
Number of free parameters =  19 
=====================================
Adding Constraint?
[1] "No"
Analysis Package
[1] "lavaan"
> 
> 
> 
> cleanEx()
> nameEx("SimModelMIOut-class")
> ### * SimModelMIOut-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimModelMIOut-class
> ### Title: Class '"SimModelMIOut"'
> ### Aliases: SimModelMIOut-class
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimModelMIOut")
Class "SimModelMIOut" [package "simsem"]

Slots:
                                                                              
Name:         FMI1        FMI2       param       start    equalCon     package
Class:     SimRSet     SimRSet    SimParam     SimRSet SimEqualCon   character
                                                                              
Name:         coef         fit          se   converged  paramValue           n
Class:     SimRSet      vector     SimRSet     logical     SimRSet     numeric
                              
Name:       indLab   factorLab
Class:      vector      vector

Extends: "SimModelOut"
> showClass("SimResult")
Class "SimResult" [package "simsem"]

Slots:
                                                                        
Name:   modelType       nRep       coef         se        fit  converged
Class:  character    numeric data.frame data.frame data.frame     vector
                                                                        
Name:  paramValue       FMI1       FMI2    stdCoef       seed          n
Class: data.frame data.frame data.frame data.frame    numeric     vector
                            
Name:      pmMCAR      pmMAR
Class:     vector     vector
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> SimMissing <- simMissing(pmMCAR=0.05, numImps=5)
> Data <- run(SimData)
> Data <- run(SimMissing, Data)
> Result <- run(SimModel, Data, SimMissing)
Loading required package: Amelia
Loading required package: foreign
## 
## Amelia II: Multiple Imputation
## (Version 1.6.1, built: 2012-03-29)
## Copyright (C) 2005-2012 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 
> summary(Result)
MODEL ANALYSIS RESULT OBJECT
Fit Indices
            Chi              df          pvalue    baseline.Chi     baseline.df 
          5.165           9.000           0.813         958.393          15.000 
baseline.pvalue             CFI             TLI             AIC             BIC 
          0.000           1.000           1.007        7678.489        7754.352 
          RMSEA  RMSEA.ci.lower  RMSEA.ci.upper            SRMR               F 
          0.000           0.000           0.031           0.013           0.574 
            df1             df2             p.F      baseline.F    baseline.df1 
          9.000          61.595           0.813          63.893          15.000 
   baseline.df2    baseline.p.F 
        390.975           0.000 
========= Parameter Estimates and Standard Errors ============
      Estimate    SE      z     p Std Est  FMI1        FMI2
LY1_1    0.716 0.041 17.262 0.000   0.724 0.014 0.014403851
LY2_1    0.685 0.043 15.774 0.000   0.674 0.008 0.007806456
LY3_1    0.726 0.047 15.326 0.000   0.688 0.113 0.118105314
LY4_1    0.696 0.044 15.966 0.000   0.679 0.004 0.004303168
LY5_1    0.737 0.047 15.747 0.000   0.696 0.092 0.095601442
LY6_1    0.654 0.044 14.724 0.000   0.664 0.101 0.105160354
TE1_1    0.467 0.038 12.418 0.000   0.476 0.019 0.019288445
TE2_2    0.564 0.043 13.184 0.000   0.546 0.024 0.023837487
TE3_3    0.585 0.046 12.853 0.000   0.527 0.043 0.044030746
TE4_4    0.565 0.044 12.700 0.000   0.539 0.083 0.086606959
TE5_5    0.577 0.046 12.434 0.000   0.515 0.087 0.090029659
TE6_6    0.543 0.044 12.360 0.000   0.560 0.159 0.169000722
TY1      0.011 0.044  0.256 0.798   0.012 0.008 0.008484157
TY2      0.010 0.046  0.211 0.833   0.010 0.033 0.033287398
TY3      0.004 0.048  0.087 0.931   0.004 0.039 0.040227013
TY4      0.041 0.046  0.885 0.376   0.040 0.019 0.018981050
TY5      0.048 0.049  0.969 0.333   0.045 0.079 0.081649930
TY6      0.018 0.045  0.413 0.680   0.019 0.024 0.024414212
Converged
[1] TRUE
> 
> 
> 
> cleanEx()

detaching 'package:Amelia', 'package:foreign'

> nameEx("SimModelOut-class")
> ### * SimModelOut-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimModelOut-class
> ### Title: Class '"SimModelOut"'
> ### Aliases: SimModelOut-class summary,SimModelOut-method
> ###   createImpliedMACS,SimModelOut-method
> ###   summaryPopulation,SimModelOut-method getPopulation,SimModelOut-method
> ###   setPopulation,SimModelOut,SimRSet-method
> ###   setPopulation,SimModelOut,SimSet-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimModelOut")
Class "SimModelOut" [package "simsem"]

Slots:
                                                                              
Name:        param       start    equalCon     package        coef         fit
Class:    SimParam     SimRSet SimEqualCon   character     SimRSet      vector
                                                                              
Name:           se   converged  paramValue           n      indLab   factorLab
Class:     SimRSet     logical     SimRSet     numeric      vector      vector

Known Subclasses: "SimModelMIOut"
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> Data <- run(SimData)
> Result <- run(SimModel, Data)
> summary(Result)
MODEL ANALYSIS RESULT OBJECT
Fit Indices
            Chi              df          pvalue    baseline.Chi     baseline.df 
          4.178           9.000           0.899        1007.154          15.000 
baseline.pvalue             CFI             TLI             AIC             BIC 
          0.000           1.000           1.008        7677.530        7753.393 
          RMSEA  RMSEA.ci.lower  RMSEA.ci.upper            SRMR 
          0.000           0.000           0.022           0.009 
========= Parameter Estimates and Standard Errors ============
      Estimate    SE      z     p      Std Est
LY1_1    0.716 0.041 17.432 0.000  0.724666685
LY2_1    0.693 0.044 15.905 0.000  0.675881269
LY3_1    0.739 0.045 16.412 0.000  0.692385420
LY4_1    0.705 0.043 16.232 0.000  0.686536799
LY5_1    0.727 0.044 16.399 0.000  0.691962134
LY6_1    0.646 0.042 15.446 0.000  0.660677441
TE1_1    0.463 0.037 12.540 0.000  0.474858196
TE2_2    0.570 0.043 13.332 0.000  0.543184510
TE3_3    0.594 0.045 13.093 0.000  0.520602430
TE4_4    0.557 0.042 13.181 0.000  0.528667224
TE5_5    0.576 0.044 13.100 0.000  0.521188406
TE6_6    0.538 0.040 13.530 0.000  0.563505319
TY1      0.003 0.044  0.060 0.952  0.002680210
TY2      0.019 0.046  0.409 0.683  0.018282260
TY3     -0.010 0.048 -0.201 0.841 -0.008973401
TY4      0.032 0.046  0.699 0.484  0.031269038
TY5      0.043 0.047  0.908 0.364  0.040613303
TY6      0.016 0.044  0.376 0.707  0.016807132
Converged
[1] TRUE
> summaryParam(Result)
          Estimate         SE           z         p      Std Est
LY1_1  0.715506677 0.04104548 17.43204614 0.0000000  0.724666685
LY2_1  0.692648365 0.04354827 15.90530123 0.0000000  0.675881269
LY3_1  0.739414122 0.04505208 16.41242949 0.0000000  0.692385420
LY4_1  0.704905029 0.04342787 16.23162921 0.0000000  0.686536799
LY5_1  0.727423233 0.04435696 16.39930406 0.0000000  0.691962134
LY6_1  0.645651773 0.04179930 15.44647208 0.0000000  0.660677441
TE1_1  0.462929363 0.03691697 12.53974432 0.0000000  0.474858196
TE2_2  0.570469175 0.04278926 13.33206383 0.0000000  0.543184510
TE3_3  0.593725696 0.04534635 13.09313084 0.0000000  0.520602430
TE4_4  0.557334544 0.04228373 13.18082878 0.0000000  0.528667224
TE5_5  0.575976048 0.04396900 13.09959485 0.0000000  0.521188406
TE6_6  0.538165385 0.03977435 13.53046460 0.0000000  0.563505319
TY1    0.002646331 0.04415607  0.05993131 0.9522103  0.002680210
TY2    0.018735802 0.04583080  0.40880376 0.6826837  0.018282260
TY3   -0.009582899 0.04775896 -0.20065136 0.8409712 -0.008973401
TY4    0.032105639 0.04591788  0.69919695 0.4844290  0.031269038
TY5    0.042694620 0.04701320  0.90814107 0.3638037  0.040613303
TY6    0.016424890 0.04370427  0.37581889 0.7070515  0.016807132
> summaryPopulation(Result)
[1] "There is no parameter value underlying the data."
[1] "There is no parameter value underlying the data."
> param <- getPopulation(Result)
> Result2 <- setPopulation(Result, param)
> Result3 <- setPopulation(Result, CFA.Model)
> 
> 
> 
> cleanEx()
> nameEx("SimParam-class")
> ### * SimParam-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimParam-class
> ### Title: Class '"SimParam"'
> ### Aliases: SimParam-class summary,SimParam-method
> 
> ### ** Examples
> 
> showClass("SimParam")
Class "SimParam" [package "simsem"]

Slots:
                                                                            
Name:  modelType        LY        TE        PS        BE        TY        AL
Class: character    matrix    matrix    matrix    matrix    vector    vector
                                                                            
Name:         LX        TD        PH        GA        TX        KA        TH
Class:    matrix    matrix    matrix    matrix    vector    vector    matrix

Extends: "VirtualRSet"
> 
> library(lavaan)
> loading <- matrix(0, 9, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 3] <- NA
> HS.Model <- simParamCFA(LX = loading)
> summary(HS.Model)
SET OF ESTIMATED PARAMETERS
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
      [,1] [,2] [,3]
 [1,]   NA    0    0
 [2,]   NA    0    0
 [3,]   NA    0    0
 [4,]    0   NA    0
 [5,]    0   NA    0
 [6,]    0   NA    0
 [7,]    0    0   NA
 [8,]    0    0   NA
 [9,]    0    0   NA

TE: Covariance of Measurement.Error.EPSILON 
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
 [1,]   NA    0    0    0    0    0    0    0    0
 [2,]    0   NA    0    0    0    0    0    0    0
 [3,]    0    0   NA    0    0    0    0    0    0
 [4,]    0    0    0   NA    0    0    0    0    0
 [5,]    0    0    0    0   NA    0    0    0    0
 [6,]    0    0    0    0    0   NA    0    0    0
 [7,]    0    0    0    0    0    0   NA    0    0
 [8,]    0    0    0    0    0    0    0   NA    0
 [9,]    0    0    0    0    0    0    0    0   NA

TY: Measurement Intercept of Indicator.Y 
[1] NA NA NA NA NA NA NA NA NA

PS: Covariance of Regression.Residual.PSI 
     [,1] [,2] [,3]
[1,]    1   NA   NA
[2,]   NA    1   NA
[3,]   NA   NA    1

AL: Regression Intercept of Factor.ETA 
[1] 1 1 1
------------------------------------------------- 
> SimModel <- simModel(HS.Model, indLab=paste("x", 1:9, sep=""))
> out <- run(SimModel, HolzingerSwineford1939)
> summary(out)
MODEL ANALYSIS RESULT OBJECT
Fit Indices
            Chi              df          pvalue    baseline.Chi     baseline.df 
         85.306          24.000           0.000         918.852          36.000 
baseline.pvalue             CFI             TLI             AIC             BIC 
          0.000           0.931           0.896        7535.490        7646.703 
          RMSEA  RMSEA.ci.lower  RMSEA.ci.upper            SRMR 
          0.092           0.071           0.114           0.060 
========= Parameter Estimates and Standard Errors ============
      Estimate    SE      z p   Std Est
LY1_1    0.900 0.081 11.127 0 0.7718808
LY2_1    0.498 0.077  6.429 0 0.4235991
LY3_1    0.656 0.074  8.817 0 0.5811320
LY4_2    0.990 0.057 17.474 0 0.8515822
LY5_2    1.102 0.063 17.576 0 0.8550653
LY6_2    0.917 0.054 17.082 0 0.8380100
LY7_3    0.619 0.070  8.903 0 0.5695144
LY8_3    0.731 0.066 11.090 0 0.7230441
LY9_3    0.670 0.065 10.305 0 0.6650091
PS2_1    0.459 0.064  7.189 0 0.4585082
PS3_1    0.471 0.073  6.461 0 0.4705332
PS3_2    0.283 0.069  4.117 0 0.2829833
TE1_1    0.549 0.114  4.833 0 0.4042000
TE2_2    1.134 0.102 11.146 0 0.8205638
TE3_3    0.844 0.091  9.317 0 0.6622856
TE4_4    0.371 0.048  7.778 0 0.2748077
TE5_5    0.446 0.058  7.642 0 0.2688633
TE6_6    0.356 0.043  8.277 0 0.2977393
TE7_7    0.799 0.081  9.823 0 0.6756533
TE8_8    0.488 0.074  6.573 0 0.4772072
TE9_9    0.566 0.071  8.003 0 0.5577629
TY1      4.036 0.105 38.398 0 3.4630482
TY2      5.590 0.103 54.322 0 4.7555391
TY3      1.594 0.099 16.126 0 1.4119762
TY4      2.071 0.088 23.611 0 1.7821807
TY5      3.239 0.097 33.332 0 2.5140601
TY6      1.269 0.083 15.328 0 1.1601697
TY7      3.566 0.094 38.078 0 3.2788058
TY8      4.796 0.088 54.518 0 4.7442674
TY9      4.704 0.087 53.963 0 4.6692496
Converged
[1] TRUE
> 
> HS.Model2 <- extract(HS.Model, y=1:3)
> summary(HS.Model2)
SET OF ESTIMATED PARAMETERS
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1] [,2] [,3]
[1,]   NA    0    0
[2,]   NA    0    0
[3,]   NA    0    0

TE: Covariance of Measurement.Error.EPSILON 
     [,1] [,2] [,3]
[1,]   NA    0    0
[2,]    0   NA    0
[3,]    0    0   NA

TY: Measurement Intercept of Indicator.Y 
[1] NA NA NA

PS: Covariance of Regression.Residual.PSI 
     [,1] [,2] [,3]
[1,]    1   NA   NA
[2,]   NA    1   NA
[3,]   NA   NA    1

AL: Regression Intercept of Factor.ETA 
[1] 1 1 1
------------------------------------------------- 
> 
> 
> 
> cleanEx()
> nameEx("SimREqualCon-class")
> ### * SimREqualCon-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimREqualCon-class
> ### Title: Class '"SimREqualCon"'
> ### Aliases: SimREqualCon-class summary,SimREqualCon-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("SimResult-class")
> ### * SimResult-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimResult-class
> ### Title: Class '"SimResult"'
> ### Aliases: SimResult-class summary,SimResult-method
> ###   summaryPopulation,SimResult-method getPopulation,SimResult-method
> ###   setPopulation,SimResult,data.frame-method
> ###   setPopulation,SimResult,SimSet-method
> ###   setPopulation,SimResult,VirtualRSet-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimResult")
Class "SimResult" [package "simsem"]

Slots:
                                                                        
Name:   modelType       nRep       coef         se        fit  converged
Class:  character    numeric data.frame data.frame data.frame     vector
                                                                        
Name:  paramValue       FMI1       FMI2    stdCoef       seed          n
Class: data.frame data.frame data.frame data.frame    numeric     vector
                            
Name:      pmMCAR      pmMAR
Class:     vector     vector
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(5, SimData, SimModel)
> summary(Output)
RESULT OBJECT
Model Type
[1] "CFA"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi     11.899   12.033   12.139   12.164
      AIC   7514.252 7539.068 7558.920 7563.387
      BIC   7590.115 7614.931 7634.783 7639.249
      RMSEA    0.025    0.026    0.026    0.027
      CFI      0.997    0.997    0.997    0.997
      TLI      0.996    0.996    0.995    0.995
      SRMR     0.014    0.014    0.014    0.014
========= Parameter Estimates and Standard Errors ============
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0. Std.Est
LY1_1            0.706       0.026      0.042                 1.0   0.704
LY2_1            0.710       0.022      0.042                 1.0   0.701
LY3_1            0.710       0.038      0.042                 1.0   0.705
LY4_1            0.708       0.053      0.041                 1.0   0.718
LY5_1            0.687       0.044      0.042                 1.0   0.687
LY6_1            0.718       0.046      0.041                 1.0   0.724
TE1_1            0.508       0.036      0.038                 1.0   0.505
TE2_2            0.522       0.041      0.039                 1.0   0.508
TE3_3            0.509       0.046      0.039                 1.0   0.502
TE4_4            0.467       0.027      0.036                 1.0   0.484
TE5_5            0.526       0.065      0.039                 1.0   0.526
TE6_6            0.466       0.041      0.036                 1.0   0.475
TY1             -0.047       0.042      0.045                 0.2  -0.047
TY2             -0.024       0.057      0.045                 0.2  -0.023
TY3             -0.035       0.058      0.045                 0.2  -0.034
TY4             -0.012       0.069      0.044                 0.2  -0.012
TY5             -0.016       0.028      0.045                 0.0  -0.016
TY6             -0.011       0.024      0.044                 0.0  -0.011
      Std.Est.SD Average.Param Average.Bias Coverage
LY1_1      0.017          0.70        0.006      1.0
LY2_1      0.018          0.70        0.010      1.0
LY3_1      0.031          0.70        0.010      1.0
LY4_1      0.032          0.70        0.008      1.0
LY5_1      0.045          0.70       -0.013      1.0
LY6_1      0.034          0.70        0.018      1.0
TE1_1      0.024          0.51       -0.002      1.0
TE2_2      0.025          0.51        0.012      1.0
TE3_3      0.043          0.51       -0.001      1.0
TE4_4      0.046          0.51       -0.043      0.8
TE5_5      0.061          0.51        0.016      0.8
TE6_6      0.049          0.51       -0.044      0.8
TY1        0.043          0.00       -0.047      0.8
TY2        0.055          0.00       -0.024      0.8
TY3        0.058          0.00       -0.035      0.8
TY4        0.069          0.00       -0.012      0.8
TY5        0.027          0.00       -0.016      1.0
TY6        0.025          0.00       -0.011      1.0
========= Correlation between Fit Indices ============
         Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR
Chi    1.000 -0.023 -0.023  0.951 -0.946 -1.000  0.978
AIC   -0.023  1.000  1.000 -0.289  0.259  0.001  0.137
BIC   -0.023  1.000  1.000 -0.289  0.259  0.001  0.137
RMSEA  0.951 -0.289 -0.289  1.000 -0.994 -0.947  0.867
CFI   -0.946  0.259  0.259 -0.994  1.000  0.944 -0.862
TLI   -1.000  0.001  0.001 -0.947  0.944  1.000 -0.980
SRMR   0.978  0.137  0.137  0.867 -0.862 -0.980  1.000
================== Replications =====================
Number of Replications
[1] 5
Number of Converged Replications
[1] 5
> getCutoff(Output, 0.05)
         Chi          AIC          BIC        RMSEA          CFI          TLI 
1.203253e+01 7.539068e+03 7.614931e+03 2.593236e-02 9.973459e-01 9.955765e-01 
        SRMR 
1.432592e-02 
> summaryParam(Output)
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0.     Std.Est
LY1_1       0.70617392  0.02632084 0.04170003                 1.0  0.70369655
LY2_1       0.70950261  0.02202627 0.04212368                 1.0  0.70095240
LY3_1       0.71040091  0.03764679 0.04182034                 1.0  0.70527823
LY4_1       0.70795573  0.05322649 0.04062185                 1.0  0.71810121
LY5_1       0.68697684  0.04421547 0.04183965                 1.0  0.68738618
LY6_1       0.71756184  0.04565351 0.04076849                 1.0  0.72383557
TE1_1       0.50835147  0.03611067 0.03847747                 1.0  0.50457420
TE2_2       0.52155750  0.04075516 0.03934573                 1.0  0.50841134
TE3_3       0.50892906  0.04558754 0.03869509                 1.0  0.50183172
TE4_4       0.46742701  0.02669592 0.03607111                 1.0  0.48351273
TE5_5       0.52571869  0.06464558 0.03922000                 1.0  0.52588737
TE6_6       0.46572295  0.04058423 0.03621606                 1.0  0.47512288
TY1        -0.04717826  0.04197696 0.04487778                 0.2 -0.04730833
TY2        -0.02411250  0.05686125 0.04527260                 0.2 -0.02290608
TY3        -0.03457255  0.05763459 0.04504030                 0.2 -0.03433061
TY4        -0.01165663  0.06935717 0.04404377                 0.2 -0.01214792
TY5        -0.01591134  0.02757372 0.04470062                 0.0 -0.01572420
TY6        -0.01083889  0.02438384 0.04431291                 0.0 -0.01133479
      Std.Est.SD Average.Param Average.Bias Coverage
LY1_1 0.01721093          0.70  0.006173922      1.0
LY2_1 0.01783240          0.70  0.009502606      1.0
LY3_1 0.03063711          0.70  0.010400910      1.0
LY4_1 0.03197510          0.70  0.007955725      1.0
LY5_1 0.04490084          0.70 -0.013023164      1.0
LY6_1 0.03426359          0.70  0.017561844      1.0
TE1_1 0.02433406          0.51 -0.001648534      1.0
TE2_2 0.02527818          0.51  0.011557500      1.0
TE3_3 0.04268899          0.51 -0.001070943      1.0
TE4_4 0.04579649          0.51 -0.042572991      0.8
TE5_5 0.06064147          0.51  0.015718693      0.8
TE6_6 0.04881015          0.51 -0.044277049      0.8
TY1   0.04322582          0.00 -0.047178260      0.8
TY2   0.05500702          0.00 -0.024112496      0.8
TY3   0.05755595          0.00 -0.034572554      0.8
TY4   0.06923763          0.00 -0.011656635      0.8
TY5   0.02711972          0.00 -0.015911335      1.0
TY6   0.02493686          0.00 -0.010838890      1.0
> summaryPopulation(Output)
                 [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
Population Value 0.7  0.7  0.7  0.7  0.7  0.7  0.51 0.51 0.51 0.51  0.51  0.51 
                 [,13] [,14] [,15] [,16] [,17] [,18]
Population Value 0     0     0     0     0     0    
> param <- getPopulation(Output)
> Output <- setPopulation(Output, param)
> Output2 <- setPopulation(Output, CFA.Model)
> 
> 
> 
> cleanEx()
> nameEx("SimResultParam-class")
> ### * SimResultParam-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimResultParam-class
> ### Title: Class '"SimResultParam"'
> ### Aliases: SimResultParam-class summary,SimResultParam-method
> ###   summaryParam,SimResultParam-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimResultParam")
Class "SimResultParam" [package "simsem"]

Slots:
                                                                        
Name:   modelType       nRep      param    misspec        fit       seed
Class:  character    numeric data.frame data.frame data.frame    numeric
> 
> u35 <- simUnif(0.3, 0.5)
> u57 <- simUnif(0.5, 0.7)
> u1 <- simUnif(-0.1, 0.1)
> n31 <- simNorm(0.3, 0.1)
> 
> path.BE <- matrix(0, 4, 4)
> path.BE[3, 1:2] <- NA
> path.BE[4, 3] <- NA
> starting.BE <- matrix("", 4, 4)
> starting.BE[3, 1:2] <- "u35"
> starting.BE[4, 3] <- "u57"
> BE <- simMatrix(path.BE, starting.BE)
> 
> residual.error <- diag(4)
> residual.error[1,2] <- residual.error[2,1] <- NA
> RPS <- symMatrix(residual.error, "n31")
> 
> ME <- simVector(rep(NA, 4), 0)
> 
> Path.Model <- simSetPath(RPS = RPS, BE = BE, ME = ME)
> 
> mis.path.BE <- matrix(0, 4, 4)
> mis.path.BE[4, 1:2] <- NA
> mis.BE <- simMatrix(mis.path.BE, "u1")
> Path.Mis.Model <- simMisspecPath(BE = mis.BE, misfitType="rmsea") #, misfitBound=c(0.05, 0.08))
> 
> # The number of replications in actual analysis should be much more than 5
> ParamObject <- simResultParam(5, Path.Model, Path.Mis.Model)
> summary(ParamObject)
PARAMETER RESULT OBJECT
Model Type
[1] "Path"
========= Parameter Values ============
       mean    sd
BE3_1 0.421 0.054
BE3_2 0.442 0.057
BE4_3 0.605 0.028
PS1_1 1.000 0.000
PS2_1 0.297 0.075
PS2_2 1.000 0.000
PS3_3 0.508 0.122
PS4_4 0.633 0.034
AL1   0.000 0.000
AL2   0.000 0.000
AL3   0.000 0.000
AL4   0.000 0.000
========= Misspecification Values ============
       mean    sd
BE4_1 0.025 0.034
BE4_2 0.000 0.086
========= Fit Indices Distributions ============
              f0 rmsea  srmr
5%         0.010 0.071 0.023
10%        0.011 0.075 0.025
25%        0.015 0.086 0.029
50%        0.015 0.088 0.034
75%        0.019 0.097 0.036
90%        0.022 0.106 0.037
95%        0.024 0.109 0.038
fitAverage 0.017 0.090 0.032
fitSE      0.006 0.016 0.007
========= Correlation between Fit Indices and Parameter Misspecification ============
       BE4_1  BE4_2     f0  rmsea   srmr
BE4_1  1.000 -0.211 -0.625 -0.630 -0.696
BE4_2 -0.211  1.000  0.626  0.577  0.453
f0    -0.625  0.626  1.000  0.996  0.854
rmsea -0.630  0.577  0.996  1.000  0.886
srmr  -0.696  0.453  0.854  0.886  1.000
> 
> 
> 
> cleanEx()
> nameEx("SimSet-class")
> ### * SimSet-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimSet-class
> ### Title: Class '"SimSet"'
> ### Aliases: SimSet-class run,SimSet-method summary,SimSet-method
> ###   extract,SimSet-method
> 
> ### ** Examples
> 
> showClass("SimSet")
Class "SimSet" [package "simsem"]

Slots:
                                                                            
Name:  modelType        LY        TE       RTE       VTE        PS       RPS
Class: character SimMatrix SymMatrix SymMatrix SimVector SymMatrix SymMatrix
                                                                            
Name:        VPS        BE        TY        AL        ME        MY        VE
Class: SimVector SimMatrix SimVector SimVector SimVector SimVector SimVector
                                                                            
Name:         VY        LX        TD       RTD       VTD        PH       RPH
Class: SimVector SimMatrix SymMatrix SymMatrix SimVector SymMatrix SymMatrix
                                                                            
Name:        VPH        GA        TX        KA        MX        VX        TH
Class: SimVector SimMatrix SimVector SimVector SimVector SimVector SimMatrix
                
Name:        RTH
Class: SimMatrix

Known Subclasses: 
Class "NullSimSet", directly
Class "SimMisspec", directly
Class "NullSimMisspec", by class "SimMisspec", distance 2
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]  [,2] 
[1,] "0.7" ""   
[2,] "0.7" ""   
[3,] "0.7" ""   
[4,] ""    "0.7"
[5,] ""    "0.7"
[6,] ""    "0.7"
> 
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> 
> # Error Correlation Object
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> 
> CFA.Model <- simSetCFA(LX = LX, RPH = RPH, RTD = RTD)
> summary(CFA.Model)
SET OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]     [,2]    
[1,] "NA:0.7" "0"     
[2,] "NA:0.7" "0"     
[3,] "NA:0.7" "0"     
[4,] "0"      "NA:0.7"
[5,] "0"      "NA:0.7"
[6,] "0"      "NA:0.7"

RTE: Correlation of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] "1"  "0"  "0"  "0"  "0"  "0" 
[2,] "0"  "1"  "0"  "0"  "0"  "0" 
[3,] "0"  "0"  "1"  "0"  "0"  "0" 
[4,] "0"  "0"  "0"  "1"  "0"  "0" 
[5,] "0"  "0"  "0"  "0"  "1"  "0" 
[6,] "0"  "0"  "0"  "0"  "0"  "1" 

VY: Variance of Indicator.Y 
[1] "NA:1" "NA:1" "NA:1" "NA:1" "NA:1" "NA:1"

TY: Measurement Intercept of Indicator.Y 
[1] "NA:0" "NA:0" "NA:0" "NA:0" "NA:0" "NA:0"

VPS: Variance of Regression.Residual.PSI 
[1] "1" "1"

RPS: Correlation of Regression.Residual.PSI 
     [,1]     [,2]    
[1,] "1"      "NA:0.5"
[2,] "NA:0.5" "1"     

VE: Variance of Factor.ETA 
[1] "1" "1"

AL: Regression Intercept of Factor.ETA 
[1] "0" "0"

ME: mean of Factor.ETA 
[1] "0" "0"
-------------------------- 
> #run(CFA.Model)
> 
> CFA.Model2 <- extract(CFA.Model, y=1:3, e=1)
> summary(CFA.Model2)
SET OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]    
[1,] "NA:0.7"
[2,] "NA:0.7"
[3,] "NA:0.7"

RTE: Correlation of Measurement.Error.EPSILON 
     [,1] [,2] [,3]
[1,] "1"  "0"  "0" 
[2,] "0"  "1"  "0" 
[3,] "0"  "0"  "1" 

VY: Variance of Indicator.Y 
[1] "NA:1" "NA:1" "NA:1"

TY: Measurement Intercept of Indicator.Y 
[1] "NA:0" "NA:0" "NA:0"

VPS: Variance of Regression.Residual.PSI 
[1] "1"

RPS: Correlation of Regression.Residual.PSI 
     [,1]
[1,] "1" 

VE: Variance of Factor.ETA 
[1] "1"

AL: Regression Intercept of Factor.ETA 
[1] "0"

ME: mean of Factor.ETA 
[1] "0"
-------------------------- 
> 
> 
> 
> cleanEx()
> nameEx("SimVector-class")
> ### * SimVector-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SimVector-class
> ### Title: Vector object: Random parameters vector
> ### Aliases: SimVector-class run,SimVector-method
> ###   summaryShort,SimVector-method summary,SimVector-method
> ###   extract,SimVector-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SimVector")
Class "SimVector" [package "simsem"]

Slots:
                    
Name:    free  value
Class: vector vector

Known Subclasses: "NullSimVector"
> 
> factor.mean <- rep(NA, 2)
> factor.mean.starting <- c(5, 2)
> AL <- simVector(factor.mean, factor.mean.starting)
> run(AL)
[1] 5 2
> summary(AL)
[1] "Random Vector Object."
[1] "Free/Fixed Parameters:"
[1] NA NA
[1] "Parameter/Starting Values:"
[1] "5" "2"
> summaryShort(AL)
[1] "NA:5" "NA:2"
> 
> n01 <- simNorm(0, 1)
> AL <- adjust(AL, "n01", 2)
> run(AL)
[1]  5.0000000 -0.6264538
> summary(AL)
[1] "Random Vector Object."
[1] "Free/Fixed Parameters:"
[1] NA NA
[1] "Parameter/Starting Values:"
[1] "5"              "rnorm(1, 0, 1)"
> 
> AL <- extract(AL, 1)
> summary(AL)
[1] "Random Vector Object."
[1] "Free/Fixed Parameters:"
[1] NA
[1] "Parameter/Starting Values:"
[1] "5"
> 
> 
> 
> cleanEx()
> nameEx("SymMatrix-class")
> ### * SymMatrix-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SymMatrix-class
> ### Title: Symmetric matrix object: Random parameters symmetric matrix
> ### Aliases: SymMatrix-class run,SymMatrix-method summary,SymMatrix-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("SymMatrix")
Class "SymMatrix" [package "simsem"]

Slots:
                    
Name:    free  value
Class: matrix matrix

Extends: "SimMatrix"

Known Subclasses: "NullSymMatrix"
> 
> latent.cor <- matrix(NA, 3, 3)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> 
> u46 <- simUnif(0.4, 0.6)
> RPH <- adjust(RPH, "u46", c(3,2))
> summary(RPH)
[1] "Random Symmetric Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2] [,3]
[1,]    1   NA   NA
[2,]   NA    1   NA
[3,]   NA   NA    1
[1] "Parameter/Starting Values:"
     [,1]  [,2]                 [,3]                
[1,] ""    "0.5"                "0.5"               
[2,] "0.5" ""                   "runif(1, 0.4, 0.6)"
[3,] "0.5" "runif(1, 0.4, 0.6)" ""                  
> summaryShort(RPH)
     [,1]     [,2]                    [,3]                   
[1,] "1"      "NA:0.5"                "NA:0.5"               
[2,] "NA:0.5" "1"                     "NA:runif(1, 0.4, 0.6)"
[3,] "NA:0.5" "NA:runif(1, 0.4, 0.6)" "1"                    
> run(RPH)
     [,1]      [,2]      [,3]
[1,]  1.0 0.5000000 0.5000000
[2,]  0.5 1.0000000 0.4531017
[3,]  0.5 0.4531017 1.0000000
> 
> 
> 
> cleanEx()
> nameEx("VirtualDist-class")
> ### * VirtualDist-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: VirtualDist-class
> ### Title: Distribution Objects
> ### Aliases: VirtualDist-class SimBeta-class SimBinom-class SimCauchy-class
> ###   SimChisq-class SimExp-class SimF-class SimGamma-class SimGeom-class
> ###   SimHyper-class SimLnorm-class SimLogis-class SimNbinom-class
> ###   SimNorm-class SimPois-class SimT-class SimUnif-class SimWeibull-class
> ###   run,SimBeta-method run,SimBinom-method run,SimCauchy-method
> ###   run,SimChisq-method run,SimExp-method run,SimF-method
> ###   run,SimGamma-method run,SimGeom-method run,SimHyper-method
> ###   run,SimLnorm-method run,SimLogis-method run,SimNbinom-method
> ###   run,SimNorm-method run,SimPois-method run,SimT-method
> ###   run,SimUnif-method run,SimWeibull-method summary,SimBeta-method
> ###   summary,SimBinom-method summary,SimCauchy-method
> ###   summary,SimChisq-method summary,SimExp-method summary,SimF-method
> ###   summary,SimGamma-method summary,SimGeom-method
> ###   summary,SimHyper-method summary,SimLnorm-method
> ###   summary,SimLogis-method summary,SimNbinom-method
> ###   summary,SimNorm-method summary,SimPois-method summary,SimT-method
> ###   summary,SimUnif-method summary,SimWeibull-method
> ###   summaryShort,SimBeta-method summaryShort,SimBinom-method
> ###   summaryShort,SimCauchy-method summaryShort,SimChisq-method
> ###   summaryShort,SimExp-method summaryShort,SimF-method
> ###   summaryShort,SimGamma-method summaryShort,SimGeom-method
> ###   summaryShort,SimHyper-method summaryShort,SimLnorm-method
> ###   summaryShort,SimLogis-method summaryShort,SimNbinom-method
> ###   summaryShort,SimNorm-method summaryShort,SimPois-method
> ###   summaryShort,SimT-method summaryShort,SimUnif-method
> ###   summaryShort,SimWeibull-method toFunction,SimBeta-method
> ###   toFunction,SimBinom-method toFunction,SimCauchy-method
> ###   toFunction,SimChisq-method toFunction,SimExp-method
> ###   toFunction,SimF-method toFunction,SimGamma-method
> ###   toFunction,SimGeom-method toFunction,SimHyper-method
> ###   toFunction,SimLnorm-method toFunction,SimLogis-method
> ###   toFunction,SimNbinom-method toFunction,SimNorm-method
> ###   toFunction,SimPois-method toFunction,SimT-method
> ###   toFunction,SimUnif-method toFunction,SimWeibull-method
> ###   plotDist,VirtualDist-method skew,VirtualDist-method
> ###   kurtosis,VirtualDist-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> showClass("VirtualDist")
Virtual Class "VirtualDist" [package "simsem"]

No Slots, prototype of class "SimUnif"

Known Subclasses: "SimUnif", "SimNorm", "SimBeta", "SimBinom", "SimCauchy", "SimChisq", "SimExp", 
"SimF", "SimGamma", "SimGeom", "SimHyper", "SimLnorm", "SimLogis", "SimNbinom", 
"SimPois", "SimT", "SimWeibull"
> u1 <- simUnif(0, 1)
> chi3 <- simChisq(3)
> summary(chi3)
[1] "Random Chi-squared Distribution Object."
[1] "Degree of freedom is 3."
[1] "Non-centrality parameter is 0."
> skew(chi3)
[1] 1.631577
> kurtosis(chi3)
[1] 3.97977
> plotDist(chi3)
> plotDist(chi3, reverse=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("VirtualRSet-class")
> ### * VirtualRSet-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ParameterSet
> ### Title: Class '"VirtualRSet"', '"SimLabels"' and '"SimRSet"'
> ### Aliases: VirtualRSet-class SimRSet-class SimLabels-class
> ###   summary,VirtualRSet-method summary,SimRSet-method
> ###   summary,SimLabels-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("adjust")
> ### * adjust
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: adjust
> ### Title: Change an element in 'SimMatrix', 'SymMatrix', or 'SimVector'.
> ### Aliases: adjust adjust-methods adjust,ANY-method
> ###   adjust,SimMatrix-method adjust,SymMatrix-method
> ###   adjust,SimVector-method
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> LX <- simMatrix(loading, 0.7)
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]  [,2] 
[1,] "0.7" ""   
[2,] "0.7" ""   
[3,] "0.7" ""   
[4,] ""    "0.7"
[5,] ""    "0.7"
[6,] ""    "0.7"
> run(LX)
     [,1] [,2]
[1,]  0.7  0.0
[2,]  0.7  0.0
[3,]  0.7  0.0
[4,]  0.0  0.7
[5,]  0.0  0.7
[6,]  0.0  0.7
> 
> u34 <- simUnif(0.3, 0.4)
> LX <- adjust(LX, "u34", c(2, 1))
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]                 [,2] 
[1,] "0.7"                ""   
[2,] "runif(1, 0.3, 0.4)" ""   
[3,] "0.7"                ""   
[4,] ""                   "0.7"
[5,] ""                   "0.7"
[6,] ""                   "0.7"
> run(LX)
          [,1] [,2]
[1,] 0.7000000  0.0
[2,] 0.3265509  0.0
[3,] 0.7000000  0.0
[4,] 0.0000000  0.7
[5,] 0.0000000  0.7
[6,] 0.0000000  0.7
> 
> LX <- adjust(LX, 0, c(2,1))
> LX <- adjust(LX, 0.5, c(2,2), FALSE)
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]    0   NA
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]  [,2] 
[1,] "0.7" ""   
[2,] ""    "0.5"
[3,] "0.7" ""   
[4,] ""    "0.7"
[5,] ""    "0.7"
[6,] ""    "0.7"
> run(LX)
     [,1] [,2]
[1,]  0.7  0.0
[2,]  0.0  0.5
[3,]  0.7  0.0
[4,]  0.0  0.7
[5,]  0.0  0.7
[6,]  0.0  0.7
> 
> factor.mean <- rep(NA, 2)
> factor.mean.starting <- c(5, 2)
> AL <- simVector(factor.mean, factor.mean.starting)
> run(AL)
[1] 5 2
> summary(AL)
[1] "Random Vector Object."
[1] "Free/Fixed Parameters:"
[1] NA NA
[1] "Parameter/Starting Values:"
[1] "5" "2"
> 
> n01 <- simNorm(0, 1)
> AL <- adjust(AL, "n01", 2)
> run(AL)
[1]  5.0000000 -0.3262334
> summary(AL)
[1] "Random Vector Object."
[1] "Free/Fixed Parameters:"
[1] NA NA
[1] "Parameter/Starting Values:"
[1] "5"              "rnorm(1, 0, 1)"
> 
> 
> 
> cleanEx()
> nameEx("anova")
> ### * anova
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: anova
> ### Title: Provide a comparison of nested models across replications
> ### Aliases: anova,SimResult-method anova,SimModelOut-method
> ###   anova,SimModelMIOut-method
> 
> ### ** Examples
> 
> loading1 <- matrix(0, 6, 1)
> loading1[1:6, 1] <- NA
> loading2 <- loading1
> loading2[6,1] <- 0
> LX1 <- simMatrix(loading1, 0.7)
> LX2 <- simMatrix(loading2, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model1 <- simSetCFA(LY = LX1, RPS = RPH, RTE = RTD)
> CFA.Model2 <- simSetCFA(LY = LX2, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model1, 500)
> SimModel1 <- simModel(CFA.Model1)
> SimModel2 <- simModel(CFA.Model2)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> # Need to make sure that both simResult calls have the same seed!
> Output1 <- simResult(5, SimData, SimModel1, seed=123567)
> Output2 <- simResult(5, SimData, SimModel2, seed=123567)
> anova(Output1, Output2)
     df   chisq     CFI     TLI    RMSEA    AIC    BIC Chisq diff Df diff Power
[1,]  9  17.429 0.99178 0.98629 0.040731 7419.1 7495.0                         
[2,] 10 277.945 0.74162 0.61243 0.231235 7677.7 7749.3     260.52       1     1
     CFI diff TLI diff RMSEA diff AIC diff BIC diff
[1,]                                               
[2,] -0.25015 -0.37386    0.19051   258.52    254.3
> 
> 
> 
> cleanEx()
> nameEx("blankParameters")
> ### * blankParameters
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: blankParameters
> ### Title: Change all elements in the non-null objects to be all NAs.
> ### Aliases: blankParameters
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("centralMoment")
> ### * centralMoment
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: centralMoment
> ### Title: Calculate central moments of a variable
> ### Aliases: centralMoment
> 
> ### ** Examples
> 
> # This function is not public.
> 
> # centralMoment(1:5, 2)
> 
> 
> 
> cleanEx()
> nameEx("checkInputValue")
> ### * checkInputValue
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: checkInputValue
> ### Title: Check the value argument in the matrix, symmetric matrix, or
> ###   vector objects
> ### Aliases: checkInputValue checkInputValueVector
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("clean")
> ### * clean
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clean
> ### Title: Extract only converged replications in the result object
> ### Aliases: clean
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("collapseExo")
> ### * collapseExo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: collapseExo
> ### Title: Collapse all exogenous variables and put all in endogenous side
> ###   only.
> ### Aliases: collapseExo
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("combineLatentCorExoEndo")
> ### * combineLatentCorExoEndo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: combineLatentCorExoEndo
> ### Title: Combine exogenous factor correlation and endogenous factor
> ###   correlation into a single matrix
> ### Aliases: combineLatentCorExoEndo
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("combineLoadingExoEndo")
> ### * combineLoadingExoEndo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: combineLoadingExoEndo
> ### Title: Combine factor loading from the exogenous and endogenous sides
> ###   into a single matrix
> ### Aliases: combineLoadingExoEndo
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("combineMeasurementErrorExoEndo")
> ### * combineMeasurementErrorExoEndo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: combineMeasurementErrorExoEndo
> ### Title: Combine measurement error correlation from the exogenous and
> ###   endogenous sides into a single matrix
> ### Aliases: combineMeasurementErrorExoEndo
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("combineObject")
> ### * combineObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: combineObject
> ### Title: Combine by summing or binding two objects together.
> ### Aliases: combineObject combineObject-methods
> ###   combineObject,ANY,ANY-method combineObject,SimMatrix,SimMatrix-method
> ###   combineObject,SimVector,SimVector-method
> ###   combineObject,vector,vector-method combineObject,matrix,matrix-method
> ###   combineObject,MatrixSet,MatrixSet-method
> ###   combineObject,SimParam,list-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("combinePathExoEndo")
> ### * combinePathExoEndo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: combinePathExoEndo
> ### Title: Combine the regression coefficient matrices
> ### Aliases: combinePathExoEndo
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("constantVector")
> ### * constantVector
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: constantVector
> ### Title: Create a constant vector object
> ### Aliases: constantVector
> 
> ### ** Examples
> 
> # This function is not public.
> 
> # constantVector(0, 5)
> 
> 
> 
> cleanEx()
> nameEx("constrainMatrices")
> ### * constrainMatrices
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: constrainMatrices
> ### Title: Impose an equality constraint in an object
> ### Aliases: constrainMatrices constrainMatrices-methods
> ###   constrainMatrices,ANY,ANY-method
> ###   constrainMatrices,MatrixSet,SimEqualCon-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("continuousPower")
> ### * continuousPower
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: continuousPower
> ### Title: Find power of model parameters when simulations have randomly
> ###   varying parameters
> ### Aliases: continuousPower
> 
> ### ** Examples
> 
> # Specify Sample Size by n
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> # We will use only 5 replications to save time.
> # In reality, more replications are needed.
> 
> # Specify both sample size and percent missing completely at random
> Output <- simResult(NULL, SimData, SimModel, n=seq(100, 200, 20), pmMCAR=c(0, 0.1, 0.2))
> summary(Output)
RESULT OBJECT
Model Type
[1] "CFA"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi     13.442   15.459   15.572   15.597
      AIC   2768.933 2845.482 2964.830 2991.683
      BIC   2827.734 2903.239 3023.877 3051.021
      RMSEA    0.057    0.060    0.063    0.064
      CFI      0.979    0.973    0.971    0.971
      TLI      0.965    0.955    0.952    0.951
      SRMR     0.044    0.051    0.064    0.067
========= Parameter Estimates and Standard Errors ============
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0. Std.Est
LY1_1            0.697       0.087      0.083               1.000   0.693
LY2_1            0.715       0.077      0.083               1.000   0.713
LY3_1            0.689       0.110      0.083               1.000   0.699
LY4_1            0.665       0.098      0.083               1.000   0.668
LY5_1            0.712       0.075      0.084               1.000   0.705
LY6_1            0.676       0.101      0.083               1.000   0.683
TE1_1            0.521       0.082      0.080               1.000   0.518
TE2_2            0.490       0.079      0.078               1.000   0.489
TE3_3            0.487       0.094      0.077               1.000   0.507
TE4_4            0.538       0.096      0.080               1.000   0.548
TE5_5            0.507       0.066      0.080               1.000   0.500
TE6_6            0.511       0.077      0.078               1.000   0.530
TY1             -0.022       0.101      0.086               0.111  -0.020
TY2              0.008       0.089      0.086               0.111   0.008
TY3              0.008       0.111      0.085               0.111   0.008
TY4             -0.021       0.116      0.085               0.111  -0.023
TY5              0.013       0.094      0.087               0.056   0.014
TY6             -0.007       0.098      0.085               0.111  -0.006
      Std.Est.SD Average.Param Average.Bias Coverage r_coef.n r_se.n
LY1_1      0.051          0.70       -0.003    1.000    0.241 -0.848
LY2_1      0.051          0.70        0.015    0.889   -0.019 -0.758
LY3_1      0.074          0.70       -0.011    0.889    0.502 -0.647
LY4_1      0.080          0.70       -0.035    0.889    0.457 -0.804
LY5_1      0.049          0.70        0.012    0.944    0.077 -0.798
LY6_1      0.061          0.70       -0.024    0.889    0.399 -0.841
TE1_1      0.071          0.51        0.011    0.944   -0.160 -0.711
TE2_2      0.072          0.51       -0.020    0.944    0.298 -0.511
TE3_3      0.097          0.51       -0.023    0.833    0.027 -0.444
TE4_4      0.102          0.51        0.028    0.889   -0.007 -0.559
TE5_5      0.070          0.51       -0.003    1.000    0.391 -0.574
TE6_6      0.083          0.51        0.001    0.944    0.049 -0.645
TY1        0.097          0.00       -0.022    0.889    0.025 -0.840
TY2        0.087          0.00        0.008    0.889    0.092 -0.825
TY3        0.115          0.00        0.008    0.889    0.007 -0.701
TY4        0.116          0.00       -0.021    0.889    0.266 -0.892
TY5        0.096          0.00        0.013    0.944   -0.222 -0.899
TY6        0.099          0.00       -0.007    0.889    0.062 -0.831
      r_coef.pmMCAR r_se.pmMCAR
LY1_1        -0.261       0.188
LY2_1         0.032       0.460
LY3_1        -0.162       0.477
LY4_1        -0.427       0.340
LY5_1        -0.387       0.508
LY6_1        -0.290       0.365
TE1_1        -0.354       0.093
TE2_2         0.122       0.534
TE3_3         0.123       0.472
TE4_4         0.125       0.393
TE5_5         0.174       0.588
TE6_6        -0.195       0.288
TY1          -0.058      -0.019
TY2           0.232       0.315
TY3           0.303       0.273
TY4           0.114       0.069
TY5           0.066       0.190
TY6           0.177       0.056
========= Correlation between Fit Indices ============
          Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR      n pmMCAR
Chi     1.000 -0.022 -0.022  0.928 -0.801 -0.907  0.628  0.014  0.148
AIC    -0.022  1.000  1.000 -0.119  0.245 -0.008 -0.562  0.922 -0.362
BIC    -0.022  1.000  1.000 -0.119  0.244 -0.009 -0.562  0.923 -0.359
RMSEA   0.928 -0.119 -0.119  1.000 -0.884 -0.862  0.679 -0.100  0.192
CFI    -0.801  0.245  0.244 -0.884  1.000  0.848 -0.880  0.159 -0.407
TLI    -0.907 -0.008 -0.009 -0.862  0.848  1.000 -0.736 -0.023 -0.142
SRMR    0.628 -0.562 -0.562  0.679 -0.880 -0.736  1.000 -0.456  0.497
n       0.014  0.922  0.923 -0.100  0.159 -0.023 -0.456  1.000  0.000
pmMCAR  0.148 -0.362 -0.359  0.192 -0.407 -0.142  0.497  0.000  1.000
================== Replications =====================
Number of Replications
[1] 18
Number of Converged Replications
[1] 18
NOTE: The sample size is varying.
NOTE: The percent of MCAR is varying.
> 
> Cpow <- continuousPower(Output, contN = TRUE, contMCAR = TRUE)
> Cpow
       N MCAR LY1_1 LY2_1 LY3_1 LY4_1 LY5_1 LY6_1 TE1_1 TE2_2 TE3_3 TE4_4 TE5_5
1    100 0.00     1     1     1     1     1     1     1     1     1     1     1
2    101 0.00     1     1     1     1     1     1     1     1     1     1     1
3    102 0.00     1     1     1     1     1     1     1     1     1     1     1
4    103 0.00     1     1     1     1     1     1     1     1     1     1     1
5    104 0.00     1     1     1     1     1     1     1     1     1     1     1
6    105 0.00     1     1     1     1     1     1     1     1     1     1     1
7    106 0.00     1     1     1     1     1     1     1     1     1     1     1
8    107 0.00     1     1     1     1     1     1     1     1     1     1     1
9    108 0.00     1     1     1     1     1     1     1     1     1     1     1
10   109 0.00     1     1     1     1     1     1     1     1     1     1     1
11   110 0.00     1     1     1     1     1     1     1     1     1     1     1
12   111 0.00     1     1     1     1     1     1     1     1     1     1     1
13   112 0.00     1     1     1     1     1     1     1     1     1     1     1
14   113 0.00     1     1     1     1     1     1     1     1     1     1     1
15   114 0.00     1     1     1     1     1     1     1     1     1     1     1
16   115 0.00     1     1     1     1     1     1     1     1     1     1     1
17   116 0.00     1     1     1     1     1     1     1     1     1     1     1
18   117 0.00     1     1     1     1     1     1     1     1     1     1     1
19   118 0.00     1     1     1     1     1     1     1     1     1     1     1
20   119 0.00     1     1     1     1     1     1     1     1     1     1     1
21   120 0.00     1     1     1     1     1     1     1     1     1     1     1
22   121 0.00     1     1     1     1     1     1     1     1     1     1     1
23   122 0.00     1     1     1     1     1     1     1     1     1     1     1
24   123 0.00     1     1     1     1     1     1     1     1     1     1     1
25   124 0.00     1     1     1     1     1     1     1     1     1     1     1
26   125 0.00     1     1     1     1     1     1     1     1     1     1     1
27   126 0.00     1     1     1     1     1     1     1     1     1     1     1
28   127 0.00     1     1     1     1     1     1     1     1     1     1     1
29   128 0.00     1     1     1     1     1     1     1     1     1     1     1
30   129 0.00     1     1     1     1     1     1     1     1     1     1     1
31   130 0.00     1     1     1     1     1     1     1     1     1     1     1
32   131 0.00     1     1     1     1     1     1     1     1     1     1     1
33   132 0.00     1     1     1     1     1     1     1     1     1     1     1
34   133 0.00     1     1     1     1     1     1     1     1     1     1     1
35   134 0.00     1     1     1     1     1     1     1     1     1     1     1
36   135 0.00     1     1     1     1     1     1     1     1     1     1     1
37   136 0.00     1     1     1     1     1     1     1     1     1     1     1
38   137 0.00     1     1     1     1     1     1     1     1     1     1     1
39   138 0.00     1     1     1     1     1     1     1     1     1     1     1
40   139 0.00     1     1     1     1     1     1     1     1     1     1     1
41   140 0.00     1     1     1     1     1     1     1     1     1     1     1
42   141 0.00     1     1     1     1     1     1     1     1     1     1     1
43   142 0.00     1     1     1     1     1     1     1     1     1     1     1
44   143 0.00     1     1     1     1     1     1     1     1     1     1     1
45   144 0.00     1     1     1     1     1     1     1     1     1     1     1
46   145 0.00     1     1     1     1     1     1     1     1     1     1     1
47   146 0.00     1     1     1     1     1     1     1     1     1     1     1
48   147 0.00     1     1     1     1     1     1     1     1     1     1     1
49   148 0.00     1     1     1     1     1     1     1     1     1     1     1
50   149 0.00     1     1     1     1     1     1     1     1     1     1     1
51   150 0.00     1     1     1     1     1     1     1     1     1     1     1
52   151 0.00     1     1     1     1     1     1     1     1     1     1     1
53   152 0.00     1     1     1     1     1     1     1     1     1     1     1
54   153 0.00     1     1     1     1     1     1     1     1     1     1     1
55   154 0.00     1     1     1     1     1     1     1     1     1     1     1
56   155 0.00     1     1     1     1     1     1     1     1     1     1     1
57   156 0.00     1     1     1     1     1     1     1     1     1     1     1
58   157 0.00     1     1     1     1     1     1     1     1     1     1     1
59   158 0.00     1     1     1     1     1     1     1     1     1     1     1
60   159 0.00     1     1     1     1     1     1     1     1     1     1     1
61   160 0.00     1     1     1     1     1     1     1     1     1     1     1
62   161 0.00     1     1     1     1     1     1     1     1     1     1     1
63   162 0.00     1     1     1     1     1     1     1     1     1     1     1
64   163 0.00     1     1     1     1     1     1     1     1     1     1     1
65   164 0.00     1     1     1     1     1     1     1     1     1     1     1
66   165 0.00     1     1     1     1     1     1     1     1     1     1     1
67   166 0.00     1     1     1     1     1     1     1     1     1     1     1
68   167 0.00     1     1     1     1     1     1     1     1     1     1     1
69   168 0.00     1     1     1     1     1     1     1     1     1     1     1
70   169 0.00     1     1     1     1     1     1     1     1     1     1     1
71   170 0.00     1     1     1     1     1     1     1     1     1     1     1
72   171 0.00     1     1     1     1     1     1     1     1     1     1     1
73   172 0.00     1     1     1     1     1     1     1     1     1     1     1
74   173 0.00     1     1     1     1     1     1     1     1     1     1     1
75   174 0.00     1     1     1     1     1     1     1     1     1     1     1
76   175 0.00     1     1     1     1     1     1     1     1     1     1     1
77   176 0.00     1     1     1     1     1     1     1     1     1     1     1
78   177 0.00     1     1     1     1     1     1     1     1     1     1     1
79   178 0.00     1     1     1     1     1     1     1     1     1     1     1
80   179 0.00     1     1     1     1     1     1     1     1     1     1     1
81   180 0.00     1     1     1     1     1     1     1     1     1     1     1
82   181 0.00     1     1     1     1     1     1     1     1     1     1     1
83   182 0.00     1     1     1     1     1     1     1     1     1     1     1
84   183 0.00     1     1     1     1     1     1     1     1     1     1     1
85   184 0.00     1     1     1     1     1     1     1     1     1     1     1
86   185 0.00     1     1     1     1     1     1     1     1     1     1     1
87   186 0.00     1     1     1     1     1     1     1     1     1     1     1
88   187 0.00     1     1     1     1     1     1     1     1     1     1     1
89   188 0.00     1     1     1     1     1     1     1     1     1     1     1
90   189 0.00     1     1     1     1     1     1     1     1     1     1     1
91   190 0.00     1     1     1     1     1     1     1     1     1     1     1
92   191 0.00     1     1     1     1     1     1     1     1     1     1     1
93   192 0.00     1     1     1     1     1     1     1     1     1     1     1
94   193 0.00     1     1     1     1     1     1     1     1     1     1     1
95   194 0.00     1     1     1     1     1     1     1     1     1     1     1
96   195 0.00     1     1     1     1     1     1     1     1     1     1     1
97   196 0.00     1     1     1     1     1     1     1     1     1     1     1
98   197 0.00     1     1     1     1     1     1     1     1     1     1     1
99   198 0.00     1     1     1     1     1     1     1     1     1     1     1
100  199 0.00     1     1     1     1     1     1     1     1     1     1     1
101  200 0.00     1     1     1     1     1     1     1     1     1     1     1
102  100 0.01     1     1     1     1     1     1     1     1     1     1     1
103  101 0.01     1     1     1     1     1     1     1     1     1     1     1
104  102 0.01     1     1     1     1     1     1     1     1     1     1     1
105  103 0.01     1     1     1     1     1     1     1     1     1     1     1
106  104 0.01     1     1     1     1     1     1     1     1     1     1     1
107  105 0.01     1     1     1     1     1     1     1     1     1     1     1
108  106 0.01     1     1     1     1     1     1     1     1     1     1     1
109  107 0.01     1     1     1     1     1     1     1     1     1     1     1
110  108 0.01     1     1     1     1     1     1     1     1     1     1     1
111  109 0.01     1     1     1     1     1     1     1     1     1     1     1
112  110 0.01     1     1     1     1     1     1     1     1     1     1     1
113  111 0.01     1     1     1     1     1     1     1     1     1     1     1
114  112 0.01     1     1     1     1     1     1     1     1     1     1     1
115  113 0.01     1     1     1     1     1     1     1     1     1     1     1
116  114 0.01     1     1     1     1     1     1     1     1     1     1     1
117  115 0.01     1     1     1     1     1     1     1     1     1     1     1
118  116 0.01     1     1     1     1     1     1     1     1     1     1     1
119  117 0.01     1     1     1     1     1     1     1     1     1     1     1
120  118 0.01     1     1     1     1     1     1     1     1     1     1     1
121  119 0.01     1     1     1     1     1     1     1     1     1     1     1
122  120 0.01     1     1     1     1     1     1     1     1     1     1     1
123  121 0.01     1     1     1     1     1     1     1     1     1     1     1
124  122 0.01     1     1     1     1     1     1     1     1     1     1     1
125  123 0.01     1     1     1     1     1     1     1     1     1     1     1
126  124 0.01     1     1     1     1     1     1     1     1     1     1     1
127  125 0.01     1     1     1     1     1     1     1     1     1     1     1
128  126 0.01     1     1     1     1     1     1     1     1     1     1     1
129  127 0.01     1     1     1     1     1     1     1     1     1     1     1
130  128 0.01     1     1     1     1     1     1     1     1     1     1     1
131  129 0.01     1     1     1     1     1     1     1     1     1     1     1
132  130 0.01     1     1     1     1     1     1     1     1     1     1     1
133  131 0.01     1     1     1     1     1     1     1     1     1     1     1
134  132 0.01     1     1     1     1     1     1     1     1     1     1     1
135  133 0.01     1     1     1     1     1     1     1     1     1     1     1
136  134 0.01     1     1     1     1     1     1     1     1     1     1     1
137  135 0.01     1     1     1     1     1     1     1     1     1     1     1
138  136 0.01     1     1     1     1     1     1     1     1     1     1     1
139  137 0.01     1     1     1     1     1     1     1     1     1     1     1
140  138 0.01     1     1     1     1     1     1     1     1     1     1     1
141  139 0.01     1     1     1     1     1     1     1     1     1     1     1
142  140 0.01     1     1     1     1     1     1     1     1     1     1     1
143  141 0.01     1     1     1     1     1     1     1     1     1     1     1
144  142 0.01     1     1     1     1     1     1     1     1     1     1     1
145  143 0.01     1     1     1     1     1     1     1     1     1     1     1
146  144 0.01     1     1     1     1     1     1     1     1     1     1     1
147  145 0.01     1     1     1     1     1     1     1     1     1     1     1
148  146 0.01     1     1     1     1     1     1     1     1     1     1     1
149  147 0.01     1     1     1     1     1     1     1     1     1     1     1
150  148 0.01     1     1     1     1     1     1     1     1     1     1     1
151  149 0.01     1     1     1     1     1     1     1     1     1     1     1
152  150 0.01     1     1     1     1     1     1     1     1     1     1     1
153  151 0.01     1     1     1     1     1     1     1     1     1     1     1
154  152 0.01     1     1     1     1     1     1     1     1     1     1     1
155  153 0.01     1     1     1     1     1     1     1     1     1     1     1
156  154 0.01     1     1     1     1     1     1     1     1     1     1     1
157  155 0.01     1     1     1     1     1     1     1     1     1     1     1
158  156 0.01     1     1     1     1     1     1     1     1     1     1     1
159  157 0.01     1     1     1     1     1     1     1     1     1     1     1
160  158 0.01     1     1     1     1     1     1     1     1     1     1     1
161  159 0.01     1     1     1     1     1     1     1     1     1     1     1
162  160 0.01     1     1     1     1     1     1     1     1     1     1     1
163  161 0.01     1     1     1     1     1     1     1     1     1     1     1
164  162 0.01     1     1     1     1     1     1     1     1     1     1     1
165  163 0.01     1     1     1     1     1     1     1     1     1     1     1
166  164 0.01     1     1     1     1     1     1     1     1     1     1     1
167  165 0.01     1     1     1     1     1     1     1     1     1     1     1
168  166 0.01     1     1     1     1     1     1     1     1     1     1     1
169  167 0.01     1     1     1     1     1     1     1     1     1     1     1
170  168 0.01     1     1     1     1     1     1     1     1     1     1     1
171  169 0.01     1     1     1     1     1     1     1     1     1     1     1
172  170 0.01     1     1     1     1     1     1     1     1     1     1     1
173  171 0.01     1     1     1     1     1     1     1     1     1     1     1
174  172 0.01     1     1     1     1     1     1     1     1     1     1     1
175  173 0.01     1     1     1     1     1     1     1     1     1     1     1
176  174 0.01     1     1     1     1     1     1     1     1     1     1     1
177  175 0.01     1     1     1     1     1     1     1     1     1     1     1
178  176 0.01     1     1     1     1     1     1     1     1     1     1     1
179  177 0.01     1     1     1     1     1     1     1     1     1     1     1
180  178 0.01     1     1     1     1     1     1     1     1     1     1     1
181  179 0.01     1     1     1     1     1     1     1     1     1     1     1
182  180 0.01     1     1     1     1     1     1     1     1     1     1     1
183  181 0.01     1     1     1     1     1     1     1     1     1     1     1
184  182 0.01     1     1     1     1     1     1     1     1     1     1     1
185  183 0.01     1     1     1     1     1     1     1     1     1     1     1
186  184 0.01     1     1     1     1     1     1     1     1     1     1     1
187  185 0.01     1     1     1     1     1     1     1     1     1     1     1
188  186 0.01     1     1     1     1     1     1     1     1     1     1     1
189  187 0.01     1     1     1     1     1     1     1     1     1     1     1
190  188 0.01     1     1     1     1     1     1     1     1     1     1     1
191  189 0.01     1     1     1     1     1     1     1     1     1     1     1
192  190 0.01     1     1     1     1     1     1     1     1     1     1     1
193  191 0.01     1     1     1     1     1     1     1     1     1     1     1
194  192 0.01     1     1     1     1     1     1     1     1     1     1     1
195  193 0.01     1     1     1     1     1     1     1     1     1     1     1
196  194 0.01     1     1     1     1     1     1     1     1     1     1     1
197  195 0.01     1     1     1     1     1     1     1     1     1     1     1
198  196 0.01     1     1     1     1     1     1     1     1     1     1     1
199  197 0.01     1     1     1     1     1     1     1     1     1     1     1
200  198 0.01     1     1     1     1     1     1     1     1     1     1     1
201  199 0.01     1     1     1     1     1     1     1     1     1     1     1
202  200 0.01     1     1     1     1     1     1     1     1     1     1     1
203  100 0.02     1     1     1     1     1     1     1     1     1     1     1
204  101 0.02     1     1     1     1     1     1     1     1     1     1     1
205  102 0.02     1     1     1     1     1     1     1     1     1     1     1
206  103 0.02     1     1     1     1     1     1     1     1     1     1     1
207  104 0.02     1     1     1     1     1     1     1     1     1     1     1
208  105 0.02     1     1     1     1     1     1     1     1     1     1     1
209  106 0.02     1     1     1     1     1     1     1     1     1     1     1
210  107 0.02     1     1     1     1     1     1     1     1     1     1     1
211  108 0.02     1     1     1     1     1     1     1     1     1     1     1
212  109 0.02     1     1     1     1     1     1     1     1     1     1     1
213  110 0.02     1     1     1     1     1     1     1     1     1     1     1
214  111 0.02     1     1     1     1     1     1     1     1     1     1     1
215  112 0.02     1     1     1     1     1     1     1     1     1     1     1
216  113 0.02     1     1     1     1     1     1     1     1     1     1     1
217  114 0.02     1     1     1     1     1     1     1     1     1     1     1
218  115 0.02     1     1     1     1     1     1     1     1     1     1     1
219  116 0.02     1     1     1     1     1     1     1     1     1     1     1
220  117 0.02     1     1     1     1     1     1     1     1     1     1     1
221  118 0.02     1     1     1     1     1     1     1     1     1     1     1
222  119 0.02     1     1     1     1     1     1     1     1     1     1     1
223  120 0.02     1     1     1     1     1     1     1     1     1     1     1
224  121 0.02     1     1     1     1     1     1     1     1     1     1     1
225  122 0.02     1     1     1     1     1     1     1     1     1     1     1
226  123 0.02     1     1     1     1     1     1     1     1     1     1     1
227  124 0.02     1     1     1     1     1     1     1     1     1     1     1
228  125 0.02     1     1     1     1     1     1     1     1     1     1     1
229  126 0.02     1     1     1     1     1     1     1     1     1     1     1
230  127 0.02     1     1     1     1     1     1     1     1     1     1     1
231  128 0.02     1     1     1     1     1     1     1     1     1     1     1
232  129 0.02     1     1     1     1     1     1     1     1     1     1     1
233  130 0.02     1     1     1     1     1     1     1     1     1     1     1
234  131 0.02     1     1     1     1     1     1     1     1     1     1     1
235  132 0.02     1     1     1     1     1     1     1     1     1     1     1
236  133 0.02     1     1     1     1     1     1     1     1     1     1     1
237  134 0.02     1     1     1     1     1     1     1     1     1     1     1
238  135 0.02     1     1     1     1     1     1     1     1     1     1     1
239  136 0.02     1     1     1     1     1     1     1     1     1     1     1
240  137 0.02     1     1     1     1     1     1     1     1     1     1     1
241  138 0.02     1     1     1     1     1     1     1     1     1     1     1
242  139 0.02     1     1     1     1     1     1     1     1     1     1     1
243  140 0.02     1     1     1     1     1     1     1     1     1     1     1
244  141 0.02     1     1     1     1     1     1     1     1     1     1     1
245  142 0.02     1     1     1     1     1     1     1     1     1     1     1
246  143 0.02     1     1     1     1     1     1     1     1     1     1     1
247  144 0.02     1     1     1     1     1     1     1     1     1     1     1
248  145 0.02     1     1     1     1     1     1     1     1     1     1     1
249  146 0.02     1     1     1     1     1     1     1     1     1     1     1
250  147 0.02     1     1     1     1     1     1     1     1     1     1     1
251  148 0.02     1     1     1     1     1     1     1     1     1     1     1
252  149 0.02     1     1     1     1     1     1     1     1     1     1     1
253  150 0.02     1     1     1     1     1     1     1     1     1     1     1
254  151 0.02     1     1     1     1     1     1     1     1     1     1     1
255  152 0.02     1     1     1     1     1     1     1     1     1     1     1
256  153 0.02     1     1     1     1     1     1     1     1     1     1     1
257  154 0.02     1     1     1     1     1     1     1     1     1     1     1
258  155 0.02     1     1     1     1     1     1     1     1     1     1     1
259  156 0.02     1     1     1     1     1     1     1     1     1     1     1
260  157 0.02     1     1     1     1     1     1     1     1     1     1     1
261  158 0.02     1     1     1     1     1     1     1     1     1     1     1
262  159 0.02     1     1     1     1     1     1     1     1     1     1     1
263  160 0.02     1     1     1     1     1     1     1     1     1     1     1
264  161 0.02     1     1     1     1     1     1     1     1     1     1     1
265  162 0.02     1     1     1     1     1     1     1     1     1     1     1
266  163 0.02     1     1     1     1     1     1     1     1     1     1     1
267  164 0.02     1     1     1     1     1     1     1     1     1     1     1
268  165 0.02     1     1     1     1     1     1     1     1     1     1     1
269  166 0.02     1     1     1     1     1     1     1     1     1     1     1
270  167 0.02     1     1     1     1     1     1     1     1     1     1     1
271  168 0.02     1     1     1     1     1     1     1     1     1     1     1
272  169 0.02     1     1     1     1     1     1     1     1     1     1     1
273  170 0.02     1     1     1     1     1     1     1     1     1     1     1
274  171 0.02     1     1     1     1     1     1     1     1     1     1     1
275  172 0.02     1     1     1     1     1     1     1     1     1     1     1
276  173 0.02     1     1     1     1     1     1     1     1     1     1     1
277  174 0.02     1     1     1     1     1     1     1     1     1     1     1
278  175 0.02     1     1     1     1     1     1     1     1     1     1     1
279  176 0.02     1     1     1     1     1     1     1     1     1     1     1
280  177 0.02     1     1     1     1     1     1     1     1     1     1     1
281  178 0.02     1     1     1     1     1     1     1     1     1     1     1
282  179 0.02     1     1     1     1     1     1     1     1     1     1     1
283  180 0.02     1     1     1     1     1     1     1     1     1     1     1
284  181 0.02     1     1     1     1     1     1     1     1     1     1     1
285  182 0.02     1     1     1     1     1     1     1     1     1     1     1
286  183 0.02     1     1     1     1     1     1     1     1     1     1     1
287  184 0.02     1     1     1     1     1     1     1     1     1     1     1
288  185 0.02     1     1     1     1     1     1     1     1     1     1     1
289  186 0.02     1     1     1     1     1     1     1     1     1     1     1
290  187 0.02     1     1     1     1     1     1     1     1     1     1     1
291  188 0.02     1     1     1     1     1     1     1     1     1     1     1
292  189 0.02     1     1     1     1     1     1     1     1     1     1     1
293  190 0.02     1     1     1     1     1     1     1     1     1     1     1
294  191 0.02     1     1     1     1     1     1     1     1     1     1     1
295  192 0.02     1     1     1     1     1     1     1     1     1     1     1
296  193 0.02     1     1     1     1     1     1     1     1     1     1     1
297  194 0.02     1     1     1     1     1     1     1     1     1     1     1
298  195 0.02     1     1     1     1     1     1     1     1     1     1     1
299  196 0.02     1     1     1     1     1     1     1     1     1     1     1
300  197 0.02     1     1     1     1     1     1     1     1     1     1     1
301  198 0.02     1     1     1     1     1     1     1     1     1     1     1
302  199 0.02     1     1     1     1     1     1     1     1     1     1     1
303  200 0.02     1     1     1     1     1     1     1     1     1     1     1
304  100 0.03     1     1     1     1     1     1     1     1     1     1     1
305  101 0.03     1     1     1     1     1     1     1     1     1     1     1
306  102 0.03     1     1     1     1     1     1     1     1     1     1     1
307  103 0.03     1     1     1     1     1     1     1     1     1     1     1
308  104 0.03     1     1     1     1     1     1     1     1     1     1     1
309  105 0.03     1     1     1     1     1     1     1     1     1     1     1
310  106 0.03     1     1     1     1     1     1     1     1     1     1     1
311  107 0.03     1     1     1     1     1     1     1     1     1     1     1
312  108 0.03     1     1     1     1     1     1     1     1     1     1     1
313  109 0.03     1     1     1     1     1     1     1     1     1     1     1
314  110 0.03     1     1     1     1     1     1     1     1     1     1     1
315  111 0.03     1     1     1     1     1     1     1     1     1     1     1
316  112 0.03     1     1     1     1     1     1     1     1     1     1     1
317  113 0.03     1     1     1     1     1     1     1     1     1     1     1
318  114 0.03     1     1     1     1     1     1     1     1     1     1     1
319  115 0.03     1     1     1     1     1     1     1     1     1     1     1
320  116 0.03     1     1     1     1     1     1     1     1     1     1     1
321  117 0.03     1     1     1     1     1     1     1     1     1     1     1
322  118 0.03     1     1     1     1     1     1     1     1     1     1     1
323  119 0.03     1     1     1     1     1     1     1     1     1     1     1
324  120 0.03     1     1     1     1     1     1     1     1     1     1     1
325  121 0.03     1     1     1     1     1     1     1     1     1     1     1
326  122 0.03     1     1     1     1     1     1     1     1     1     1     1
327  123 0.03     1     1     1     1     1     1     1     1     1     1     1
328  124 0.03     1     1     1     1     1     1     1     1     1     1     1
329  125 0.03     1     1     1     1     1     1     1     1     1     1     1
330  126 0.03     1     1     1     1     1     1     1     1     1     1     1
331  127 0.03     1     1     1     1     1     1     1     1     1     1     1
332  128 0.03     1     1     1     1     1     1     1     1     1     1     1
333  129 0.03     1     1     1     1     1     1     1     1     1     1     1
334  130 0.03     1     1     1     1     1     1     1     1     1     1     1
335  131 0.03     1     1     1     1     1     1     1     1     1     1     1
336  132 0.03     1     1     1     1     1     1     1     1     1     1     1
337  133 0.03     1     1     1     1     1     1     1     1     1     1     1
338  134 0.03     1     1     1     1     1     1     1     1     1     1     1
339  135 0.03     1     1     1     1     1     1     1     1     1     1     1
340  136 0.03     1     1     1     1     1     1     1     1     1     1     1
341  137 0.03     1     1     1     1     1     1     1     1     1     1     1
342  138 0.03     1     1     1     1     1     1     1     1     1     1     1
343  139 0.03     1     1     1     1     1     1     1     1     1     1     1
344  140 0.03     1     1     1     1     1     1     1     1     1     1     1
345  141 0.03     1     1     1     1     1     1     1     1     1     1     1
346  142 0.03     1     1     1     1     1     1     1     1     1     1     1
347  143 0.03     1     1     1     1     1     1     1     1     1     1     1
348  144 0.03     1     1     1     1     1     1     1     1     1     1     1
349  145 0.03     1     1     1     1     1     1     1     1     1     1     1
350  146 0.03     1     1     1     1     1     1     1     1     1     1     1
351  147 0.03     1     1     1     1     1     1     1     1     1     1     1
352  148 0.03     1     1     1     1     1     1     1     1     1     1     1
353  149 0.03     1     1     1     1     1     1     1     1     1     1     1
354  150 0.03     1     1     1     1     1     1     1     1     1     1     1
355  151 0.03     1     1     1     1     1     1     1     1     1     1     1
356  152 0.03     1     1     1     1     1     1     1     1     1     1     1
357  153 0.03     1     1     1     1     1     1     1     1     1     1     1
358  154 0.03     1     1     1     1     1     1     1     1     1     1     1
359  155 0.03     1     1     1     1     1     1     1     1     1     1     1
360  156 0.03     1     1     1     1     1     1     1     1     1     1     1
361  157 0.03     1     1     1     1     1     1     1     1     1     1     1
362  158 0.03     1     1     1     1     1     1     1     1     1     1     1
363  159 0.03     1     1     1     1     1     1     1     1     1     1     1
364  160 0.03     1     1     1     1     1     1     1     1     1     1     1
365  161 0.03     1     1     1     1     1     1     1     1     1     1     1
366  162 0.03     1     1     1     1     1     1     1     1     1     1     1
367  163 0.03     1     1     1     1     1     1     1     1     1     1     1
368  164 0.03     1     1     1     1     1     1     1     1     1     1     1
369  165 0.03     1     1     1     1     1     1     1     1     1     1     1
370  166 0.03     1     1     1     1     1     1     1     1     1     1     1
371  167 0.03     1     1     1     1     1     1     1     1     1     1     1
372  168 0.03     1     1     1     1     1     1     1     1     1     1     1
373  169 0.03     1     1     1     1     1     1     1     1     1     1     1
374  170 0.03     1     1     1     1     1     1     1     1     1     1     1
375  171 0.03     1     1     1     1     1     1     1     1     1     1     1
376  172 0.03     1     1     1     1     1     1     1     1     1     1     1
377  173 0.03     1     1     1     1     1     1     1     1     1     1     1
378  174 0.03     1     1     1     1     1     1     1     1     1     1     1
379  175 0.03     1     1     1     1     1     1     1     1     1     1     1
380  176 0.03     1     1     1     1     1     1     1     1     1     1     1
381  177 0.03     1     1     1     1     1     1     1     1     1     1     1
382  178 0.03     1     1     1     1     1     1     1     1     1     1     1
383  179 0.03     1     1     1     1     1     1     1     1     1     1     1
384  180 0.03     1     1     1     1     1     1     1     1     1     1     1
385  181 0.03     1     1     1     1     1     1     1     1     1     1     1
386  182 0.03     1     1     1     1     1     1     1     1     1     1     1
387  183 0.03     1     1     1     1     1     1     1     1     1     1     1
388  184 0.03     1     1     1     1     1     1     1     1     1     1     1
389  185 0.03     1     1     1     1     1     1     1     1     1     1     1
390  186 0.03     1     1     1     1     1     1     1     1     1     1     1
391  187 0.03     1     1     1     1     1     1     1     1     1     1     1
392  188 0.03     1     1     1     1     1     1     1     1     1     1     1
393  189 0.03     1     1     1     1     1     1     1     1     1     1     1
394  190 0.03     1     1     1     1     1     1     1     1     1     1     1
395  191 0.03     1     1     1     1     1     1     1     1     1     1     1
396  192 0.03     1     1     1     1     1     1     1     1     1     1     1
397  193 0.03     1     1     1     1     1     1     1     1     1     1     1
398  194 0.03     1     1     1     1     1     1     1     1     1     1     1
399  195 0.03     1     1     1     1     1     1     1     1     1     1     1
400  196 0.03     1     1     1     1     1     1     1     1     1     1     1
401  197 0.03     1     1     1     1     1     1     1     1     1     1     1
402  198 0.03     1     1     1     1     1     1     1     1     1     1     1
403  199 0.03     1     1     1     1     1     1     1     1     1     1     1
404  200 0.03     1     1     1     1     1     1     1     1     1     1     1
405  100 0.04     1     1     1     1     1     1     1     1     1     1     1
406  101 0.04     1     1     1     1     1     1     1     1     1     1     1
407  102 0.04     1     1     1     1     1     1     1     1     1     1     1
408  103 0.04     1     1     1     1     1     1     1     1     1     1     1
409  104 0.04     1     1     1     1     1     1     1     1     1     1     1
410  105 0.04     1     1     1     1     1     1     1     1     1     1     1
411  106 0.04     1     1     1     1     1     1     1     1     1     1     1
412  107 0.04     1     1     1     1     1     1     1     1     1     1     1
413  108 0.04     1     1     1     1     1     1     1     1     1     1     1
414  109 0.04     1     1     1     1     1     1     1     1     1     1     1
415  110 0.04     1     1     1     1     1     1     1     1     1     1     1
416  111 0.04     1     1     1     1     1     1     1     1     1     1     1
417  112 0.04     1     1     1     1     1     1     1     1     1     1     1
418  113 0.04     1     1     1     1     1     1     1     1     1     1     1
419  114 0.04     1     1     1     1     1     1     1     1     1     1     1
420  115 0.04     1     1     1     1     1     1     1     1     1     1     1
421  116 0.04     1     1     1     1     1     1     1     1     1     1     1
422  117 0.04     1     1     1     1     1     1     1     1     1     1     1
423  118 0.04     1     1     1     1     1     1     1     1     1     1     1
424  119 0.04     1     1     1     1     1     1     1     1     1     1     1
425  120 0.04     1     1     1     1     1     1     1     1     1     1     1
426  121 0.04     1     1     1     1     1     1     1     1     1     1     1
427  122 0.04     1     1     1     1     1     1     1     1     1     1     1
428  123 0.04     1     1     1     1     1     1     1     1     1     1     1
429  124 0.04     1     1     1     1     1     1     1     1     1     1     1
430  125 0.04     1     1     1     1     1     1     1     1     1     1     1
431  126 0.04     1     1     1     1     1     1     1     1     1     1     1
432  127 0.04     1     1     1     1     1     1     1     1     1     1     1
433  128 0.04     1     1     1     1     1     1     1     1     1     1     1
434  129 0.04     1     1     1     1     1     1     1     1     1     1     1
435  130 0.04     1     1     1     1     1     1     1     1     1     1     1
436  131 0.04     1     1     1     1     1     1     1     1     1     1     1
437  132 0.04     1     1     1     1     1     1     1     1     1     1     1
438  133 0.04     1     1     1     1     1     1     1     1     1     1     1
439  134 0.04     1     1     1     1     1     1     1     1     1     1     1
440  135 0.04     1     1     1     1     1     1     1     1     1     1     1
441  136 0.04     1     1     1     1     1     1     1     1     1     1     1
442  137 0.04     1     1     1     1     1     1     1     1     1     1     1
443  138 0.04     1     1     1     1     1     1     1     1     1     1     1
444  139 0.04     1     1     1     1     1     1     1     1     1     1     1
445  140 0.04     1     1     1     1     1     1     1     1     1     1     1
446  141 0.04     1     1     1     1     1     1     1     1     1     1     1
447  142 0.04     1     1     1     1     1     1     1     1     1     1     1
448  143 0.04     1     1     1     1     1     1     1     1     1     1     1
449  144 0.04     1     1     1     1     1     1     1     1     1     1     1
450  145 0.04     1     1     1     1     1     1     1     1     1     1     1
451  146 0.04     1     1     1     1     1     1     1     1     1     1     1
452  147 0.04     1     1     1     1     1     1     1     1     1     1     1
453  148 0.04     1     1     1     1     1     1     1     1     1     1     1
454  149 0.04     1     1     1     1     1     1     1     1     1     1     1
455  150 0.04     1     1     1     1     1     1     1     1     1     1     1
456  151 0.04     1     1     1     1     1     1     1     1     1     1     1
457  152 0.04     1     1     1     1     1     1     1     1     1     1     1
458  153 0.04     1     1     1     1     1     1     1     1     1     1     1
459  154 0.04     1     1     1     1     1     1     1     1     1     1     1
460  155 0.04     1     1     1     1     1     1     1     1     1     1     1
461  156 0.04     1     1     1     1     1     1     1     1     1     1     1
462  157 0.04     1     1     1     1     1     1     1     1     1     1     1
463  158 0.04     1     1     1     1     1     1     1     1     1     1     1
464  159 0.04     1     1     1     1     1     1     1     1     1     1     1
465  160 0.04     1     1     1     1     1     1     1     1     1     1     1
466  161 0.04     1     1     1     1     1     1     1     1     1     1     1
467  162 0.04     1     1     1     1     1     1     1     1     1     1     1
468  163 0.04     1     1     1     1     1     1     1     1     1     1     1
469  164 0.04     1     1     1     1     1     1     1     1     1     1     1
470  165 0.04     1     1     1     1     1     1     1     1     1     1     1
471  166 0.04     1     1     1     1     1     1     1     1     1     1     1
472  167 0.04     1     1     1     1     1     1     1     1     1     1     1
473  168 0.04     1     1     1     1     1     1     1     1     1     1     1
474  169 0.04     1     1     1     1     1     1     1     1     1     1     1
475  170 0.04     1     1     1     1     1     1     1     1     1     1     1
476  171 0.04     1     1     1     1     1     1     1     1     1     1     1
477  172 0.04     1     1     1     1     1     1     1     1     1     1     1
478  173 0.04     1     1     1     1     1     1     1     1     1     1     1
479  174 0.04     1     1     1     1     1     1     1     1     1     1     1
480  175 0.04     1     1     1     1     1     1     1     1     1     1     1
481  176 0.04     1     1     1     1     1     1     1     1     1     1     1
482  177 0.04     1     1     1     1     1     1     1     1     1     1     1
483  178 0.04     1     1     1     1     1     1     1     1     1     1     1
484  179 0.04     1     1     1     1     1     1     1     1     1     1     1
485  180 0.04     1     1     1     1     1     1     1     1     1     1     1
486  181 0.04     1     1     1     1     1     1     1     1     1     1     1
487  182 0.04     1     1     1     1     1     1     1     1     1     1     1
488  183 0.04     1     1     1     1     1     1     1     1     1     1     1
489  184 0.04     1     1     1     1     1     1     1     1     1     1     1
490  185 0.04     1     1     1     1     1     1     1     1     1     1     1
491  186 0.04     1     1     1     1     1     1     1     1     1     1     1
492  187 0.04     1     1     1     1     1     1     1     1     1     1     1
493  188 0.04     1     1     1     1     1     1     1     1     1     1     1
494  189 0.04     1     1     1     1     1     1     1     1     1     1     1
495  190 0.04     1     1     1     1     1     1     1     1     1     1     1
496  191 0.04     1     1     1     1     1     1     1     1     1     1     1
497  192 0.04     1     1     1     1     1     1     1     1     1     1     1
498  193 0.04     1     1     1     1     1     1     1     1     1     1     1
499  194 0.04     1     1     1     1     1     1     1     1     1     1     1
500  195 0.04     1     1     1     1     1     1     1     1     1     1     1
501  196 0.04     1     1     1     1     1     1     1     1     1     1     1
502  197 0.04     1     1     1     1     1     1     1     1     1     1     1
503  198 0.04     1     1     1     1     1     1     1     1     1     1     1
504  199 0.04     1     1     1     1     1     1     1     1     1     1     1
505  200 0.04     1     1     1     1     1     1     1     1     1     1     1
506  100 0.05     1     1     1     1     1     1     1     1     1     1     1
507  101 0.05     1     1     1     1     1     1     1     1     1     1     1
508  102 0.05     1     1     1     1     1     1     1     1     1     1     1
509  103 0.05     1     1     1     1     1     1     1     1     1     1     1
510  104 0.05     1     1     1     1     1     1     1     1     1     1     1
511  105 0.05     1     1     1     1     1     1     1     1     1     1     1
512  106 0.05     1     1     1     1     1     1     1     1     1     1     1
513  107 0.05     1     1     1     1     1     1     1     1     1     1     1
514  108 0.05     1     1     1     1     1     1     1     1     1     1     1
515  109 0.05     1     1     1     1     1     1     1     1     1     1     1
516  110 0.05     1     1     1     1     1     1     1     1     1     1     1
517  111 0.05     1     1     1     1     1     1     1     1     1     1     1
518  112 0.05     1     1     1     1     1     1     1     1     1     1     1
519  113 0.05     1     1     1     1     1     1     1     1     1     1     1
520  114 0.05     1     1     1     1     1     1     1     1     1     1     1
521  115 0.05     1     1     1     1     1     1     1     1     1     1     1
522  116 0.05     1     1     1     1     1     1     1     1     1     1     1
523  117 0.05     1     1     1     1     1     1     1     1     1     1     1
524  118 0.05     1     1     1     1     1     1     1     1     1     1     1
525  119 0.05     1     1     1     1     1     1     1     1     1     1     1
526  120 0.05     1     1     1     1     1     1     1     1     1     1     1
527  121 0.05     1     1     1     1     1     1     1     1     1     1     1
528  122 0.05     1     1     1     1     1     1     1     1     1     1     1
529  123 0.05     1     1     1     1     1     1     1     1     1     1     1
530  124 0.05     1     1     1     1     1     1     1     1     1     1     1
531  125 0.05     1     1     1     1     1     1     1     1     1     1     1
532  126 0.05     1     1     1     1     1     1     1     1     1     1     1
533  127 0.05     1     1     1     1     1     1     1     1     1     1     1
534  128 0.05     1     1     1     1     1     1     1     1     1     1     1
535  129 0.05     1     1     1     1     1     1     1     1     1     1     1
536  130 0.05     1     1     1     1     1     1     1     1     1     1     1
537  131 0.05     1     1     1     1     1     1     1     1     1     1     1
538  132 0.05     1     1     1     1     1     1     1     1     1     1     1
539  133 0.05     1     1     1     1     1     1     1     1     1     1     1
540  134 0.05     1     1     1     1     1     1     1     1     1     1     1
541  135 0.05     1     1     1     1     1     1     1     1     1     1     1
542  136 0.05     1     1     1     1     1     1     1     1     1     1     1
543  137 0.05     1     1     1     1     1     1     1     1     1     1     1
544  138 0.05     1     1     1     1     1     1     1     1     1     1     1
545  139 0.05     1     1     1     1     1     1     1     1     1     1     1
546  140 0.05     1     1     1     1     1     1     1     1     1     1     1
547  141 0.05     1     1     1     1     1     1     1     1     1     1     1
548  142 0.05     1     1     1     1     1     1     1     1     1     1     1
549  143 0.05     1     1     1     1     1     1     1     1     1     1     1
550  144 0.05     1     1     1     1     1     1     1     1     1     1     1
551  145 0.05     1     1     1     1     1     1     1     1     1     1     1
552  146 0.05     1     1     1     1     1     1     1     1     1     1     1
553  147 0.05     1     1     1     1     1     1     1     1     1     1     1
554  148 0.05     1     1     1     1     1     1     1     1     1     1     1
555  149 0.05     1     1     1     1     1     1     1     1     1     1     1
556  150 0.05     1     1     1     1     1     1     1     1     1     1     1
557  151 0.05     1     1     1     1     1     1     1     1     1     1     1
558  152 0.05     1     1     1     1     1     1     1     1     1     1     1
559  153 0.05     1     1     1     1     1     1     1     1     1     1     1
560  154 0.05     1     1     1     1     1     1     1     1     1     1     1
561  155 0.05     1     1     1     1     1     1     1     1     1     1     1
562  156 0.05     1     1     1     1     1     1     1     1     1     1     1
563  157 0.05     1     1     1     1     1     1     1     1     1     1     1
564  158 0.05     1     1     1     1     1     1     1     1     1     1     1
565  159 0.05     1     1     1     1     1     1     1     1     1     1     1
566  160 0.05     1     1     1     1     1     1     1     1     1     1     1
567  161 0.05     1     1     1     1     1     1     1     1     1     1     1
568  162 0.05     1     1     1     1     1     1     1     1     1     1     1
569  163 0.05     1     1     1     1     1     1     1     1     1     1     1
570  164 0.05     1     1     1     1     1     1     1     1     1     1     1
571  165 0.05     1     1     1     1     1     1     1     1     1     1     1
572  166 0.05     1     1     1     1     1     1     1     1     1     1     1
573  167 0.05     1     1     1     1     1     1     1     1     1     1     1
574  168 0.05     1     1     1     1     1     1     1     1     1     1     1
575  169 0.05     1     1     1     1     1     1     1     1     1     1     1
576  170 0.05     1     1     1     1     1     1     1     1     1     1     1
577  171 0.05     1     1     1     1     1     1     1     1     1     1     1
578  172 0.05     1     1     1     1     1     1     1     1     1     1     1
579  173 0.05     1     1     1     1     1     1     1     1     1     1     1
580  174 0.05     1     1     1     1     1     1     1     1     1     1     1
581  175 0.05     1     1     1     1     1     1     1     1     1     1     1
582  176 0.05     1     1     1     1     1     1     1     1     1     1     1
583  177 0.05     1     1     1     1     1     1     1     1     1     1     1
584  178 0.05     1     1     1     1     1     1     1     1     1     1     1
585  179 0.05     1     1     1     1     1     1     1     1     1     1     1
586  180 0.05     1     1     1     1     1     1     1     1     1     1     1
587  181 0.05     1     1     1     1     1     1     1     1     1     1     1
588  182 0.05     1     1     1     1     1     1     1     1     1     1     1
589  183 0.05     1     1     1     1     1     1     1     1     1     1     1
590  184 0.05     1     1     1     1     1     1     1     1     1     1     1
591  185 0.05     1     1     1     1     1     1     1     1     1     1     1
592  186 0.05     1     1     1     1     1     1     1     1     1     1     1
593  187 0.05     1     1     1     1     1     1     1     1     1     1     1
594  188 0.05     1     1     1     1     1     1     1     1     1     1     1
595  189 0.05     1     1     1     1     1     1     1     1     1     1     1
596  190 0.05     1     1     1     1     1     1     1     1     1     1     1
597  191 0.05     1     1     1     1     1     1     1     1     1     1     1
598  192 0.05     1     1     1     1     1     1     1     1     1     1     1
599  193 0.05     1     1     1     1     1     1     1     1     1     1     1
600  194 0.05     1     1     1     1     1     1     1     1     1     1     1
601  195 0.05     1     1     1     1     1     1     1     1     1     1     1
602  196 0.05     1     1     1     1     1     1     1     1     1     1     1
603  197 0.05     1     1     1     1     1     1     1     1     1     1     1
604  198 0.05     1     1     1     1     1     1     1     1     1     1     1
605  199 0.05     1     1     1     1     1     1     1     1     1     1     1
606  200 0.05     1     1     1     1     1     1     1     1     1     1     1
607  100 0.06     1     1     1     1     1     1     1     1     1     1     1
608  101 0.06     1     1     1     1     1     1     1     1     1     1     1
609  102 0.06     1     1     1     1     1     1     1     1     1     1     1
610  103 0.06     1     1     1     1     1     1     1     1     1     1     1
611  104 0.06     1     1     1     1     1     1     1     1     1     1     1
612  105 0.06     1     1     1     1     1     1     1     1     1     1     1
613  106 0.06     1     1     1     1     1     1     1     1     1     1     1
614  107 0.06     1     1     1     1     1     1     1     1     1     1     1
615  108 0.06     1     1     1     1     1     1     1     1     1     1     1
616  109 0.06     1     1     1     1     1     1     1     1     1     1     1
617  110 0.06     1     1     1     1     1     1     1     1     1     1     1
618  111 0.06     1     1     1     1     1     1     1     1     1     1     1
619  112 0.06     1     1     1     1     1     1     1     1     1     1     1
620  113 0.06     1     1     1     1     1     1     1     1     1     1     1
621  114 0.06     1     1     1     1     1     1     1     1     1     1     1
622  115 0.06     1     1     1     1     1     1     1     1     1     1     1
623  116 0.06     1     1     1     1     1     1     1     1     1     1     1
624  117 0.06     1     1     1     1     1     1     1     1     1     1     1
625  118 0.06     1     1     1     1     1     1     1     1     1     1     1
626  119 0.06     1     1     1     1     1     1     1     1     1     1     1
627  120 0.06     1     1     1     1     1     1     1     1     1     1     1
628  121 0.06     1     1     1     1     1     1     1     1     1     1     1
629  122 0.06     1     1     1     1     1     1     1     1     1     1     1
630  123 0.06     1     1     1     1     1     1     1     1     1     1     1
631  124 0.06     1     1     1     1     1     1     1     1     1     1     1
632  125 0.06     1     1     1     1     1     1     1     1     1     1     1
633  126 0.06     1     1     1     1     1     1     1     1     1     1     1
634  127 0.06     1     1     1     1     1     1     1     1     1     1     1
635  128 0.06     1     1     1     1     1     1     1     1     1     1     1
636  129 0.06     1     1     1     1     1     1     1     1     1     1     1
637  130 0.06     1     1     1     1     1     1     1     1     1     1     1
638  131 0.06     1     1     1     1     1     1     1     1     1     1     1
639  132 0.06     1     1     1     1     1     1     1     1     1     1     1
640  133 0.06     1     1     1     1     1     1     1     1     1     1     1
641  134 0.06     1     1     1     1     1     1     1     1     1     1     1
642  135 0.06     1     1     1     1     1     1     1     1     1     1     1
643  136 0.06     1     1     1     1     1     1     1     1     1     1     1
644  137 0.06     1     1     1     1     1     1     1     1     1     1     1
645  138 0.06     1     1     1     1     1     1     1     1     1     1     1
646  139 0.06     1     1     1     1     1     1     1     1     1     1     1
647  140 0.06     1     1     1     1     1     1     1     1     1     1     1
648  141 0.06     1     1     1     1     1     1     1     1     1     1     1
649  142 0.06     1     1     1     1     1     1     1     1     1     1     1
650  143 0.06     1     1     1     1     1     1     1     1     1     1     1
651  144 0.06     1     1     1     1     1     1     1     1     1     1     1
652  145 0.06     1     1     1     1     1     1     1     1     1     1     1
653  146 0.06     1     1     1     1     1     1     1     1     1     1     1
654  147 0.06     1     1     1     1     1     1     1     1     1     1     1
655  148 0.06     1     1     1     1     1     1     1     1     1     1     1
656  149 0.06     1     1     1     1     1     1     1     1     1     1     1
657  150 0.06     1     1     1     1     1     1     1     1     1     1     1
658  151 0.06     1     1     1     1     1     1     1     1     1     1     1
659  152 0.06     1     1     1     1     1     1     1     1     1     1     1
660  153 0.06     1     1     1     1     1     1     1     1     1     1     1
661  154 0.06     1     1     1     1     1     1     1     1     1     1     1
662  155 0.06     1     1     1     1     1     1     1     1     1     1     1
663  156 0.06     1     1     1     1     1     1     1     1     1     1     1
664  157 0.06     1     1     1     1     1     1     1     1     1     1     1
665  158 0.06     1     1     1     1     1     1     1     1     1     1     1
666  159 0.06     1     1     1     1     1     1     1     1     1     1     1
667  160 0.06     1     1     1     1     1     1     1     1     1     1     1
668  161 0.06     1     1     1     1     1     1     1     1     1     1     1
669  162 0.06     1     1     1     1     1     1     1     1     1     1     1
670  163 0.06     1     1     1     1     1     1     1     1     1     1     1
671  164 0.06     1     1     1     1     1     1     1     1     1     1     1
672  165 0.06     1     1     1     1     1     1     1     1     1     1     1
673  166 0.06     1     1     1     1     1     1     1     1     1     1     1
674  167 0.06     1     1     1     1     1     1     1     1     1     1     1
675  168 0.06     1     1     1     1     1     1     1     1     1     1     1
676  169 0.06     1     1     1     1     1     1     1     1     1     1     1
677  170 0.06     1     1     1     1     1     1     1     1     1     1     1
678  171 0.06     1     1     1     1     1     1     1     1     1     1     1
679  172 0.06     1     1     1     1     1     1     1     1     1     1     1
680  173 0.06     1     1     1     1     1     1     1     1     1     1     1
681  174 0.06     1     1     1     1     1     1     1     1     1     1     1
682  175 0.06     1     1     1     1     1     1     1     1     1     1     1
683  176 0.06     1     1     1     1     1     1     1     1     1     1     1
684  177 0.06     1     1     1     1     1     1     1     1     1     1     1
685  178 0.06     1     1     1     1     1     1     1     1     1     1     1
686  179 0.06     1     1     1     1     1     1     1     1     1     1     1
687  180 0.06     1     1     1     1     1     1     1     1     1     1     1
688  181 0.06     1     1     1     1     1     1     1     1     1     1     1
689  182 0.06     1     1     1     1     1     1     1     1     1     1     1
690  183 0.06     1     1     1     1     1     1     1     1     1     1     1
691  184 0.06     1     1     1     1     1     1     1     1     1     1     1
692  185 0.06     1     1     1     1     1     1     1     1     1     1     1
693  186 0.06     1     1     1     1     1     1     1     1     1     1     1
694  187 0.06     1     1     1     1     1     1     1     1     1     1     1
695  188 0.06     1     1     1     1     1     1     1     1     1     1     1
696  189 0.06     1     1     1     1     1     1     1     1     1     1     1
697  190 0.06     1     1     1     1     1     1     1     1     1     1     1
698  191 0.06     1     1     1     1     1     1     1     1     1     1     1
699  192 0.06     1     1     1     1     1     1     1     1     1     1     1
700  193 0.06     1     1     1     1     1     1     1     1     1     1     1
701  194 0.06     1     1     1     1     1     1     1     1     1     1     1
702  195 0.06     1     1     1     1     1     1     1     1     1     1     1
703  196 0.06     1     1     1     1     1     1     1     1     1     1     1
704  197 0.06     1     1     1     1     1     1     1     1     1     1     1
705  198 0.06     1     1     1     1     1     1     1     1     1     1     1
706  199 0.06     1     1     1     1     1     1     1     1     1     1     1
707  200 0.06     1     1     1     1     1     1     1     1     1     1     1
708  100 0.07     1     1     1     1     1     1     1     1     1     1     1
709  101 0.07     1     1     1     1     1     1     1     1     1     1     1
710  102 0.07     1     1     1     1     1     1     1     1     1     1     1
711  103 0.07     1     1     1     1     1     1     1     1     1     1     1
712  104 0.07     1     1     1     1     1     1     1     1     1     1     1
713  105 0.07     1     1     1     1     1     1     1     1     1     1     1
714  106 0.07     1     1     1     1     1     1     1     1     1     1     1
715  107 0.07     1     1     1     1     1     1     1     1     1     1     1
716  108 0.07     1     1     1     1     1     1     1     1     1     1     1
717  109 0.07     1     1     1     1     1     1     1     1     1     1     1
718  110 0.07     1     1     1     1     1     1     1     1     1     1     1
719  111 0.07     1     1     1     1     1     1     1     1     1     1     1
720  112 0.07     1     1     1     1     1     1     1     1     1     1     1
721  113 0.07     1     1     1     1     1     1     1     1     1     1     1
722  114 0.07     1     1     1     1     1     1     1     1     1     1     1
723  115 0.07     1     1     1     1     1     1     1     1     1     1     1
724  116 0.07     1     1     1     1     1     1     1     1     1     1     1
725  117 0.07     1     1     1     1     1     1     1     1     1     1     1
726  118 0.07     1     1     1     1     1     1     1     1     1     1     1
727  119 0.07     1     1     1     1     1     1     1     1     1     1     1
728  120 0.07     1     1     1     1     1     1     1     1     1     1     1
729  121 0.07     1     1     1     1     1     1     1     1     1     1     1
730  122 0.07     1     1     1     1     1     1     1     1     1     1     1
731  123 0.07     1     1     1     1     1     1     1     1     1     1     1
732  124 0.07     1     1     1     1     1     1     1     1     1     1     1
733  125 0.07     1     1     1     1     1     1     1     1     1     1     1
734  126 0.07     1     1     1     1     1     1     1     1     1     1     1
735  127 0.07     1     1     1     1     1     1     1     1     1     1     1
736  128 0.07     1     1     1     1     1     1     1     1     1     1     1
737  129 0.07     1     1     1     1     1     1     1     1     1     1     1
738  130 0.07     1     1     1     1     1     1     1     1     1     1     1
739  131 0.07     1     1     1     1     1     1     1     1     1     1     1
740  132 0.07     1     1     1     1     1     1     1     1     1     1     1
741  133 0.07     1     1     1     1     1     1     1     1     1     1     1
742  134 0.07     1     1     1     1     1     1     1     1     1     1     1
743  135 0.07     1     1     1     1     1     1     1     1     1     1     1
744  136 0.07     1     1     1     1     1     1     1     1     1     1     1
745  137 0.07     1     1     1     1     1     1     1     1     1     1     1
746  138 0.07     1     1     1     1     1     1     1     1     1     1     1
747  139 0.07     1     1     1     1     1     1     1     1     1     1     1
748  140 0.07     1     1     1     1     1     1     1     1     1     1     1
749  141 0.07     1     1     1     1     1     1     1     1     1     1     1
750  142 0.07     1     1     1     1     1     1     1     1     1     1     1
751  143 0.07     1     1     1     1     1     1     1     1     1     1     1
752  144 0.07     1     1     1     1     1     1     1     1     1     1     1
753  145 0.07     1     1     1     1     1     1     1     1     1     1     1
754  146 0.07     1     1     1     1     1     1     1     1     1     1     1
755  147 0.07     1     1     1     1     1     1     1     1     1     1     1
756  148 0.07     1     1     1     1     1     1     1     1     1     1     1
757  149 0.07     1     1     1     1     1     1     1     1     1     1     1
758  150 0.07     1     1     1     1     1     1     1     1     1     1     1
759  151 0.07     1     1     1     1     1     1     1     1     1     1     1
760  152 0.07     1     1     1     1     1     1     1     1     1     1     1
761  153 0.07     1     1     1     1     1     1     1     1     1     1     1
762  154 0.07     1     1     1     1     1     1     1     1     1     1     1
763  155 0.07     1     1     1     1     1     1     1     1     1     1     1
764  156 0.07     1     1     1     1     1     1     1     1     1     1     1
765  157 0.07     1     1     1     1     1     1     1     1     1     1     1
766  158 0.07     1     1     1     1     1     1     1     1     1     1     1
767  159 0.07     1     1     1     1     1     1     1     1     1     1     1
768  160 0.07     1     1     1     1     1     1     1     1     1     1     1
769  161 0.07     1     1     1     1     1     1     1     1     1     1     1
770  162 0.07     1     1     1     1     1     1     1     1     1     1     1
771  163 0.07     1     1     1     1     1     1     1     1     1     1     1
772  164 0.07     1     1     1     1     1     1     1     1     1     1     1
773  165 0.07     1     1     1     1     1     1     1     1     1     1     1
774  166 0.07     1     1     1     1     1     1     1     1     1     1     1
775  167 0.07     1     1     1     1     1     1     1     1     1     1     1
776  168 0.07     1     1     1     1     1     1     1     1     1     1     1
777  169 0.07     1     1     1     1     1     1     1     1     1     1     1
778  170 0.07     1     1     1     1     1     1     1     1     1     1     1
779  171 0.07     1     1     1     1     1     1     1     1     1     1     1
780  172 0.07     1     1     1     1     1     1     1     1     1     1     1
781  173 0.07     1     1     1     1     1     1     1     1     1     1     1
782  174 0.07     1     1     1     1     1     1     1     1     1     1     1
783  175 0.07     1     1     1     1     1     1     1     1     1     1     1
784  176 0.07     1     1     1     1     1     1     1     1     1     1     1
785  177 0.07     1     1     1     1     1     1     1     1     1     1     1
786  178 0.07     1     1     1     1     1     1     1     1     1     1     1
787  179 0.07     1     1     1     1     1     1     1     1     1     1     1
788  180 0.07     1     1     1     1     1     1     1     1     1     1     1
789  181 0.07     1     1     1     1     1     1     1     1     1     1     1
790  182 0.07     1     1     1     1     1     1     1     1     1     1     1
791  183 0.07     1     1     1     1     1     1     1     1     1     1     1
792  184 0.07     1     1     1     1     1     1     1     1     1     1     1
793  185 0.07     1     1     1     1     1     1     1     1     1     1     1
794  186 0.07     1     1     1     1     1     1     1     1     1     1     1
795  187 0.07     1     1     1     1     1     1     1     1     1     1     1
796  188 0.07     1     1     1     1     1     1     1     1     1     1     1
797  189 0.07     1     1     1     1     1     1     1     1     1     1     1
798  190 0.07     1     1     1     1     1     1     1     1     1     1     1
799  191 0.07     1     1     1     1     1     1     1     1     1     1     1
800  192 0.07     1     1     1     1     1     1     1     1     1     1     1
801  193 0.07     1     1     1     1     1     1     1     1     1     1     1
802  194 0.07     1     1     1     1     1     1     1     1     1     1     1
803  195 0.07     1     1     1     1     1     1     1     1     1     1     1
804  196 0.07     1     1     1     1     1     1     1     1     1     1     1
805  197 0.07     1     1     1     1     1     1     1     1     1     1     1
806  198 0.07     1     1     1     1     1     1     1     1     1     1     1
807  199 0.07     1     1     1     1     1     1     1     1     1     1     1
808  200 0.07     1     1     1     1     1     1     1     1     1     1     1
809  100 0.08     1     1     1     1     1     1     1     1     1     1     1
810  101 0.08     1     1     1     1     1     1     1     1     1     1     1
811  102 0.08     1     1     1     1     1     1     1     1     1     1     1
812  103 0.08     1     1     1     1     1     1     1     1     1     1     1
813  104 0.08     1     1     1     1     1     1     1     1     1     1     1
814  105 0.08     1     1     1     1     1     1     1     1     1     1     1
815  106 0.08     1     1     1     1     1     1     1     1     1     1     1
816  107 0.08     1     1     1     1     1     1     1     1     1     1     1
817  108 0.08     1     1     1     1     1     1     1     1     1     1     1
818  109 0.08     1     1     1     1     1     1     1     1     1     1     1
819  110 0.08     1     1     1     1     1     1     1     1     1     1     1
820  111 0.08     1     1     1     1     1     1     1     1     1     1     1
821  112 0.08     1     1     1     1     1     1     1     1     1     1     1
822  113 0.08     1     1     1     1     1     1     1     1     1     1     1
823  114 0.08     1     1     1     1     1     1     1     1     1     1     1
824  115 0.08     1     1     1     1     1     1     1     1     1     1     1
825  116 0.08     1     1     1     1     1     1     1     1     1     1     1
826  117 0.08     1     1     1     1     1     1     1     1     1     1     1
827  118 0.08     1     1     1     1     1     1     1     1     1     1     1
828  119 0.08     1     1     1     1     1     1     1     1     1     1     1
829  120 0.08     1     1     1     1     1     1     1     1     1     1     1
830  121 0.08     1     1     1     1     1     1     1     1     1     1     1
831  122 0.08     1     1     1     1     1     1     1     1     1     1     1
832  123 0.08     1     1     1     1     1     1     1     1     1     1     1
833  124 0.08     1     1     1     1     1     1     1     1     1     1     1
834  125 0.08     1     1     1     1     1     1     1     1     1     1     1
835  126 0.08     1     1     1     1     1     1     1     1     1     1     1
836  127 0.08     1     1     1     1     1     1     1     1     1     1     1
837  128 0.08     1     1     1     1     1     1     1     1     1     1     1
838  129 0.08     1     1     1     1     1     1     1     1     1     1     1
839  130 0.08     1     1     1     1     1     1     1     1     1     1     1
840  131 0.08     1     1     1     1     1     1     1     1     1     1     1
841  132 0.08     1     1     1     1     1     1     1     1     1     1     1
842  133 0.08     1     1     1     1     1     1     1     1     1     1     1
843  134 0.08     1     1     1     1     1     1     1     1     1     1     1
844  135 0.08     1     1     1     1     1     1     1     1     1     1     1
845  136 0.08     1     1     1     1     1     1     1     1     1     1     1
846  137 0.08     1     1     1     1     1     1     1     1     1     1     1
847  138 0.08     1     1     1     1     1     1     1     1     1     1     1
848  139 0.08     1     1     1     1     1     1     1     1     1     1     1
849  140 0.08     1     1     1     1     1     1     1     1     1     1     1
850  141 0.08     1     1     1     1     1     1     1     1     1     1     1
851  142 0.08     1     1     1     1     1     1     1     1     1     1     1
852  143 0.08     1     1     1     1     1     1     1     1     1     1     1
853  144 0.08     1     1     1     1     1     1     1     1     1     1     1
854  145 0.08     1     1     1     1     1     1     1     1     1     1     1
855  146 0.08     1     1     1     1     1     1     1     1     1     1     1
856  147 0.08     1     1     1     1     1     1     1     1     1     1     1
857  148 0.08     1     1     1     1     1     1     1     1     1     1     1
858  149 0.08     1     1     1     1     1     1     1     1     1     1     1
859  150 0.08     1     1     1     1     1     1     1     1     1     1     1
860  151 0.08     1     1     1     1     1     1     1     1     1     1     1
861  152 0.08     1     1     1     1     1     1     1     1     1     1     1
862  153 0.08     1     1     1     1     1     1     1     1     1     1     1
863  154 0.08     1     1     1     1     1     1     1     1     1     1     1
864  155 0.08     1     1     1     1     1     1     1     1     1     1     1
865  156 0.08     1     1     1     1     1     1     1     1     1     1     1
866  157 0.08     1     1     1     1     1     1     1     1     1     1     1
867  158 0.08     1     1     1     1     1     1     1     1     1     1     1
868  159 0.08     1     1     1     1     1     1     1     1     1     1     1
869  160 0.08     1     1     1     1     1     1     1     1     1     1     1
870  161 0.08     1     1     1     1     1     1     1     1     1     1     1
871  162 0.08     1     1     1     1     1     1     1     1     1     1     1
872  163 0.08     1     1     1     1     1     1     1     1     1     1     1
873  164 0.08     1     1     1     1     1     1     1     1     1     1     1
874  165 0.08     1     1     1     1     1     1     1     1     1     1     1
875  166 0.08     1     1     1     1     1     1     1     1     1     1     1
876  167 0.08     1     1     1     1     1     1     1     1     1     1     1
877  168 0.08     1     1     1     1     1     1     1     1     1     1     1
878  169 0.08     1     1     1     1     1     1     1     1     1     1     1
879  170 0.08     1     1     1     1     1     1     1     1     1     1     1
880  171 0.08     1     1     1     1     1     1     1     1     1     1     1
881  172 0.08     1     1     1     1     1     1     1     1     1     1     1
882  173 0.08     1     1     1     1     1     1     1     1     1     1     1
883  174 0.08     1     1     1     1     1     1     1     1     1     1     1
884  175 0.08     1     1     1     1     1     1     1     1     1     1     1
885  176 0.08     1     1     1     1     1     1     1     1     1     1     1
886  177 0.08     1     1     1     1     1     1     1     1     1     1     1
887  178 0.08     1     1     1     1     1     1     1     1     1     1     1
888  179 0.08     1     1     1     1     1     1     1     1     1     1     1
889  180 0.08     1     1     1     1     1     1     1     1     1     1     1
890  181 0.08     1     1     1     1     1     1     1     1     1     1     1
891  182 0.08     1     1     1     1     1     1     1     1     1     1     1
892  183 0.08     1     1     1     1     1     1     1     1     1     1     1
893  184 0.08     1     1     1     1     1     1     1     1     1     1     1
894  185 0.08     1     1     1     1     1     1     1     1     1     1     1
895  186 0.08     1     1     1     1     1     1     1     1     1     1     1
896  187 0.08     1     1     1     1     1     1     1     1     1     1     1
897  188 0.08     1     1     1     1     1     1     1     1     1     1     1
898  189 0.08     1     1     1     1     1     1     1     1     1     1     1
899  190 0.08     1     1     1     1     1     1     1     1     1     1     1
900  191 0.08     1     1     1     1     1     1     1     1     1     1     1
901  192 0.08     1     1     1     1     1     1     1     1     1     1     1
902  193 0.08     1     1     1     1     1     1     1     1     1     1     1
903  194 0.08     1     1     1     1     1     1     1     1     1     1     1
904  195 0.08     1     1     1     1     1     1     1     1     1     1     1
905  196 0.08     1     1     1     1     1     1     1     1     1     1     1
906  197 0.08     1     1     1     1     1     1     1     1     1     1     1
907  198 0.08     1     1     1     1     1     1     1     1     1     1     1
908  199 0.08     1     1     1     1     1     1     1     1     1     1     1
909  200 0.08     1     1     1     1     1     1     1     1     1     1     1
910  100 0.09     1     1     1     1     1     1     1     1     1     1     1
911  101 0.09     1     1     1     1     1     1     1     1     1     1     1
912  102 0.09     1     1     1     1     1     1     1     1     1     1     1
913  103 0.09     1     1     1     1     1     1     1     1     1     1     1
914  104 0.09     1     1     1     1     1     1     1     1     1     1     1
915  105 0.09     1     1     1     1     1     1     1     1     1     1     1
916  106 0.09     1     1     1     1     1     1     1     1     1     1     1
917  107 0.09     1     1     1     1     1     1     1     1     1     1     1
918  108 0.09     1     1     1     1     1     1     1     1     1     1     1
919  109 0.09     1     1     1     1     1     1     1     1     1     1     1
920  110 0.09     1     1     1     1     1     1     1     1     1     1     1
921  111 0.09     1     1     1     1     1     1     1     1     1     1     1
922  112 0.09     1     1     1     1     1     1     1     1     1     1     1
923  113 0.09     1     1     1     1     1     1     1     1     1     1     1
924  114 0.09     1     1     1     1     1     1     1     1     1     1     1
925  115 0.09     1     1     1     1     1     1     1     1     1     1     1
926  116 0.09     1     1     1     1     1     1     1     1     1     1     1
927  117 0.09     1     1     1     1     1     1     1     1     1     1     1
928  118 0.09     1     1     1     1     1     1     1     1     1     1     1
929  119 0.09     1     1     1     1     1     1     1     1     1     1     1
930  120 0.09     1     1     1     1     1     1     1     1     1     1     1
931  121 0.09     1     1     1     1     1     1     1     1     1     1     1
932  122 0.09     1     1     1     1     1     1     1     1     1     1     1
933  123 0.09     1     1     1     1     1     1     1     1     1     1     1
934  124 0.09     1     1     1     1     1     1     1     1     1     1     1
935  125 0.09     1     1     1     1     1     1     1     1     1     1     1
936  126 0.09     1     1     1     1     1     1     1     1     1     1     1
937  127 0.09     1     1     1     1     1     1     1     1     1     1     1
938  128 0.09     1     1     1     1     1     1     1     1     1     1     1
939  129 0.09     1     1     1     1     1     1     1     1     1     1     1
940  130 0.09     1     1     1     1     1     1     1     1     1     1     1
941  131 0.09     1     1     1     1     1     1     1     1     1     1     1
942  132 0.09     1     1     1     1     1     1     1     1     1     1     1
943  133 0.09     1     1     1     1     1     1     1     1     1     1     1
944  134 0.09     1     1     1     1     1     1     1     1     1     1     1
945  135 0.09     1     1     1     1     1     1     1     1     1     1     1
946  136 0.09     1     1     1     1     1     1     1     1     1     1     1
947  137 0.09     1     1     1     1     1     1     1     1     1     1     1
948  138 0.09     1     1     1     1     1     1     1     1     1     1     1
949  139 0.09     1     1     1     1     1     1     1     1     1     1     1
950  140 0.09     1     1     1     1     1     1     1     1     1     1     1
951  141 0.09     1     1     1     1     1     1     1     1     1     1     1
952  142 0.09     1     1     1     1     1     1     1     1     1     1     1
953  143 0.09     1     1     1     1     1     1     1     1     1     1     1
954  144 0.09     1     1     1     1     1     1     1     1     1     1     1
955  145 0.09     1     1     1     1     1     1     1     1     1     1     1
956  146 0.09     1     1     1     1     1     1     1     1     1     1     1
957  147 0.09     1     1     1     1     1     1     1     1     1     1     1
958  148 0.09     1     1     1     1     1     1     1     1     1     1     1
959  149 0.09     1     1     1     1     1     1     1     1     1     1     1
960  150 0.09     1     1     1     1     1     1     1     1     1     1     1
961  151 0.09     1     1     1     1     1     1     1     1     1     1     1
962  152 0.09     1     1     1     1     1     1     1     1     1     1     1
963  153 0.09     1     1     1     1     1     1     1     1     1     1     1
964  154 0.09     1     1     1     1     1     1     1     1     1     1     1
965  155 0.09     1     1     1     1     1     1     1     1     1     1     1
966  156 0.09     1     1     1     1     1     1     1     1     1     1     1
967  157 0.09     1     1     1     1     1     1     1     1     1     1     1
968  158 0.09     1     1     1     1     1     1     1     1     1     1     1
969  159 0.09     1     1     1     1     1     1     1     1     1     1     1
970  160 0.09     1     1     1     1     1     1     1     1     1     1     1
971  161 0.09     1     1     1     1     1     1     1     1     1     1     1
972  162 0.09     1     1     1     1     1     1     1     1     1     1     1
973  163 0.09     1     1     1     1     1     1     1     1     1     1     1
974  164 0.09     1     1     1     1     1     1     1     1     1     1     1
975  165 0.09     1     1     1     1     1     1     1     1     1     1     1
976  166 0.09     1     1     1     1     1     1     1     1     1     1     1
977  167 0.09     1     1     1     1     1     1     1     1     1     1     1
978  168 0.09     1     1     1     1     1     1     1     1     1     1     1
979  169 0.09     1     1     1     1     1     1     1     1     1     1     1
980  170 0.09     1     1     1     1     1     1     1     1     1     1     1
981  171 0.09     1     1     1     1     1     1     1     1     1     1     1
982  172 0.09     1     1     1     1     1     1     1     1     1     1     1
983  173 0.09     1     1     1     1     1     1     1     1     1     1     1
984  174 0.09     1     1     1     1     1     1     1     1     1     1     1
985  175 0.09     1     1     1     1     1     1     1     1     1     1     1
986  176 0.09     1     1     1     1     1     1     1     1     1     1     1
987  177 0.09     1     1     1     1     1     1     1     1     1     1     1
988  178 0.09     1     1     1     1     1     1     1     1     1     1     1
989  179 0.09     1     1     1     1     1     1     1     1     1     1     1
990  180 0.09     1     1     1     1     1     1     1     1     1     1     1
991  181 0.09     1     1     1     1     1     1     1     1     1     1     1
992  182 0.09     1     1     1     1     1     1     1     1     1     1     1
993  183 0.09     1     1     1     1     1     1     1     1     1     1     1
994  184 0.09     1     1     1     1     1     1     1     1     1     1     1
995  185 0.09     1     1     1     1     1     1     1     1     1     1     1
996  186 0.09     1     1     1     1     1     1     1     1     1     1     1
997  187 0.09     1     1     1     1     1     1     1     1     1     1     1
998  188 0.09     1     1     1     1     1     1     1     1     1     1     1
999  189 0.09     1     1     1     1     1     1     1     1     1     1     1
1000 190 0.09     1     1     1     1     1     1     1     1     1     1     1
1001 191 0.09     1     1     1     1     1     1     1     1     1     1     1
1002 192 0.09     1     1     1     1     1     1     1     1     1     1     1
1003 193 0.09     1     1     1     1     1     1     1     1     1     1     1
1004 194 0.09     1     1     1     1     1     1     1     1     1     1     1
1005 195 0.09     1     1     1     1     1     1     1     1     1     1     1
1006 196 0.09     1     1     1     1     1     1     1     1     1     1     1
1007 197 0.09     1     1     1     1     1     1     1     1     1     1     1
1008 198 0.09     1     1     1     1     1     1     1     1     1     1     1
1009 199 0.09     1     1     1     1     1     1     1     1     1     1     1
1010 200 0.09     1     1     1     1     1     1     1     1     1     1     1
1011 100 0.10     1     1     1     1     1     1     1     1     1     1     1
1012 101 0.10     1     1     1     1     1     1     1     1     1     1     1
1013 102 0.10     1     1     1     1     1     1     1     1     1     1     1
1014 103 0.10     1     1     1     1     1     1     1     1     1     1     1
1015 104 0.10     1     1     1     1     1     1     1     1     1     1     1
1016 105 0.10     1     1     1     1     1     1     1     1     1     1     1
1017 106 0.10     1     1     1     1     1     1     1     1     1     1     1
1018 107 0.10     1     1     1     1     1     1     1     1     1     1     1
1019 108 0.10     1     1     1     1     1     1     1     1     1     1     1
1020 109 0.10     1     1     1     1     1     1     1     1     1     1     1
1021 110 0.10     1     1     1     1     1     1     1     1     1     1     1
1022 111 0.10     1     1     1     1     1     1     1     1     1     1     1
1023 112 0.10     1     1     1     1     1     1     1     1     1     1     1
1024 113 0.10     1     1     1     1     1     1     1     1     1     1     1
1025 114 0.10     1     1     1     1     1     1     1     1     1     1     1
1026 115 0.10     1     1     1     1     1     1     1     1     1     1     1
1027 116 0.10     1     1     1     1     1     1     1     1     1     1     1
1028 117 0.10     1     1     1     1     1     1     1     1     1     1     1
1029 118 0.10     1     1     1     1     1     1     1     1     1     1     1
1030 119 0.10     1     1     1     1     1     1     1     1     1     1     1
1031 120 0.10     1     1     1     1     1     1     1     1     1     1     1
1032 121 0.10     1     1     1     1     1     1     1     1     1     1     1
1033 122 0.10     1     1     1     1     1     1     1     1     1     1     1
1034 123 0.10     1     1     1     1     1     1     1     1     1     1     1
1035 124 0.10     1     1     1     1     1     1     1     1     1     1     1
1036 125 0.10     1     1     1     1     1     1     1     1     1     1     1
1037 126 0.10     1     1     1     1     1     1     1     1     1     1     1
1038 127 0.10     1     1     1     1     1     1     1     1     1     1     1
1039 128 0.10     1     1     1     1     1     1     1     1     1     1     1
1040 129 0.10     1     1     1     1     1     1     1     1     1     1     1
1041 130 0.10     1     1     1     1     1     1     1     1     1     1     1
1042 131 0.10     1     1     1     1     1     1     1     1     1     1     1
1043 132 0.10     1     1     1     1     1     1     1     1     1     1     1
1044 133 0.10     1     1     1     1     1     1     1     1     1     1     1
1045 134 0.10     1     1     1     1     1     1     1     1     1     1     1
1046 135 0.10     1     1     1     1     1     1     1     1     1     1     1
1047 136 0.10     1     1     1     1     1     1     1     1     1     1     1
1048 137 0.10     1     1     1     1     1     1     1     1     1     1     1
1049 138 0.10     1     1     1     1     1     1     1     1     1     1     1
1050 139 0.10     1     1     1     1     1     1     1     1     1     1     1
1051 140 0.10     1     1     1     1     1     1     1     1     1     1     1
1052 141 0.10     1     1     1     1     1     1     1     1     1     1     1
1053 142 0.10     1     1     1     1     1     1     1     1     1     1     1
1054 143 0.10     1     1     1     1     1     1     1     1     1     1     1
1055 144 0.10     1     1     1     1     1     1     1     1     1     1     1
1056 145 0.10     1     1     1     1     1     1     1     1     1     1     1
1057 146 0.10     1     1     1     1     1     1     1     1     1     1     1
1058 147 0.10     1     1     1     1     1     1     1     1     1     1     1
1059 148 0.10     1     1     1     1     1     1     1     1     1     1     1
1060 149 0.10     1     1     1     1     1     1     1     1     1     1     1
1061 150 0.10     1     1     1     1     1     1     1     1     1     1     1
1062 151 0.10     1     1     1     1     1     1     1     1     1     1     1
1063 152 0.10     1     1     1     1     1     1     1     1     1     1     1
1064 153 0.10     1     1     1     1     1     1     1     1     1     1     1
1065 154 0.10     1     1     1     1     1     1     1     1     1     1     1
1066 155 0.10     1     1     1     1     1     1     1     1     1     1     1
1067 156 0.10     1     1     1     1     1     1     1     1     1     1     1
1068 157 0.10     1     1     1     1     1     1     1     1     1     1     1
1069 158 0.10     1     1     1     1     1     1     1     1     1     1     1
1070 159 0.10     1     1     1     1     1     1     1     1     1     1     1
1071 160 0.10     1     1     1     1     1     1     1     1     1     1     1
1072 161 0.10     1     1     1     1     1     1     1     1     1     1     1
1073 162 0.10     1     1     1     1     1     1     1     1     1     1     1
1074 163 0.10     1     1     1     1     1     1     1     1     1     1     1
1075 164 0.10     1     1     1     1     1     1     1     1     1     1     1
1076 165 0.10     1     1     1     1     1     1     1     1     1     1     1
1077 166 0.10     1     1     1     1     1     1     1     1     1     1     1
1078 167 0.10     1     1     1     1     1     1     1     1     1     1     1
1079 168 0.10     1     1     1     1     1     1     1     1     1     1     1
1080 169 0.10     1     1     1     1     1     1     1     1     1     1     1
1081 170 0.10     1     1     1     1     1     1     1     1     1     1     1
1082 171 0.10     1     1     1     1     1     1     1     1     1     1     1
1083 172 0.10     1     1     1     1     1     1     1     1     1     1     1
1084 173 0.10     1     1     1     1     1     1     1     1     1     1     1
1085 174 0.10     1     1     1     1     1     1     1     1     1     1     1
1086 175 0.10     1     1     1     1     1     1     1     1     1     1     1
1087 176 0.10     1     1     1     1     1     1     1     1     1     1     1
1088 177 0.10     1     1     1     1     1     1     1     1     1     1     1
1089 178 0.10     1     1     1     1     1     1     1     1     1     1     1
1090 179 0.10     1     1     1     1     1     1     1     1     1     1     1
1091 180 0.10     1     1     1     1     1     1     1     1     1     1     1
1092 181 0.10     1     1     1     1     1     1     1     1     1     1     1
1093 182 0.10     1     1     1     1     1     1     1     1     1     1     1
1094 183 0.10     1     1     1     1     1     1     1     1     1     1     1
1095 184 0.10     1     1     1     1     1     1     1     1     1     1     1
1096 185 0.10     1     1     1     1     1     1     1     1     1     1     1
1097 186 0.10     1     1     1     1     1     1     1     1     1     1     1
1098 187 0.10     1     1     1     1     1     1     1     1     1     1     1
1099 188 0.10     1     1     1     1     1     1     1     1     1     1     1
1100 189 0.10     1     1     1     1     1     1     1     1     1     1     1
1101 190 0.10     1     1     1     1     1     1     1     1     1     1     1
1102 191 0.10     1     1     1     1     1     1     1     1     1     1     1
1103 192 0.10     1     1     1     1     1     1     1     1     1     1     1
1104 193 0.10     1     1     1     1     1     1     1     1     1     1     1
1105 194 0.10     1     1     1     1     1     1     1     1     1     1     1
1106 195 0.10     1     1     1     1     1     1     1     1     1     1     1
1107 196 0.10     1     1     1     1     1     1     1     1     1     1     1
1108 197 0.10     1     1     1     1     1     1     1     1     1     1     1
1109 198 0.10     1     1     1     1     1     1     1     1     1     1     1
1110 199 0.10     1     1     1     1     1     1     1     1     1     1     1
1111 200 0.10     1     1     1     1     1     1     1     1     1     1     1
1112 100 0.11     1     1     1     1     1     1     1     1     1     1     1
1113 101 0.11     1     1     1     1     1     1     1     1     1     1     1
1114 102 0.11     1     1     1     1     1     1     1     1     1     1     1
1115 103 0.11     1     1     1     1     1     1     1     1     1     1     1
1116 104 0.11     1     1     1     1     1     1     1     1     1     1     1
1117 105 0.11     1     1     1     1     1     1     1     1     1     1     1
1118 106 0.11     1     1     1     1     1     1     1     1     1     1     1
1119 107 0.11     1     1     1     1     1     1     1     1     1     1     1
1120 108 0.11     1     1     1     1     1     1     1     1     1     1     1
1121 109 0.11     1     1     1     1     1     1     1     1     1     1     1
1122 110 0.11     1     1     1     1     1     1     1     1     1     1     1
1123 111 0.11     1     1     1     1     1     1     1     1     1     1     1
1124 112 0.11     1     1     1     1     1     1     1     1     1     1     1
1125 113 0.11     1     1     1     1     1     1     1     1     1     1     1
1126 114 0.11     1     1     1     1     1     1     1     1     1     1     1
1127 115 0.11     1     1     1     1     1     1     1     1     1     1     1
1128 116 0.11     1     1     1     1     1     1     1     1     1     1     1
1129 117 0.11     1     1     1     1     1     1     1     1     1     1     1
1130 118 0.11     1     1     1     1     1     1     1     1     1     1     1
1131 119 0.11     1     1     1     1     1     1     1     1     1     1     1
1132 120 0.11     1     1     1     1     1     1     1     1     1     1     1
1133 121 0.11     1     1     1     1     1     1     1     1     1     1     1
1134 122 0.11     1     1     1     1     1     1     1     1     1     1     1
1135 123 0.11     1     1     1     1     1     1     1     1     1     1     1
1136 124 0.11     1     1     1     1     1     1     1     1     1     1     1
1137 125 0.11     1     1     1     1     1     1     1     1     1     1     1
1138 126 0.11     1     1     1     1     1     1     1     1     1     1     1
1139 127 0.11     1     1     1     1     1     1     1     1     1     1     1
1140 128 0.11     1     1     1     1     1     1     1     1     1     1     1
1141 129 0.11     1     1     1     1     1     1     1     1     1     1     1
1142 130 0.11     1     1     1     1     1     1     1     1     1     1     1
1143 131 0.11     1     1     1     1     1     1     1     1     1     1     1
1144 132 0.11     1     1     1     1     1     1     1     1     1     1     1
1145 133 0.11     1     1     1     1     1     1     1     1     1     1     1
1146 134 0.11     1     1     1     1     1     1     1     1     1     1     1
1147 135 0.11     1     1     1     1     1     1     1     1     1     1     1
1148 136 0.11     1     1     1     1     1     1     1     1     1     1     1
1149 137 0.11     1     1     1     1     1     1     1     1     1     1     1
1150 138 0.11     1     1     1     1     1     1     1     1     1     1     1
1151 139 0.11     1     1     1     1     1     1     1     1     1     1     1
1152 140 0.11     1     1     1     1     1     1     1     1     1     1     1
1153 141 0.11     1     1     1     1     1     1     1     1     1     1     1
1154 142 0.11     1     1     1     1     1     1     1     1     1     1     1
1155 143 0.11     1     1     1     1     1     1     1     1     1     1     1
1156 144 0.11     1     1     1     1     1     1     1     1     1     1     1
1157 145 0.11     1     1     1     1     1     1     1     1     1     1     1
1158 146 0.11     1     1     1     1     1     1     1     1     1     1     1
1159 147 0.11     1     1     1     1     1     1     1     1     1     1     1
1160 148 0.11     1     1     1     1     1     1     1     1     1     1     1
1161 149 0.11     1     1     1     1     1     1     1     1     1     1     1
1162 150 0.11     1     1     1     1     1     1     1     1     1     1     1
1163 151 0.11     1     1     1     1     1     1     1     1     1     1     1
1164 152 0.11     1     1     1     1     1     1     1     1     1     1     1
1165 153 0.11     1     1     1     1     1     1     1     1     1     1     1
1166 154 0.11     1     1     1     1     1     1     1     1     1     1     1
1167 155 0.11     1     1     1     1     1     1     1     1     1     1     1
1168 156 0.11     1     1     1     1     1     1     1     1     1     1     1
1169 157 0.11     1     1     1     1     1     1     1     1     1     1     1
1170 158 0.11     1     1     1     1     1     1     1     1     1     1     1
1171 159 0.11     1     1     1     1     1     1     1     1     1     1     1
1172 160 0.11     1     1     1     1     1     1     1     1     1     1     1
1173 161 0.11     1     1     1     1     1     1     1     1     1     1     1
1174 162 0.11     1     1     1     1     1     1     1     1     1     1     1
1175 163 0.11     1     1     1     1     1     1     1     1     1     1     1
1176 164 0.11     1     1     1     1     1     1     1     1     1     1     1
1177 165 0.11     1     1     1     1     1     1     1     1     1     1     1
1178 166 0.11     1     1     1     1     1     1     1     1     1     1     1
1179 167 0.11     1     1     1     1     1     1     1     1     1     1     1
1180 168 0.11     1     1     1     1     1     1     1     1     1     1     1
1181 169 0.11     1     1     1     1     1     1     1     1     1     1     1
1182 170 0.11     1     1     1     1     1     1     1     1     1     1     1
1183 171 0.11     1     1     1     1     1     1     1     1     1     1     1
1184 172 0.11     1     1     1     1     1     1     1     1     1     1     1
1185 173 0.11     1     1     1     1     1     1     1     1     1     1     1
1186 174 0.11     1     1     1     1     1     1     1     1     1     1     1
1187 175 0.11     1     1     1     1     1     1     1     1     1     1     1
1188 176 0.11     1     1     1     1     1     1     1     1     1     1     1
1189 177 0.11     1     1     1     1     1     1     1     1     1     1     1
1190 178 0.11     1     1     1     1     1     1     1     1     1     1     1
1191 179 0.11     1     1     1     1     1     1     1     1     1     1     1
1192 180 0.11     1     1     1     1     1     1     1     1     1     1     1
1193 181 0.11     1     1     1     1     1     1     1     1     1     1     1
1194 182 0.11     1     1     1     1     1     1     1     1     1     1     1
1195 183 0.11     1     1     1     1     1     1     1     1     1     1     1
1196 184 0.11     1     1     1     1     1     1     1     1     1     1     1
1197 185 0.11     1     1     1     1     1     1     1     1     1     1     1
1198 186 0.11     1     1     1     1     1     1     1     1     1     1     1
1199 187 0.11     1     1     1     1     1     1     1     1     1     1     1
1200 188 0.11     1     1     1     1     1     1     1     1     1     1     1
1201 189 0.11     1     1     1     1     1     1     1     1     1     1     1
1202 190 0.11     1     1     1     1     1     1     1     1     1     1     1
1203 191 0.11     1     1     1     1     1     1     1     1     1     1     1
1204 192 0.11     1     1     1     1     1     1     1     1     1     1     1
1205 193 0.11     1     1     1     1     1     1     1     1     1     1     1
1206 194 0.11     1     1     1     1     1     1     1     1     1     1     1
1207 195 0.11     1     1     1     1     1     1     1     1     1     1     1
1208 196 0.11     1     1     1     1     1     1     1     1     1     1     1
1209 197 0.11     1     1     1     1     1     1     1     1     1     1     1
1210 198 0.11     1     1     1     1     1     1     1     1     1     1     1
1211 199 0.11     1     1     1     1     1     1     1     1     1     1     1
1212 200 0.11     1     1     1     1     1     1     1     1     1     1     1
1213 100 0.12     1     1     1     1     1     1     1     1     1     1     1
1214 101 0.12     1     1     1     1     1     1     1     1     1     1     1
1215 102 0.12     1     1     1     1     1     1     1     1     1     1     1
1216 103 0.12     1     1     1     1     1     1     1     1     1     1     1
1217 104 0.12     1     1     1     1     1     1     1     1     1     1     1
1218 105 0.12     1     1     1     1     1     1     1     1     1     1     1
1219 106 0.12     1     1     1     1     1     1     1     1     1     1     1
1220 107 0.12     1     1     1     1     1     1     1     1     1     1     1
1221 108 0.12     1     1     1     1     1     1     1     1     1     1     1
1222 109 0.12     1     1     1     1     1     1     1     1     1     1     1
1223 110 0.12     1     1     1     1     1     1     1     1     1     1     1
1224 111 0.12     1     1     1     1     1     1     1     1     1     1     1
1225 112 0.12     1     1     1     1     1     1     1     1     1     1     1
1226 113 0.12     1     1     1     1     1     1     1     1     1     1     1
1227 114 0.12     1     1     1     1     1     1     1     1     1     1     1
1228 115 0.12     1     1     1     1     1     1     1     1     1     1     1
1229 116 0.12     1     1     1     1     1     1     1     1     1     1     1
1230 117 0.12     1     1     1     1     1     1     1     1     1     1     1
1231 118 0.12     1     1     1     1     1     1     1     1     1     1     1
1232 119 0.12     1     1     1     1     1     1     1     1     1     1     1
1233 120 0.12     1     1     1     1     1     1     1     1     1     1     1
1234 121 0.12     1     1     1     1     1     1     1     1     1     1     1
1235 122 0.12     1     1     1     1     1     1     1     1     1     1     1
1236 123 0.12     1     1     1     1     1     1     1     1     1     1     1
1237 124 0.12     1     1     1     1     1     1     1     1     1     1     1
1238 125 0.12     1     1     1     1     1     1     1     1     1     1     1
1239 126 0.12     1     1     1     1     1     1     1     1     1     1     1
1240 127 0.12     1     1     1     1     1     1     1     1     1     1     1
1241 128 0.12     1     1     1     1     1     1     1     1     1     1     1
1242 129 0.12     1     1     1     1     1     1     1     1     1     1     1
1243 130 0.12     1     1     1     1     1     1     1     1     1     1     1
1244 131 0.12     1     1     1     1     1     1     1     1     1     1     1
1245 132 0.12     1     1     1     1     1     1     1     1     1     1     1
1246 133 0.12     1     1     1     1     1     1     1     1     1     1     1
1247 134 0.12     1     1     1     1     1     1     1     1     1     1     1
1248 135 0.12     1     1     1     1     1     1     1     1     1     1     1
1249 136 0.12     1     1     1     1     1     1     1     1     1     1     1
1250 137 0.12     1     1     1     1     1     1     1     1     1     1     1
1251 138 0.12     1     1     1     1     1     1     1     1     1     1     1
1252 139 0.12     1     1     1     1     1     1     1     1     1     1     1
1253 140 0.12     1     1     1     1     1     1     1     1     1     1     1
1254 141 0.12     1     1     1     1     1     1     1     1     1     1     1
1255 142 0.12     1     1     1     1     1     1     1     1     1     1     1
1256 143 0.12     1     1     1     1     1     1     1     1     1     1     1
1257 144 0.12     1     1     1     1     1     1     1     1     1     1     1
1258 145 0.12     1     1     1     1     1     1     1     1     1     1     1
1259 146 0.12     1     1     1     1     1     1     1     1     1     1     1
1260 147 0.12     1     1     1     1     1     1     1     1     1     1     1
1261 148 0.12     1     1     1     1     1     1     1     1     1     1     1
1262 149 0.12     1     1     1     1     1     1     1     1     1     1     1
1263 150 0.12     1     1     1     1     1     1     1     1     1     1     1
1264 151 0.12     1     1     1     1     1     1     1     1     1     1     1
1265 152 0.12     1     1     1     1     1     1     1     1     1     1     1
1266 153 0.12     1     1     1     1     1     1     1     1     1     1     1
1267 154 0.12     1     1     1     1     1     1     1     1     1     1     1
1268 155 0.12     1     1     1     1     1     1     1     1     1     1     1
1269 156 0.12     1     1     1     1     1     1     1     1     1     1     1
1270 157 0.12     1     1     1     1     1     1     1     1     1     1     1
1271 158 0.12     1     1     1     1     1     1     1     1     1     1     1
1272 159 0.12     1     1     1     1     1     1     1     1     1     1     1
1273 160 0.12     1     1     1     1     1     1     1     1     1     1     1
1274 161 0.12     1     1     1     1     1     1     1     1     1     1     1
1275 162 0.12     1     1     1     1     1     1     1     1     1     1     1
1276 163 0.12     1     1     1     1     1     1     1     1     1     1     1
1277 164 0.12     1     1     1     1     1     1     1     1     1     1     1
1278 165 0.12     1     1     1     1     1     1     1     1     1     1     1
1279 166 0.12     1     1     1     1     1     1     1     1     1     1     1
1280 167 0.12     1     1     1     1     1     1     1     1     1     1     1
1281 168 0.12     1     1     1     1     1     1     1     1     1     1     1
1282 169 0.12     1     1     1     1     1     1     1     1     1     1     1
1283 170 0.12     1     1     1     1     1     1     1     1     1     1     1
1284 171 0.12     1     1     1     1     1     1     1     1     1     1     1
1285 172 0.12     1     1     1     1     1     1     1     1     1     1     1
1286 173 0.12     1     1     1     1     1     1     1     1     1     1     1
1287 174 0.12     1     1     1     1     1     1     1     1     1     1     1
1288 175 0.12     1     1     1     1     1     1     1     1     1     1     1
1289 176 0.12     1     1     1     1     1     1     1     1     1     1     1
1290 177 0.12     1     1     1     1     1     1     1     1     1     1     1
1291 178 0.12     1     1     1     1     1     1     1     1     1     1     1
1292 179 0.12     1     1     1     1     1     1     1     1     1     1     1
1293 180 0.12     1     1     1     1     1     1     1     1     1     1     1
1294 181 0.12     1     1     1     1     1     1     1     1     1     1     1
1295 182 0.12     1     1     1     1     1     1     1     1     1     1     1
1296 183 0.12     1     1     1     1     1     1     1     1     1     1     1
1297 184 0.12     1     1     1     1     1     1     1     1     1     1     1
1298 185 0.12     1     1     1     1     1     1     1     1     1     1     1
1299 186 0.12     1     1     1     1     1     1     1     1     1     1     1
1300 187 0.12     1     1     1     1     1     1     1     1     1     1     1
1301 188 0.12     1     1     1     1     1     1     1     1     1     1     1
1302 189 0.12     1     1     1     1     1     1     1     1     1     1     1
1303 190 0.12     1     1     1     1     1     1     1     1     1     1     1
1304 191 0.12     1     1     1     1     1     1     1     1     1     1     1
1305 192 0.12     1     1     1     1     1     1     1     1     1     1     1
1306 193 0.12     1     1     1     1     1     1     1     1     1     1     1
1307 194 0.12     1     1     1     1     1     1     1     1     1     1     1
1308 195 0.12     1     1     1     1     1     1     1     1     1     1     1
1309 196 0.12     1     1     1     1     1     1     1     1     1     1     1
1310 197 0.12     1     1     1     1     1     1     1     1     1     1     1
1311 198 0.12     1     1     1     1     1     1     1     1     1     1     1
1312 199 0.12     1     1     1     1     1     1     1     1     1     1     1
1313 200 0.12     1     1     1     1     1     1     1     1     1     1     1
1314 100 0.13     1     1     1     1     1     1     1     1     1     1     1
1315 101 0.13     1     1     1     1     1     1     1     1     1     1     1
1316 102 0.13     1     1     1     1     1     1     1     1     1     1     1
1317 103 0.13     1     1     1     1     1     1     1     1     1     1     1
1318 104 0.13     1     1     1     1     1     1     1     1     1     1     1
1319 105 0.13     1     1     1     1     1     1     1     1     1     1     1
1320 106 0.13     1     1     1     1     1     1     1     1     1     1     1
1321 107 0.13     1     1     1     1     1     1     1     1     1     1     1
1322 108 0.13     1     1     1     1     1     1     1     1     1     1     1
1323 109 0.13     1     1     1     1     1     1     1     1     1     1     1
1324 110 0.13     1     1     1     1     1     1     1     1     1     1     1
1325 111 0.13     1     1     1     1     1     1     1     1     1     1     1
1326 112 0.13     1     1     1     1     1     1     1     1     1     1     1
1327 113 0.13     1     1     1     1     1     1     1     1     1     1     1
1328 114 0.13     1     1     1     1     1     1     1     1     1     1     1
1329 115 0.13     1     1     1     1     1     1     1     1     1     1     1
1330 116 0.13     1     1     1     1     1     1     1     1     1     1     1
1331 117 0.13     1     1     1     1     1     1     1     1     1     1     1
1332 118 0.13     1     1     1     1     1     1     1     1     1     1     1
1333 119 0.13     1     1     1     1     1     1     1     1     1     1     1
1334 120 0.13     1     1     1     1     1     1     1     1     1     1     1
1335 121 0.13     1     1     1     1     1     1     1     1     1     1     1
1336 122 0.13     1     1     1     1     1     1     1     1     1     1     1
1337 123 0.13     1     1     1     1     1     1     1     1     1     1     1
1338 124 0.13     1     1     1     1     1     1     1     1     1     1     1
1339 125 0.13     1     1     1     1     1     1     1     1     1     1     1
1340 126 0.13     1     1     1     1     1     1     1     1     1     1     1
1341 127 0.13     1     1     1     1     1     1     1     1     1     1     1
1342 128 0.13     1     1     1     1     1     1     1     1     1     1     1
1343 129 0.13     1     1     1     1     1     1     1     1     1     1     1
1344 130 0.13     1     1     1     1     1     1     1     1     1     1     1
1345 131 0.13     1     1     1     1     1     1     1     1     1     1     1
1346 132 0.13     1     1     1     1     1     1     1     1     1     1     1
1347 133 0.13     1     1     1     1     1     1     1     1     1     1     1
1348 134 0.13     1     1     1     1     1     1     1     1     1     1     1
1349 135 0.13     1     1     1     1     1     1     1     1     1     1     1
1350 136 0.13     1     1     1     1     1     1     1     1     1     1     1
1351 137 0.13     1     1     1     1     1     1     1     1     1     1     1
1352 138 0.13     1     1     1     1     1     1     1     1     1     1     1
1353 139 0.13     1     1     1     1     1     1     1     1     1     1     1
1354 140 0.13     1     1     1     1     1     1     1     1     1     1     1
1355 141 0.13     1     1     1     1     1     1     1     1     1     1     1
1356 142 0.13     1     1     1     1     1     1     1     1     1     1     1
1357 143 0.13     1     1     1     1     1     1     1     1     1     1     1
1358 144 0.13     1     1     1     1     1     1     1     1     1     1     1
1359 145 0.13     1     1     1     1     1     1     1     1     1     1     1
1360 146 0.13     1     1     1     1     1     1     1     1     1     1     1
1361 147 0.13     1     1     1     1     1     1     1     1     1     1     1
1362 148 0.13     1     1     1     1     1     1     1     1     1     1     1
1363 149 0.13     1     1     1     1     1     1     1     1     1     1     1
1364 150 0.13     1     1     1     1     1     1     1     1     1     1     1
1365 151 0.13     1     1     1     1     1     1     1     1     1     1     1
1366 152 0.13     1     1     1     1     1     1     1     1     1     1     1
1367 153 0.13     1     1     1     1     1     1     1     1     1     1     1
1368 154 0.13     1     1     1     1     1     1     1     1     1     1     1
1369 155 0.13     1     1     1     1     1     1     1     1     1     1     1
1370 156 0.13     1     1     1     1     1     1     1     1     1     1     1
1371 157 0.13     1     1     1     1     1     1     1     1     1     1     1
1372 158 0.13     1     1     1     1     1     1     1     1     1     1     1
1373 159 0.13     1     1     1     1     1     1     1     1     1     1     1
1374 160 0.13     1     1     1     1     1     1     1     1     1     1     1
1375 161 0.13     1     1     1     1     1     1     1     1     1     1     1
1376 162 0.13     1     1     1     1     1     1     1     1     1     1     1
1377 163 0.13     1     1     1     1     1     1     1     1     1     1     1
1378 164 0.13     1     1     1     1     1     1     1     1     1     1     1
1379 165 0.13     1     1     1     1     1     1     1     1     1     1     1
1380 166 0.13     1     1     1     1     1     1     1     1     1     1     1
1381 167 0.13     1     1     1     1     1     1     1     1     1     1     1
1382 168 0.13     1     1     1     1     1     1     1     1     1     1     1
1383 169 0.13     1     1     1     1     1     1     1     1     1     1     1
1384 170 0.13     1     1     1     1     1     1     1     1     1     1     1
1385 171 0.13     1     1     1     1     1     1     1     1     1     1     1
1386 172 0.13     1     1     1     1     1     1     1     1     1     1     1
1387 173 0.13     1     1     1     1     1     1     1     1     1     1     1
1388 174 0.13     1     1     1     1     1     1     1     1     1     1     1
1389 175 0.13     1     1     1     1     1     1     1     1     1     1     1
1390 176 0.13     1     1     1     1     1     1     1     1     1     1     1
1391 177 0.13     1     1     1     1     1     1     1     1     1     1     1
1392 178 0.13     1     1     1     1     1     1     1     1     1     1     1
1393 179 0.13     1     1     1     1     1     1     1     1     1     1     1
1394 180 0.13     1     1     1     1     1     1     1     1     1     1     1
1395 181 0.13     1     1     1     1     1     1     1     1     1     1     1
1396 182 0.13     1     1     1     1     1     1     1     1     1     1     1
1397 183 0.13     1     1     1     1     1     1     1     1     1     1     1
1398 184 0.13     1     1     1     1     1     1     1     1     1     1     1
1399 185 0.13     1     1     1     1     1     1     1     1     1     1     1
1400 186 0.13     1     1     1     1     1     1     1     1     1     1     1
1401 187 0.13     1     1     1     1     1     1     1     1     1     1     1
1402 188 0.13     1     1     1     1     1     1     1     1     1     1     1
1403 189 0.13     1     1     1     1     1     1     1     1     1     1     1
1404 190 0.13     1     1     1     1     1     1     1     1     1     1     1
1405 191 0.13     1     1     1     1     1     1     1     1     1     1     1
1406 192 0.13     1     1     1     1     1     1     1     1     1     1     1
1407 193 0.13     1     1     1     1     1     1     1     1     1     1     1
1408 194 0.13     1     1     1     1     1     1     1     1     1     1     1
1409 195 0.13     1     1     1     1     1     1     1     1     1     1     1
1410 196 0.13     1     1     1     1     1     1     1     1     1     1     1
1411 197 0.13     1     1     1     1     1     1     1     1     1     1     1
1412 198 0.13     1     1     1     1     1     1     1     1     1     1     1
1413 199 0.13     1     1     1     1     1     1     1     1     1     1     1
1414 200 0.13     1     1     1     1     1     1     1     1     1     1     1
1415 100 0.14     1     1     1     1     1     1     1     1     1     1     1
1416 101 0.14     1     1     1     1     1     1     1     1     1     1     1
1417 102 0.14     1     1     1     1     1     1     1     1     1     1     1
1418 103 0.14     1     1     1     1     1     1     1     1     1     1     1
1419 104 0.14     1     1     1     1     1     1     1     1     1     1     1
1420 105 0.14     1     1     1     1     1     1     1     1     1     1     1
1421 106 0.14     1     1     1     1     1     1     1     1     1     1     1
1422 107 0.14     1     1     1     1     1     1     1     1     1     1     1
1423 108 0.14     1     1     1     1     1     1     1     1     1     1     1
1424 109 0.14     1     1     1     1     1     1     1     1     1     1     1
1425 110 0.14     1     1     1     1     1     1     1     1     1     1     1
1426 111 0.14     1     1     1     1     1     1     1     1     1     1     1
1427 112 0.14     1     1     1     1     1     1     1     1     1     1     1
1428 113 0.14     1     1     1     1     1     1     1     1     1     1     1
1429 114 0.14     1     1     1     1     1     1     1     1     1     1     1
1430 115 0.14     1     1     1     1     1     1     1     1     1     1     1
1431 116 0.14     1     1     1     1     1     1     1     1     1     1     1
1432 117 0.14     1     1     1     1     1     1     1     1     1     1     1
1433 118 0.14     1     1     1     1     1     1     1     1     1     1     1
1434 119 0.14     1     1     1     1     1     1     1     1     1     1     1
1435 120 0.14     1     1     1     1     1     1     1     1     1     1     1
1436 121 0.14     1     1     1     1     1     1     1     1     1     1     1
1437 122 0.14     1     1     1     1     1     1     1     1     1     1     1
1438 123 0.14     1     1     1     1     1     1     1     1     1     1     1
1439 124 0.14     1     1     1     1     1     1     1     1     1     1     1
1440 125 0.14     1     1     1     1     1     1     1     1     1     1     1
1441 126 0.14     1     1     1     1     1     1     1     1     1     1     1
1442 127 0.14     1     1     1     1     1     1     1     1     1     1     1
1443 128 0.14     1     1     1     1     1     1     1     1     1     1     1
1444 129 0.14     1     1     1     1     1     1     1     1     1     1     1
1445 130 0.14     1     1     1     1     1     1     1     1     1     1     1
1446 131 0.14     1     1     1     1     1     1     1     1     1     1     1
1447 132 0.14     1     1     1     1     1     1     1     1     1     1     1
1448 133 0.14     1     1     1     1     1     1     1     1     1     1     1
1449 134 0.14     1     1     1     1     1     1     1     1     1     1     1
1450 135 0.14     1     1     1     1     1     1     1     1     1     1     1
1451 136 0.14     1     1     1     1     1     1     1     1     1     1     1
1452 137 0.14     1     1     1     1     1     1     1     1     1     1     1
1453 138 0.14     1     1     1     1     1     1     1     1     1     1     1
1454 139 0.14     1     1     1     1     1     1     1     1     1     1     1
1455 140 0.14     1     1     1     1     1     1     1     1     1     1     1
1456 141 0.14     1     1     1     1     1     1     1     1     1     1     1
1457 142 0.14     1     1     1     1     1     1     1     1     1     1     1
1458 143 0.14     1     1     1     1     1     1     1     1     1     1     1
1459 144 0.14     1     1     1     1     1     1     1     1     1     1     1
1460 145 0.14     1     1     1     1     1     1     1     1     1     1     1
1461 146 0.14     1     1     1     1     1     1     1     1     1     1     1
1462 147 0.14     1     1     1     1     1     1     1     1     1     1     1
1463 148 0.14     1     1     1     1     1     1     1     1     1     1     1
1464 149 0.14     1     1     1     1     1     1     1     1     1     1     1
1465 150 0.14     1     1     1     1     1     1     1     1     1     1     1
1466 151 0.14     1     1     1     1     1     1     1     1     1     1     1
1467 152 0.14     1     1     1     1     1     1     1     1     1     1     1
1468 153 0.14     1     1     1     1     1     1     1     1     1     1     1
1469 154 0.14     1     1     1     1     1     1     1     1     1     1     1
1470 155 0.14     1     1     1     1     1     1     1     1     1     1     1
1471 156 0.14     1     1     1     1     1     1     1     1     1     1     1
1472 157 0.14     1     1     1     1     1     1     1     1     1     1     1
1473 158 0.14     1     1     1     1     1     1     1     1     1     1     1
1474 159 0.14     1     1     1     1     1     1     1     1     1     1     1
1475 160 0.14     1     1     1     1     1     1     1     1     1     1     1
1476 161 0.14     1     1     1     1     1     1     1     1     1     1     1
1477 162 0.14     1     1     1     1     1     1     1     1     1     1     1
1478 163 0.14     1     1     1     1     1     1     1     1     1     1     1
1479 164 0.14     1     1     1     1     1     1     1     1     1     1     1
1480 165 0.14     1     1     1     1     1     1     1     1     1     1     1
1481 166 0.14     1     1     1     1     1     1     1     1     1     1     1
1482 167 0.14     1     1     1     1     1     1     1     1     1     1     1
1483 168 0.14     1     1     1     1     1     1     1     1     1     1     1
1484 169 0.14     1     1     1     1     1     1     1     1     1     1     1
1485 170 0.14     1     1     1     1     1     1     1     1     1     1     1
1486 171 0.14     1     1     1     1     1     1     1     1     1     1     1
1487 172 0.14     1     1     1     1     1     1     1     1     1     1     1
1488 173 0.14     1     1     1     1     1     1     1     1     1     1     1
1489 174 0.14     1     1     1     1     1     1     1     1     1     1     1
1490 175 0.14     1     1     1     1     1     1     1     1     1     1     1
1491 176 0.14     1     1     1     1     1     1     1     1     1     1     1
1492 177 0.14     1     1     1     1     1     1     1     1     1     1     1
1493 178 0.14     1     1     1     1     1     1     1     1     1     1     1
1494 179 0.14     1     1     1     1     1     1     1     1     1     1     1
1495 180 0.14     1     1     1     1     1     1     1     1     1     1     1
1496 181 0.14     1     1     1     1     1     1     1     1     1     1     1
1497 182 0.14     1     1     1     1     1     1     1     1     1     1     1
1498 183 0.14     1     1     1     1     1     1     1     1     1     1     1
1499 184 0.14     1     1     1     1     1     1     1     1     1     1     1
1500 185 0.14     1     1     1     1     1     1     1     1     1     1     1
1501 186 0.14     1     1     1     1     1     1     1     1     1     1     1
1502 187 0.14     1     1     1     1     1     1     1     1     1     1     1
1503 188 0.14     1     1     1     1     1     1     1     1     1     1     1
1504 189 0.14     1     1     1     1     1     1     1     1     1     1     1
1505 190 0.14     1     1     1     1     1     1     1     1     1     1     1
1506 191 0.14     1     1     1     1     1     1     1     1     1     1     1
1507 192 0.14     1     1     1     1     1     1     1     1     1     1     1
1508 193 0.14     1     1     1     1     1     1     1     1     1     1     1
1509 194 0.14     1     1     1     1     1     1     1     1     1     1     1
1510 195 0.14     1     1     1     1     1     1     1     1     1     1     1
1511 196 0.14     1     1     1     1     1     1     1     1     1     1     1
1512 197 0.14     1     1     1     1     1     1     1     1     1     1     1
1513 198 0.14     1     1     1     1     1     1     1     1     1     1     1
1514 199 0.14     1     1     1     1     1     1     1     1     1     1     1
1515 200 0.14     1     1     1     1     1     1     1     1     1     1     1
1516 100 0.15     1     1     1     1     1     1     1     1     1     1     1
1517 101 0.15     1     1     1     1     1     1     1     1     1     1     1
1518 102 0.15     1     1     1     1     1     1     1     1     1     1     1
1519 103 0.15     1     1     1     1     1     1     1     1     1     1     1
1520 104 0.15     1     1     1     1     1     1     1     1     1     1     1
1521 105 0.15     1     1     1     1     1     1     1     1     1     1     1
1522 106 0.15     1     1     1     1     1     1     1     1     1     1     1
1523 107 0.15     1     1     1     1     1     1     1     1     1     1     1
1524 108 0.15     1     1     1     1     1     1     1     1     1     1     1
1525 109 0.15     1     1     1     1     1     1     1     1     1     1     1
1526 110 0.15     1     1     1     1     1     1     1     1     1     1     1
1527 111 0.15     1     1     1     1     1     1     1     1     1     1     1
1528 112 0.15     1     1     1     1     1     1     1     1     1     1     1
1529 113 0.15     1     1     1     1     1     1     1     1     1     1     1
1530 114 0.15     1     1     1     1     1     1     1     1     1     1     1
1531 115 0.15     1     1     1     1     1     1     1     1     1     1     1
1532 116 0.15     1     1     1     1     1     1     1     1     1     1     1
1533 117 0.15     1     1     1     1     1     1     1     1     1     1     1
1534 118 0.15     1     1     1     1     1     1     1     1     1     1     1
1535 119 0.15     1     1     1     1     1     1     1     1     1     1     1
1536 120 0.15     1     1     1     1     1     1     1     1     1     1     1
1537 121 0.15     1     1     1     1     1     1     1     1     1     1     1
1538 122 0.15     1     1     1     1     1     1     1     1     1     1     1
1539 123 0.15     1     1     1     1     1     1     1     1     1     1     1
1540 124 0.15     1     1     1     1     1     1     1     1     1     1     1
1541 125 0.15     1     1     1     1     1     1     1     1     1     1     1
1542 126 0.15     1     1     1     1     1     1     1     1     1     1     1
1543 127 0.15     1     1     1     1     1     1     1     1     1     1     1
1544 128 0.15     1     1     1     1     1     1     1     1     1     1     1
1545 129 0.15     1     1     1     1     1     1     1     1     1     1     1
1546 130 0.15     1     1     1     1     1     1     1     1     1     1     1
1547 131 0.15     1     1     1     1     1     1     1     1     1     1     1
1548 132 0.15     1     1     1     1     1     1     1     1     1     1     1
1549 133 0.15     1     1     1     1     1     1     1     1     1     1     1
1550 134 0.15     1     1     1     1     1     1     1     1     1     1     1
1551 135 0.15     1     1     1     1     1     1     1     1     1     1     1
1552 136 0.15     1     1     1     1     1     1     1     1     1     1     1
1553 137 0.15     1     1     1     1     1     1     1     1     1     1     1
1554 138 0.15     1     1     1     1     1     1     1     1     1     1     1
1555 139 0.15     1     1     1     1     1     1     1     1     1     1     1
1556 140 0.15     1     1     1     1     1     1     1     1     1     1     1
1557 141 0.15     1     1     1     1     1     1     1     1     1     1     1
1558 142 0.15     1     1     1     1     1     1     1     1     1     1     1
1559 143 0.15     1     1     1     1     1     1     1     1     1     1     1
1560 144 0.15     1     1     1     1     1     1     1     1     1     1     1
1561 145 0.15     1     1     1     1     1     1     1     1     1     1     1
1562 146 0.15     1     1     1     1     1     1     1     1     1     1     1
1563 147 0.15     1     1     1     1     1     1     1     1     1     1     1
1564 148 0.15     1     1     1     1     1     1     1     1     1     1     1
1565 149 0.15     1     1     1     1     1     1     1     1     1     1     1
1566 150 0.15     1     1     1     1     1     1     1     1     1     1     1
1567 151 0.15     1     1     1     1     1     1     1     1     1     1     1
1568 152 0.15     1     1     1     1     1     1     1     1     1     1     1
1569 153 0.15     1     1     1     1     1     1     1     1     1     1     1
1570 154 0.15     1     1     1     1     1     1     1     1     1     1     1
1571 155 0.15     1     1     1     1     1     1     1     1     1     1     1
1572 156 0.15     1     1     1     1     1     1     1     1     1     1     1
1573 157 0.15     1     1     1     1     1     1     1     1     1     1     1
1574 158 0.15     1     1     1     1     1     1     1     1     1     1     1
1575 159 0.15     1     1     1     1     1     1     1     1     1     1     1
1576 160 0.15     1     1     1     1     1     1     1     1     1     1     1
1577 161 0.15     1     1     1     1     1     1     1     1     1     1     1
1578 162 0.15     1     1     1     1     1     1     1     1     1     1     1
1579 163 0.15     1     1     1     1     1     1     1     1     1     1     1
1580 164 0.15     1     1     1     1     1     1     1     1     1     1     1
1581 165 0.15     1     1     1     1     1     1     1     1     1     1     1
1582 166 0.15     1     1     1     1     1     1     1     1     1     1     1
1583 167 0.15     1     1     1     1     1     1     1     1     1     1     1
1584 168 0.15     1     1     1     1     1     1     1     1     1     1     1
1585 169 0.15     1     1     1     1     1     1     1     1     1     1     1
1586 170 0.15     1     1     1     1     1     1     1     1     1     1     1
1587 171 0.15     1     1     1     1     1     1     1     1     1     1     1
1588 172 0.15     1     1     1     1     1     1     1     1     1     1     1
1589 173 0.15     1     1     1     1     1     1     1     1     1     1     1
1590 174 0.15     1     1     1     1     1     1     1     1     1     1     1
1591 175 0.15     1     1     1     1     1     1     1     1     1     1     1
1592 176 0.15     1     1     1     1     1     1     1     1     1     1     1
1593 177 0.15     1     1     1     1     1     1     1     1     1     1     1
1594 178 0.15     1     1     1     1     1     1     1     1     1     1     1
1595 179 0.15     1     1     1     1     1     1     1     1     1     1     1
1596 180 0.15     1     1     1     1     1     1     1     1     1     1     1
1597 181 0.15     1     1     1     1     1     1     1     1     1     1     1
1598 182 0.15     1     1     1     1     1     1     1     1     1     1     1
1599 183 0.15     1     1     1     1     1     1     1     1     1     1     1
1600 184 0.15     1     1     1     1     1     1     1     1     1     1     1
1601 185 0.15     1     1     1     1     1     1     1     1     1     1     1
1602 186 0.15     1     1     1     1     1     1     1     1     1     1     1
1603 187 0.15     1     1     1     1     1     1     1     1     1     1     1
1604 188 0.15     1     1     1     1     1     1     1     1     1     1     1
1605 189 0.15     1     1     1     1     1     1     1     1     1     1     1
1606 190 0.15     1     1     1     1     1     1     1     1     1     1     1
1607 191 0.15     1     1     1     1     1     1     1     1     1     1     1
1608 192 0.15     1     1     1     1     1     1     1     1     1     1     1
1609 193 0.15     1     1     1     1     1     1     1     1     1     1     1
1610 194 0.15     1     1     1     1     1     1     1     1     1     1     1
1611 195 0.15     1     1     1     1     1     1     1     1     1     1     1
1612 196 0.15     1     1     1     1     1     1     1     1     1     1     1
1613 197 0.15     1     1     1     1     1     1     1     1     1     1     1
1614 198 0.15     1     1     1     1     1     1     1     1     1     1     1
1615 199 0.15     1     1     1     1     1     1     1     1     1     1     1
1616 200 0.15     1     1     1     1     1     1     1     1     1     1     1
1617 100 0.16     1     1     1     1     1     1     1     1     1     1     1
1618 101 0.16     1     1     1     1     1     1     1     1     1     1     1
1619 102 0.16     1     1     1     1     1     1     1     1     1     1     1
1620 103 0.16     1     1     1     1     1     1     1     1     1     1     1
1621 104 0.16     1     1     1     1     1     1     1     1     1     1     1
1622 105 0.16     1     1     1     1     1     1     1     1     1     1     1
1623 106 0.16     1     1     1     1     1     1     1     1     1     1     1
1624 107 0.16     1     1     1     1     1     1     1     1     1     1     1
1625 108 0.16     1     1     1     1     1     1     1     1     1     1     1
1626 109 0.16     1     1     1     1     1     1     1     1     1     1     1
1627 110 0.16     1     1     1     1     1     1     1     1     1     1     1
1628 111 0.16     1     1     1     1     1     1     1     1     1     1     1
1629 112 0.16     1     1     1     1     1     1     1     1     1     1     1
1630 113 0.16     1     1     1     1     1     1     1     1     1     1     1
1631 114 0.16     1     1     1     1     1     1     1     1     1     1     1
1632 115 0.16     1     1     1     1     1     1     1     1     1     1     1
1633 116 0.16     1     1     1     1     1     1     1     1     1     1     1
1634 117 0.16     1     1     1     1     1     1     1     1     1     1     1
1635 118 0.16     1     1     1     1     1     1     1     1     1     1     1
1636 119 0.16     1     1     1     1     1     1     1     1     1     1     1
1637 120 0.16     1     1     1     1     1     1     1     1     1     1     1
1638 121 0.16     1     1     1     1     1     1     1     1     1     1     1
1639 122 0.16     1     1     1     1     1     1     1     1     1     1     1
1640 123 0.16     1     1     1     1     1     1     1     1     1     1     1
1641 124 0.16     1     1     1     1     1     1     1     1     1     1     1
1642 125 0.16     1     1     1     1     1     1     1     1     1     1     1
1643 126 0.16     1     1     1     1     1     1     1     1     1     1     1
1644 127 0.16     1     1     1     1     1     1     1     1     1     1     1
1645 128 0.16     1     1     1     1     1     1     1     1     1     1     1
1646 129 0.16     1     1     1     1     1     1     1     1     1     1     1
1647 130 0.16     1     1     1     1     1     1     1     1     1     1     1
1648 131 0.16     1     1     1     1     1     1     1     1     1     1     1
1649 132 0.16     1     1     1     1     1     1     1     1     1     1     1
1650 133 0.16     1     1     1     1     1     1     1     1     1     1     1
1651 134 0.16     1     1     1     1     1     1     1     1     1     1     1
1652 135 0.16     1     1     1     1     1     1     1     1     1     1     1
1653 136 0.16     1     1     1     1     1     1     1     1     1     1     1
1654 137 0.16     1     1     1     1     1     1     1     1     1     1     1
1655 138 0.16     1     1     1     1     1     1     1     1     1     1     1
1656 139 0.16     1     1     1     1     1     1     1     1     1     1     1
1657 140 0.16     1     1     1     1     1     1     1     1     1     1     1
1658 141 0.16     1     1     1     1     1     1     1     1     1     1     1
1659 142 0.16     1     1     1     1     1     1     1     1     1     1     1
1660 143 0.16     1     1     1     1     1     1     1     1     1     1     1
1661 144 0.16     1     1     1     1     1     1     1     1     1     1     1
1662 145 0.16     1     1     1     1     1     1     1     1     1     1     1
1663 146 0.16     1     1     1     1     1     1     1     1     1     1     1
1664 147 0.16     1     1     1     1     1     1     1     1     1     1     1
1665 148 0.16     1     1     1     1     1     1     1     1     1     1     1
1666 149 0.16     1     1     1     1     1     1     1     1     1     1     1
1667 150 0.16     1     1     1     1     1     1     1     1     1     1     1
1668 151 0.16     1     1     1     1     1     1     1     1     1     1     1
1669 152 0.16     1     1     1     1     1     1     1     1     1     1     1
1670 153 0.16     1     1     1     1     1     1     1     1     1     1     1
1671 154 0.16     1     1     1     1     1     1     1     1     1     1     1
1672 155 0.16     1     1     1     1     1     1     1     1     1     1     1
1673 156 0.16     1     1     1     1     1     1     1     1     1     1     1
1674 157 0.16     1     1     1     1     1     1     1     1     1     1     1
1675 158 0.16     1     1     1     1     1     1     1     1     1     1     1
1676 159 0.16     1     1     1     1     1     1     1     1     1     1     1
1677 160 0.16     1     1     1     1     1     1     1     1     1     1     1
1678 161 0.16     1     1     1     1     1     1     1     1     1     1     1
1679 162 0.16     1     1     1     1     1     1     1     1     1     1     1
1680 163 0.16     1     1     1     1     1     1     1     1     1     1     1
1681 164 0.16     1     1     1     1     1     1     1     1     1     1     1
1682 165 0.16     1     1     1     1     1     1     1     1     1     1     1
1683 166 0.16     1     1     1     1     1     1     1     1     1     1     1
1684 167 0.16     1     1     1     1     1     1     1     1     1     1     1
1685 168 0.16     1     1     1     1     1     1     1     1     1     1     1
1686 169 0.16     1     1     1     1     1     1     1     1     1     1     1
1687 170 0.16     1     1     1     1     1     1     1     1     1     1     1
1688 171 0.16     1     1     1     1     1     1     1     1     1     1     1
1689 172 0.16     1     1     1     1     1     1     1     1     1     1     1
1690 173 0.16     1     1     1     1     1     1     1     1     1     1     1
1691 174 0.16     1     1     1     1     1     1     1     1     1     1     1
1692 175 0.16     1     1     1     1     1     1     1     1     1     1     1
1693 176 0.16     1     1     1     1     1     1     1     1     1     1     1
1694 177 0.16     1     1     1     1     1     1     1     1     1     1     1
1695 178 0.16     1     1     1     1     1     1     1     1     1     1     1
1696 179 0.16     1     1     1     1     1     1     1     1     1     1     1
1697 180 0.16     1     1     1     1     1     1     1     1     1     1     1
1698 181 0.16     1     1     1     1     1     1     1     1     1     1     1
1699 182 0.16     1     1     1     1     1     1     1     1     1     1     1
1700 183 0.16     1     1     1     1     1     1     1     1     1     1     1
1701 184 0.16     1     1     1     1     1     1     1     1     1     1     1
1702 185 0.16     1     1     1     1     1     1     1     1     1     1     1
1703 186 0.16     1     1     1     1     1     1     1     1     1     1     1
1704 187 0.16     1     1     1     1     1     1     1     1     1     1     1
1705 188 0.16     1     1     1     1     1     1     1     1     1     1     1
1706 189 0.16     1     1     1     1     1     1     1     1     1     1     1
1707 190 0.16     1     1     1     1     1     1     1     1     1     1     1
1708 191 0.16     1     1     1     1     1     1     1     1     1     1     1
1709 192 0.16     1     1     1     1     1     1     1     1     1     1     1
1710 193 0.16     1     1     1     1     1     1     1     1     1     1     1
1711 194 0.16     1     1     1     1     1     1     1     1     1     1     1
1712 195 0.16     1     1     1     1     1     1     1     1     1     1     1
1713 196 0.16     1     1     1     1     1     1     1     1     1     1     1
1714 197 0.16     1     1     1     1     1     1     1     1     1     1     1
1715 198 0.16     1     1     1     1     1     1     1     1     1     1     1
1716 199 0.16     1     1     1     1     1     1     1     1     1     1     1
1717 200 0.16     1     1     1     1     1     1     1     1     1     1     1
1718 100 0.17     1     1     1     1     1     1     1     1     1     1     1
1719 101 0.17     1     1     1     1     1     1     1     1     1     1     1
1720 102 0.17     1     1     1     1     1     1     1     1     1     1     1
1721 103 0.17     1     1     1     1     1     1     1     1     1     1     1
1722 104 0.17     1     1     1     1     1     1     1     1     1     1     1
1723 105 0.17     1     1     1     1     1     1     1     1     1     1     1
1724 106 0.17     1     1     1     1     1     1     1     1     1     1     1
1725 107 0.17     1     1     1     1     1     1     1     1     1     1     1
1726 108 0.17     1     1     1     1     1     1     1     1     1     1     1
1727 109 0.17     1     1     1     1     1     1     1     1     1     1     1
1728 110 0.17     1     1     1     1     1     1     1     1     1     1     1
1729 111 0.17     1     1     1     1     1     1     1     1     1     1     1
1730 112 0.17     1     1     1     1     1     1     1     1     1     1     1
1731 113 0.17     1     1     1     1     1     1     1     1     1     1     1
1732 114 0.17     1     1     1     1     1     1     1     1     1     1     1
1733 115 0.17     1     1     1     1     1     1     1     1     1     1     1
1734 116 0.17     1     1     1     1     1     1     1     1     1     1     1
1735 117 0.17     1     1     1     1     1     1     1     1     1     1     1
1736 118 0.17     1     1     1     1     1     1     1     1     1     1     1
1737 119 0.17     1     1     1     1     1     1     1     1     1     1     1
1738 120 0.17     1     1     1     1     1     1     1     1     1     1     1
1739 121 0.17     1     1     1     1     1     1     1     1     1     1     1
1740 122 0.17     1     1     1     1     1     1     1     1     1     1     1
1741 123 0.17     1     1     1     1     1     1     1     1     1     1     1
1742 124 0.17     1     1     1     1     1     1     1     1     1     1     1
1743 125 0.17     1     1     1     1     1     1     1     1     1     1     1
1744 126 0.17     1     1     1     1     1     1     1     1     1     1     1
1745 127 0.17     1     1     1     1     1     1     1     1     1     1     1
1746 128 0.17     1     1     1     1     1     1     1     1     1     1     1
1747 129 0.17     1     1     1     1     1     1     1     1     1     1     1
1748 130 0.17     1     1     1     1     1     1     1     1     1     1     1
1749 131 0.17     1     1     1     1     1     1     1     1     1     1     1
1750 132 0.17     1     1     1     1     1     1     1     1     1     1     1
1751 133 0.17     1     1     1     1     1     1     1     1     1     1     1
1752 134 0.17     1     1     1     1     1     1     1     1     1     1     1
1753 135 0.17     1     1     1     1     1     1     1     1     1     1     1
1754 136 0.17     1     1     1     1     1     1     1     1     1     1     1
1755 137 0.17     1     1     1     1     1     1     1     1     1     1     1
1756 138 0.17     1     1     1     1     1     1     1     1     1     1     1
1757 139 0.17     1     1     1     1     1     1     1     1     1     1     1
1758 140 0.17     1     1     1     1     1     1     1     1     1     1     1
1759 141 0.17     1     1     1     1     1     1     1     1     1     1     1
1760 142 0.17     1     1     1     1     1     1     1     1     1     1     1
1761 143 0.17     1     1     1     1     1     1     1     1     1     1     1
1762 144 0.17     1     1     1     1     1     1     1     1     1     1     1
1763 145 0.17     1     1     1     1     1     1     1     1     1     1     1
1764 146 0.17     1     1     1     1     1     1     1     1     1     1     1
1765 147 0.17     1     1     1     1     1     1     1     1     1     1     1
1766 148 0.17     1     1     1     1     1     1     1     1     1     1     1
1767 149 0.17     1     1     1     1     1     1     1     1     1     1     1
1768 150 0.17     1     1     1     1     1     1     1     1     1     1     1
1769 151 0.17     1     1     1     1     1     1     1     1     1     1     1
1770 152 0.17     1     1     1     1     1     1     1     1     1     1     1
1771 153 0.17     1     1     1     1     1     1     1     1     1     1     1
1772 154 0.17     1     1     1     1     1     1     1     1     1     1     1
1773 155 0.17     1     1     1     1     1     1     1     1     1     1     1
1774 156 0.17     1     1     1     1     1     1     1     1     1     1     1
1775 157 0.17     1     1     1     1     1     1     1     1     1     1     1
1776 158 0.17     1     1     1     1     1     1     1     1     1     1     1
1777 159 0.17     1     1     1     1     1     1     1     1     1     1     1
1778 160 0.17     1     1     1     1     1     1     1     1     1     1     1
1779 161 0.17     1     1     1     1     1     1     1     1     1     1     1
1780 162 0.17     1     1     1     1     1     1     1     1     1     1     1
1781 163 0.17     1     1     1     1     1     1     1     1     1     1     1
1782 164 0.17     1     1     1     1     1     1     1     1     1     1     1
1783 165 0.17     1     1     1     1     1     1     1     1     1     1     1
1784 166 0.17     1     1     1     1     1     1     1     1     1     1     1
1785 167 0.17     1     1     1     1     1     1     1     1     1     1     1
1786 168 0.17     1     1     1     1     1     1     1     1     1     1     1
1787 169 0.17     1     1     1     1     1     1     1     1     1     1     1
1788 170 0.17     1     1     1     1     1     1     1     1     1     1     1
1789 171 0.17     1     1     1     1     1     1     1     1     1     1     1
1790 172 0.17     1     1     1     1     1     1     1     1     1     1     1
1791 173 0.17     1     1     1     1     1     1     1     1     1     1     1
1792 174 0.17     1     1     1     1     1     1     1     1     1     1     1
1793 175 0.17     1     1     1     1     1     1     1     1     1     1     1
1794 176 0.17     1     1     1     1     1     1     1     1     1     1     1
1795 177 0.17     1     1     1     1     1     1     1     1     1     1     1
1796 178 0.17     1     1     1     1     1     1     1     1     1     1     1
1797 179 0.17     1     1     1     1     1     1     1     1     1     1     1
1798 180 0.17     1     1     1     1     1     1     1     1     1     1     1
1799 181 0.17     1     1     1     1     1     1     1     1     1     1     1
1800 182 0.17     1     1     1     1     1     1     1     1     1     1     1
1801 183 0.17     1     1     1     1     1     1     1     1     1     1     1
1802 184 0.17     1     1     1     1     1     1     1     1     1     1     1
1803 185 0.17     1     1     1     1     1     1     1     1     1     1     1
1804 186 0.17     1     1     1     1     1     1     1     1     1     1     1
1805 187 0.17     1     1     1     1     1     1     1     1     1     1     1
1806 188 0.17     1     1     1     1     1     1     1     1     1     1     1
1807 189 0.17     1     1     1     1     1     1     1     1     1     1     1
1808 190 0.17     1     1     1     1     1     1     1     1     1     1     1
1809 191 0.17     1     1     1     1     1     1     1     1     1     1     1
1810 192 0.17     1     1     1     1     1     1     1     1     1     1     1
1811 193 0.17     1     1     1     1     1     1     1     1     1     1     1
1812 194 0.17     1     1     1     1     1     1     1     1     1     1     1
1813 195 0.17     1     1     1     1     1     1     1     1     1     1     1
1814 196 0.17     1     1     1     1     1     1     1     1     1     1     1
1815 197 0.17     1     1     1     1     1     1     1     1     1     1     1
1816 198 0.17     1     1     1     1     1     1     1     1     1     1     1
1817 199 0.17     1     1     1     1     1     1     1     1     1     1     1
1818 200 0.17     1     1     1     1     1     1     1     1     1     1     1
1819 100 0.18     1     1     1     1     1     1     1     1     1     1     1
1820 101 0.18     1     1     1     1     1     1     1     1     1     1     1
1821 102 0.18     1     1     1     1     1     1     1     1     1     1     1
1822 103 0.18     1     1     1     1     1     1     1     1     1     1     1
1823 104 0.18     1     1     1     1     1     1     1     1     1     1     1
1824 105 0.18     1     1     1     1     1     1     1     1     1     1     1
1825 106 0.18     1     1     1     1     1     1     1     1     1     1     1
1826 107 0.18     1     1     1     1     1     1     1     1     1     1     1
1827 108 0.18     1     1     1     1     1     1     1     1     1     1     1
1828 109 0.18     1     1     1     1     1     1     1     1     1     1     1
1829 110 0.18     1     1     1     1     1     1     1     1     1     1     1
1830 111 0.18     1     1     1     1     1     1     1     1     1     1     1
1831 112 0.18     1     1     1     1     1     1     1     1     1     1     1
1832 113 0.18     1     1     1     1     1     1     1     1     1     1     1
1833 114 0.18     1     1     1     1     1     1     1     1     1     1     1
1834 115 0.18     1     1     1     1     1     1     1     1     1     1     1
1835 116 0.18     1     1     1     1     1     1     1     1     1     1     1
1836 117 0.18     1     1     1     1     1     1     1     1     1     1     1
1837 118 0.18     1     1     1     1     1     1     1     1     1     1     1
1838 119 0.18     1     1     1     1     1     1     1     1     1     1     1
1839 120 0.18     1     1     1     1     1     1     1     1     1     1     1
1840 121 0.18     1     1     1     1     1     1     1     1     1     1     1
1841 122 0.18     1     1     1     1     1     1     1     1     1     1     1
1842 123 0.18     1     1     1     1     1     1     1     1     1     1     1
1843 124 0.18     1     1     1     1     1     1     1     1     1     1     1
1844 125 0.18     1     1     1     1     1     1     1     1     1     1     1
1845 126 0.18     1     1     1     1     1     1     1     1     1     1     1
1846 127 0.18     1     1     1     1     1     1     1     1     1     1     1
1847 128 0.18     1     1     1     1     1     1     1     1     1     1     1
1848 129 0.18     1     1     1     1     1     1     1     1     1     1     1
1849 130 0.18     1     1     1     1     1     1     1     1     1     1     1
1850 131 0.18     1     1     1     1     1     1     1     1     1     1     1
1851 132 0.18     1     1     1     1     1     1     1     1     1     1     1
1852 133 0.18     1     1     1     1     1     1     1     1     1     1     1
1853 134 0.18     1     1     1     1     1     1     1     1     1     1     1
1854 135 0.18     1     1     1     1     1     1     1     1     1     1     1
1855 136 0.18     1     1     1     1     1     1     1     1     1     1     1
1856 137 0.18     1     1     1     1     1     1     1     1     1     1     1
1857 138 0.18     1     1     1     1     1     1     1     1     1     1     1
1858 139 0.18     1     1     1     1     1     1     1     1     1     1     1
1859 140 0.18     1     1     1     1     1     1     1     1     1     1     1
1860 141 0.18     1     1     1     1     1     1     1     1     1     1     1
1861 142 0.18     1     1     1     1     1     1     1     1     1     1     1
1862 143 0.18     1     1     1     1     1     1     1     1     1     1     1
1863 144 0.18     1     1     1     1     1     1     1     1     1     1     1
1864 145 0.18     1     1     1     1     1     1     1     1     1     1     1
1865 146 0.18     1     1     1     1     1     1     1     1     1     1     1
1866 147 0.18     1     1     1     1     1     1     1     1     1     1     1
1867 148 0.18     1     1     1     1     1     1     1     1     1     1     1
1868 149 0.18     1     1     1     1     1     1     1     1     1     1     1
1869 150 0.18     1     1     1     1     1     1     1     1     1     1     1
1870 151 0.18     1     1     1     1     1     1     1     1     1     1     1
1871 152 0.18     1     1     1     1     1     1     1     1     1     1     1
1872 153 0.18     1     1     1     1     1     1     1     1     1     1     1
1873 154 0.18     1     1     1     1     1     1     1     1     1     1     1
1874 155 0.18     1     1     1     1     1     1     1     1     1     1     1
1875 156 0.18     1     1     1     1     1     1     1     1     1     1     1
1876 157 0.18     1     1     1     1     1     1     1     1     1     1     1
1877 158 0.18     1     1     1     1     1     1     1     1     1     1     1
1878 159 0.18     1     1     1     1     1     1     1     1     1     1     1
1879 160 0.18     1     1     1     1     1     1     1     1     1     1     1
1880 161 0.18     1     1     1     1     1     1     1     1     1     1     1
1881 162 0.18     1     1     1     1     1     1     1     1     1     1     1
1882 163 0.18     1     1     1     1     1     1     1     1     1     1     1
1883 164 0.18     1     1     1     1     1     1     1     1     1     1     1
1884 165 0.18     1     1     1     1     1     1     1     1     1     1     1
1885 166 0.18     1     1     1     1     1     1     1     1     1     1     1
1886 167 0.18     1     1     1     1     1     1     1     1     1     1     1
1887 168 0.18     1     1     1     1     1     1     1     1     1     1     1
1888 169 0.18     1     1     1     1     1     1     1     1     1     1     1
1889 170 0.18     1     1     1     1     1     1     1     1     1     1     1
1890 171 0.18     1     1     1     1     1     1     1     1     1     1     1
1891 172 0.18     1     1     1     1     1     1     1     1     1     1     1
1892 173 0.18     1     1     1     1     1     1     1     1     1     1     1
1893 174 0.18     1     1     1     1     1     1     1     1     1     1     1
1894 175 0.18     1     1     1     1     1     1     1     1     1     1     1
1895 176 0.18     1     1     1     1     1     1     1     1     1     1     1
1896 177 0.18     1     1     1     1     1     1     1     1     1     1     1
1897 178 0.18     1     1     1     1     1     1     1     1     1     1     1
1898 179 0.18     1     1     1     1     1     1     1     1     1     1     1
1899 180 0.18     1     1     1     1     1     1     1     1     1     1     1
1900 181 0.18     1     1     1     1     1     1     1     1     1     1     1
1901 182 0.18     1     1     1     1     1     1     1     1     1     1     1
1902 183 0.18     1     1     1     1     1     1     1     1     1     1     1
1903 184 0.18     1     1     1     1     1     1     1     1     1     1     1
1904 185 0.18     1     1     1     1     1     1     1     1     1     1     1
1905 186 0.18     1     1     1     1     1     1     1     1     1     1     1
1906 187 0.18     1     1     1     1     1     1     1     1     1     1     1
1907 188 0.18     1     1     1     1     1     1     1     1     1     1     1
1908 189 0.18     1     1     1     1     1     1     1     1     1     1     1
1909 190 0.18     1     1     1     1     1     1     1     1     1     1     1
1910 191 0.18     1     1     1     1     1     1     1     1     1     1     1
1911 192 0.18     1     1     1     1     1     1     1     1     1     1     1
1912 193 0.18     1     1     1     1     1     1     1     1     1     1     1
1913 194 0.18     1     1     1     1     1     1     1     1     1     1     1
1914 195 0.18     1     1     1     1     1     1     1     1     1     1     1
1915 196 0.18     1     1     1     1     1     1     1     1     1     1     1
1916 197 0.18     1     1     1     1     1     1     1     1     1     1     1
1917 198 0.18     1     1     1     1     1     1     1     1     1     1     1
1918 199 0.18     1     1     1     1     1     1     1     1     1     1     1
1919 200 0.18     1     1     1     1     1     1     1     1     1     1     1
1920 100 0.19     1     1     1     1     1     1     1     1     1     1     1
1921 101 0.19     1     1     1     1     1     1     1     1     1     1     1
1922 102 0.19     1     1     1     1     1     1     1     1     1     1     1
1923 103 0.19     1     1     1     1     1     1     1     1     1     1     1
1924 104 0.19     1     1     1     1     1     1     1     1     1     1     1
1925 105 0.19     1     1     1     1     1     1     1     1     1     1     1
1926 106 0.19     1     1     1     1     1     1     1     1     1     1     1
1927 107 0.19     1     1     1     1     1     1     1     1     1     1     1
1928 108 0.19     1     1     1     1     1     1     1     1     1     1     1
1929 109 0.19     1     1     1     1     1     1     1     1     1     1     1
1930 110 0.19     1     1     1     1     1     1     1     1     1     1     1
1931 111 0.19     1     1     1     1     1     1     1     1     1     1     1
1932 112 0.19     1     1     1     1     1     1     1     1     1     1     1
1933 113 0.19     1     1     1     1     1     1     1     1     1     1     1
1934 114 0.19     1     1     1     1     1     1     1     1     1     1     1
1935 115 0.19     1     1     1     1     1     1     1     1     1     1     1
1936 116 0.19     1     1     1     1     1     1     1     1     1     1     1
1937 117 0.19     1     1     1     1     1     1     1     1     1     1     1
1938 118 0.19     1     1     1     1     1     1     1     1     1     1     1
1939 119 0.19     1     1     1     1     1     1     1     1     1     1     1
1940 120 0.19     1     1     1     1     1     1     1     1     1     1     1
1941 121 0.19     1     1     1     1     1     1     1     1     1     1     1
1942 122 0.19     1     1     1     1     1     1     1     1     1     1     1
1943 123 0.19     1     1     1     1     1     1     1     1     1     1     1
1944 124 0.19     1     1     1     1     1     1     1     1     1     1     1
1945 125 0.19     1     1     1     1     1     1     1     1     1     1     1
1946 126 0.19     1     1     1     1     1     1     1     1     1     1     1
1947 127 0.19     1     1     1     1     1     1     1     1     1     1     1
1948 128 0.19     1     1     1     1     1     1     1     1     1     1     1
1949 129 0.19     1     1     1     1     1     1     1     1     1     1     1
1950 130 0.19     1     1     1     1     1     1     1     1     1     1     1
1951 131 0.19     1     1     1     1     1     1     1     1     1     1     1
1952 132 0.19     1     1     1     1     1     1     1     1     1     1     1
1953 133 0.19     1     1     1     1     1     1     1     1     1     1     1
1954 134 0.19     1     1     1     1     1     1     1     1     1     1     1
1955 135 0.19     1     1     1     1     1     1     1     1     1     1     1
1956 136 0.19     1     1     1     1     1     1     1     1     1     1     1
1957 137 0.19     1     1     1     1     1     1     1     1     1     1     1
1958 138 0.19     1     1     1     1     1     1     1     1     1     1     1
1959 139 0.19     1     1     1     1     1     1     1     1     1     1     1
1960 140 0.19     1     1     1     1     1     1     1     1     1     1     1
1961 141 0.19     1     1     1     1     1     1     1     1     1     1     1
1962 142 0.19     1     1     1     1     1     1     1     1     1     1     1
1963 143 0.19     1     1     1     1     1     1     1     1     1     1     1
1964 144 0.19     1     1     1     1     1     1     1     1     1     1     1
1965 145 0.19     1     1     1     1     1     1     1     1     1     1     1
1966 146 0.19     1     1     1     1     1     1     1     1     1     1     1
1967 147 0.19     1     1     1     1     1     1     1     1     1     1     1
1968 148 0.19     1     1     1     1     1     1     1     1     1     1     1
1969 149 0.19     1     1     1     1     1     1     1     1     1     1     1
1970 150 0.19     1     1     1     1     1     1     1     1     1     1     1
1971 151 0.19     1     1     1     1     1     1     1     1     1     1     1
1972 152 0.19     1     1     1     1     1     1     1     1     1     1     1
1973 153 0.19     1     1     1     1     1     1     1     1     1     1     1
1974 154 0.19     1     1     1     1     1     1     1     1     1     1     1
1975 155 0.19     1     1     1     1     1     1     1     1     1     1     1
1976 156 0.19     1     1     1     1     1     1     1     1     1     1     1
1977 157 0.19     1     1     1     1     1     1     1     1     1     1     1
1978 158 0.19     1     1     1     1     1     1     1     1     1     1     1
1979 159 0.19     1     1     1     1     1     1     1     1     1     1     1
1980 160 0.19     1     1     1     1     1     1     1     1     1     1     1
1981 161 0.19     1     1     1     1     1     1     1     1     1     1     1
1982 162 0.19     1     1     1     1     1     1     1     1     1     1     1
1983 163 0.19     1     1     1     1     1     1     1     1     1     1     1
1984 164 0.19     1     1     1     1     1     1     1     1     1     1     1
1985 165 0.19     1     1     1     1     1     1     1     1     1     1     1
1986 166 0.19     1     1     1     1     1     1     1     1     1     1     1
1987 167 0.19     1     1     1     1     1     1     1     1     1     1     1
1988 168 0.19     1     1     1     1     1     1     1     1     1     1     1
1989 169 0.19     1     1     1     1     1     1     1     1     1     1     1
1990 170 0.19     1     1     1     1     1     1     1     1     1     1     1
1991 171 0.19     1     1     1     1     1     1     1     1     1     1     1
1992 172 0.19     1     1     1     1     1     1     1     1     1     1     1
1993 173 0.19     1     1     1     1     1     1     1     1     1     1     1
1994 174 0.19     1     1     1     1     1     1     1     1     1     1     1
1995 175 0.19     1     1     1     1     1     1     1     1     1     1     1
1996 176 0.19     1     1     1     1     1     1     1     1     1     1     1
1997 177 0.19     1     1     1     1     1     1     1     1     1     1     1
1998 178 0.19     1     1     1     1     1     1     1     1     1     1     1
1999 179 0.19     1     1     1     1     1     1     1     1     1     1     1
2000 180 0.19     1     1     1     1     1     1     1     1     1     1     1
2001 181 0.19     1     1     1     1     1     1     1     1     1     1     1
2002 182 0.19     1     1     1     1     1     1     1     1     1     1     1
2003 183 0.19     1     1     1     1     1     1     1     1     1     1     1
2004 184 0.19     1     1     1     1     1     1     1     1     1     1     1
2005 185 0.19     1     1     1     1     1     1     1     1     1     1     1
2006 186 0.19     1     1     1     1     1     1     1     1     1     1     1
2007 187 0.19     1     1     1     1     1     1     1     1     1     1     1
2008 188 0.19     1     1     1     1     1     1     1     1     1     1     1
2009 189 0.19     1     1     1     1     1     1     1     1     1     1     1
2010 190 0.19     1     1     1     1     1     1     1     1     1     1     1
2011 191 0.19     1     1     1     1     1     1     1     1     1     1     1
2012 192 0.19     1     1     1     1     1     1     1     1     1     1     1
2013 193 0.19     1     1     1     1     1     1     1     1     1     1     1
2014 194 0.19     1     1     1     1     1     1     1     1     1     1     1
2015 195 0.19     1     1     1     1     1     1     1     1     1     1     1
2016 196 0.19     1     1     1     1     1     1     1     1     1     1     1
2017 197 0.19     1     1     1     1     1     1     1     1     1     1     1
2018 198 0.19     1     1     1     1     1     1     1     1     1     1     1
2019 199 0.19     1     1     1     1     1     1     1     1     1     1     1
2020 200 0.19     1     1     1     1     1     1     1     1     1     1     1
2021 100 0.20     1     1     1     1     1     1     1     1     1     1     1
2022 101 0.20     1     1     1     1     1     1     1     1     1     1     1
2023 102 0.20     1     1     1     1     1     1     1     1     1     1     1
2024 103 0.20     1     1     1     1     1     1     1     1     1     1     1
2025 104 0.20     1     1     1     1     1     1     1     1     1     1     1
2026 105 0.20     1     1     1     1     1     1     1     1     1     1     1
2027 106 0.20     1     1     1     1     1     1     1     1     1     1     1
2028 107 0.20     1     1     1     1     1     1     1     1     1     1     1
2029 108 0.20     1     1     1     1     1     1     1     1     1     1     1
2030 109 0.20     1     1     1     1     1     1     1     1     1     1     1
2031 110 0.20     1     1     1     1     1     1     1     1     1     1     1
2032 111 0.20     1     1     1     1     1     1     1     1     1     1     1
2033 112 0.20     1     1     1     1     1     1     1     1     1     1     1
2034 113 0.20     1     1     1     1     1     1     1     1     1     1     1
2035 114 0.20     1     1     1     1     1     1     1     1     1     1     1
2036 115 0.20     1     1     1     1     1     1     1     1     1     1     1
2037 116 0.20     1     1     1     1     1     1     1     1     1     1     1
2038 117 0.20     1     1     1     1     1     1     1     1     1     1     1
2039 118 0.20     1     1     1     1     1     1     1     1     1     1     1
2040 119 0.20     1     1     1     1     1     1     1     1     1     1     1
2041 120 0.20     1     1     1     1     1     1     1     1     1     1     1
2042 121 0.20     1     1     1     1     1     1     1     1     1     1     1
2043 122 0.20     1     1     1     1     1     1     1     1     1     1     1
2044 123 0.20     1     1     1     1     1     1     1     1     1     1     1
2045 124 0.20     1     1     1     1     1     1     1     1     1     1     1
2046 125 0.20     1     1     1     1     1     1     1     1     1     1     1
2047 126 0.20     1     1     1     1     1     1     1     1     1     1     1
2048 127 0.20     1     1     1     1     1     1     1     1     1     1     1
2049 128 0.20     1     1     1     1     1     1     1     1     1     1     1
2050 129 0.20     1     1     1     1     1     1     1     1     1     1     1
2051 130 0.20     1     1     1     1     1     1     1     1     1     1     1
2052 131 0.20     1     1     1     1     1     1     1     1     1     1     1
2053 132 0.20     1     1     1     1     1     1     1     1     1     1     1
2054 133 0.20     1     1     1     1     1     1     1     1     1     1     1
2055 134 0.20     1     1     1     1     1     1     1     1     1     1     1
2056 135 0.20     1     1     1     1     1     1     1     1     1     1     1
2057 136 0.20     1     1     1     1     1     1     1     1     1     1     1
2058 137 0.20     1     1     1     1     1     1     1     1     1     1     1
2059 138 0.20     1     1     1     1     1     1     1     1     1     1     1
2060 139 0.20     1     1     1     1     1     1     1     1     1     1     1
2061 140 0.20     1     1     1     1     1     1     1     1     1     1     1
2062 141 0.20     1     1     1     1     1     1     1     1     1     1     1
2063 142 0.20     1     1     1     1     1     1     1     1     1     1     1
2064 143 0.20     1     1     1     1     1     1     1     1     1     1     1
2065 144 0.20     1     1     1     1     1     1     1     1     1     1     1
2066 145 0.20     1     1     1     1     1     1     1     1     1     1     1
2067 146 0.20     1     1     1     1     1     1     1     1     1     1     1
2068 147 0.20     1     1     1     1     1     1     1     1     1     1     1
2069 148 0.20     1     1     1     1     1     1     1     1     1     1     1
2070 149 0.20     1     1     1     1     1     1     1     1     1     1     1
2071 150 0.20     1     1     1     1     1     1     1     1     1     1     1
2072 151 0.20     1     1     1     1     1     1     1     1     1     1     1
2073 152 0.20     1     1     1     1     1     1     1     1     1     1     1
2074 153 0.20     1     1     1     1     1     1     1     1     1     1     1
2075 154 0.20     1     1     1     1     1     1     1     1     1     1     1
2076 155 0.20     1     1     1     1     1     1     1     1     1     1     1
2077 156 0.20     1     1     1     1     1     1     1     1     1     1     1
2078 157 0.20     1     1     1     1     1     1     1     1     1     1     1
2079 158 0.20     1     1     1     1     1     1     1     1     1     1     1
2080 159 0.20     1     1     1     1     1     1     1     1     1     1     1
2081 160 0.20     1     1     1     1     1     1     1     1     1     1     1
2082 161 0.20     1     1     1     1     1     1     1     1     1     1     1
2083 162 0.20     1     1     1     1     1     1     1     1     1     1     1
2084 163 0.20     1     1     1     1     1     1     1     1     1     1     1
2085 164 0.20     1     1     1     1     1     1     1     1     1     1     1
2086 165 0.20     1     1     1     1     1     1     1     1     1     1     1
2087 166 0.20     1     1     1     1     1     1     1     1     1     1     1
2088 167 0.20     1     1     1     1     1     1     1     1     1     1     1
2089 168 0.20     1     1     1     1     1     1     1     1     1     1     1
2090 169 0.20     1     1     1     1     1     1     1     1     1     1     1
2091 170 0.20     1     1     1     1     1     1     1     1     1     1     1
2092 171 0.20     1     1     1     1     1     1     1     1     1     1     1
2093 172 0.20     1     1     1     1     1     1     1     1     1     1     1
2094 173 0.20     1     1     1     1     1     1     1     1     1     1     1
2095 174 0.20     1     1     1     1     1     1     1     1     1     1     1
2096 175 0.20     1     1     1     1     1     1     1     1     1     1     1
2097 176 0.20     1     1     1     1     1     1     1     1     1     1     1
2098 177 0.20     1     1     1     1     1     1     1     1     1     1     1
2099 178 0.20     1     1     1     1     1     1     1     1     1     1     1
2100 179 0.20     1     1     1     1     1     1     1     1     1     1     1
2101 180 0.20     1     1     1     1     1     1     1     1     1     1     1
2102 181 0.20     1     1     1     1     1     1     1     1     1     1     1
2103 182 0.20     1     1     1     1     1     1     1     1     1     1     1
2104 183 0.20     1     1     1     1     1     1     1     1     1     1     1
2105 184 0.20     1     1     1     1     1     1     1     1     1     1     1
2106 185 0.20     1     1     1     1     1     1     1     1     1     1     1
2107 186 0.20     1     1     1     1     1     1     1     1     1     1     1
2108 187 0.20     1     1     1     1     1     1     1     1     1     1     1
2109 188 0.20     1     1     1     1     1     1     1     1     1     1     1
2110 189 0.20     1     1     1     1     1     1     1     1     1     1     1
2111 190 0.20     1     1     1     1     1     1     1     1     1     1     1
2112 191 0.20     1     1     1     1     1     1     1     1     1     1     1
2113 192 0.20     1     1     1     1     1     1     1     1     1     1     1
2114 193 0.20     1     1     1     1     1     1     1     1     1     1     1
2115 194 0.20     1     1     1     1     1     1     1     1     1     1     1
2116 195 0.20     1     1     1     1     1     1     1     1     1     1     1
2117 196 0.20     1     1     1     1     1     1     1     1     1     1     1
2118 197 0.20     1     1     1     1     1     1     1     1     1     1     1
2119 198 0.20     1     1     1     1     1     1     1     1     1     1     1
2120 199 0.20     1     1     1     1     1     1     1     1     1     1     1
2121 200 0.20     1     1     1     1     1     1     1     1     1     1     1
     TE6_6        TY1       TY2         TY3       TY4          TY5        TY6
1        1 0.16371053 0.1111111 0.526622157 0.1111111 4.561136e-01 0.06817024
2        1 0.16236743 0.1111111 0.516899850 0.1111111 4.463038e-01 0.06879814
3        1 0.16103323 0.1111111 0.507164733 0.1111111 4.365357e-01 0.06943140
4        1 0.15970790 0.1111111 0.497424179 0.1111111 4.268166e-01 0.07007004
5        1 0.15839142 0.1111111 0.487685581 0.1111111 4.171536e-01 0.07071411
6        1 0.15708377 0.1111111 0.477956322 0.1111111 4.075539e-01 0.07136365
7        1 0.15578491 0.1111111 0.468243760 0.1111111 3.980242e-01 0.07201869
8        1 0.15449482 0.1111111 0.458555201 0.1111111 3.885712e-01 0.07267927
9        1 0.15321348 0.1111111 0.448897879 0.1111111 3.792013e-01 0.07334543
10       1 0.15194085 0.1111111 0.439278934 0.1111111 3.699206e-01 0.07401721
11       1 0.15067692 0.1111111 0.429705392 0.1111111 3.607351e-01 0.07469465
12       1 0.14942165 0.1111111 0.420184144 0.1111111 3.516504e-01 0.07537779
13       1 0.14817500 0.1111111 0.410721926 0.1111111 3.426718e-01 0.07606665
14       1 0.14693697 0.1111111 0.401325303 0.1111111 3.338045e-01 0.07676130
15       1 0.14570751 0.1111111 0.392000650 0.1111111 3.250531e-01 0.07746175
16       1 0.14448659 0.1111111 0.382754137 0.1111111 3.164222e-01 0.07816805
17       1 0.14327419 0.1111111 0.373591713 0.1111111 3.079159e-01 0.07888024
18       1 0.14207027 0.1111111 0.364519093 0.1111111 2.995381e-01 0.07959836
19       1 0.14087480 0.1111111 0.355541744 0.1111111 2.912923e-01 0.08032245
20       1 0.13968776 0.1111111 0.346664880 0.1111111 2.831817e-01 0.08105255
21       1 0.13850911 0.1111111 0.337893443 0.1111111 2.752092e-01 0.08178869
22       1 0.13733881 0.1111111 0.329232104 0.1111111 2.673775e-01 0.08253092
23       1 0.13617684 0.1111111 0.320685251 0.1111111 2.596888e-01 0.08327927
24       1 0.13502316 0.1111111 0.312256986 0.1111111 2.521451e-01 0.08403378
25       1 0.13387774 0.1111111 0.303951120 0.1111111 2.447481e-01 0.08479450
26       1 0.13274054 0.1111111 0.295771172 0.1111111 2.374991e-01 0.08556147
27       1 0.13161154 0.1111111 0.287720366 0.1111111 2.303994e-01 0.08633471
28       1 0.13049070 0.1111111 0.279801632 0.1111111 2.234497e-01 0.08711428
29       1 0.12937797 0.1111111 0.272017609 0.1111111 2.166507e-01 0.08790021
30       1 0.12827334 0.1111111 0.264370645 0.1111111 2.100025e-01 0.08869254
31       1 0.12717676 0.1111111 0.256862801 0.1111111 2.035054e-01 0.08949131
32       1 0.12608820 0.1111111 0.249495858 0.1111111 1.971591e-01 0.09029657
33       1 0.12500762 0.1111111 0.242271320 0.1111111 1.909633e-01 0.09110834
34       1 0.12393499 0.1111111 0.235190422 0.1111111 1.849173e-01 0.09192668
35       1 0.12287027 0.1111111 0.228254137 0.1111111 1.790204e-01 0.09275161
36       1 0.12181343 0.1111111 0.221463183 0.1111111 1.732716e-01 0.09358318
37       1 0.12076442 0.1111111 0.214818031 0.1111111 1.676697e-01 0.09442144
38       1 0.11972322 0.1111111 0.208318920 0.1111111 1.622133e-01 0.09526641
39       1 0.11868978 0.1111111 0.201965856 0.1111111 1.569011e-01 0.09611815
40       1 0.11766407 0.1111111 0.195758633 0.1111111 1.517313e-01 0.09697668
41       1 0.11664605 0.1111111 0.189696835 0.1111111 1.467022e-01 0.09784205
42       1 0.11563569 0.1111111 0.183779851 0.1111111 1.418119e-01 0.09871430
43       1 0.11463294 0.1111111 0.178006884 0.1111111 1.370584e-01 0.09959346
44       1 0.11363777 0.1111111 0.172376962 0.1111111 1.324397e-01 0.10047958
45       1 0.11265013 0.1111111 0.166888949 0.1111111 1.279536e-01 0.10137270
46       1 0.11167000 0.1111111 0.161541556 0.1111111 1.235978e-01 0.10227286
47       1 0.11069734 0.1111111 0.156333350 0.1111111 1.193699e-01 0.10318009
48       1 0.10973210 0.1111111 0.151262767 0.1111111 1.152677e-01 0.10409443
49       1 0.10877425 0.1111111 0.146328121 0.1111111 1.112886e-01 0.10501593
50       1 0.10782374 0.1111111 0.141527614 0.1111111 1.074302e-01 0.10594462
51       1 0.10688055 0.1111111 0.136859346 0.1111111 1.036900e-01 0.10688055
52       1 0.10594462 0.1111111 0.132321326 0.1111111 1.000654e-01 0.10782374
53       1 0.10501593 0.1111111 0.127911480 0.1111111 9.655382e-02 0.10877425
54       1 0.10409443 0.1111111 0.123627660 0.1111111 9.315273e-02 0.10973210
55       1 0.10318009 0.1111111 0.119467654 0.1111111 8.985953e-02 0.11069734
56       1 0.10227286 0.1111111 0.115429193 0.1111111 8.667162e-02 0.11167000
57       1 0.10137270 0.1111111 0.111509958 0.1111111 8.358643e-02 0.11265013
58       1 0.10047958 0.1111111 0.107707593 0.1111111 8.060136e-02 0.11363777
59       1 0.09959346 0.1111111 0.104019705 0.1111111 7.771386e-02 0.11463294
60       1 0.09871430 0.1111111 0.100443874 0.1111111 7.492137e-02 0.11563569
61       1 0.09784205 0.1111111 0.096977664 0.1111111 7.222137e-02 0.11664605
62       1 0.09697668 0.1111111 0.093618620 0.1111111 6.961135e-02 0.11766407
63       1 0.09611815 0.1111111 0.090364281 0.1111111 6.708883e-02 0.11868978
64       1 0.09526641 0.1111111 0.087212184 0.1111111 6.465137e-02 0.11972322
65       1 0.09442144 0.1111111 0.084159865 0.1111111 6.229655e-02 0.12076442
66       1 0.09358318 0.1111111 0.081204870 0.1111111 6.002199e-02 0.12181343
67       1 0.09275161 0.1111111 0.078344755 0.1111111 5.782537e-02 0.12287027
68       1 0.09192668 0.1111111 0.075577089 0.1111111 5.570437e-02 0.12393499
69       1 0.09110834 0.1111111 0.072899463 0.1111111 5.365674e-02 0.12500762
70       1 0.09029657 0.1111111 0.070309487 0.1111111 5.168025e-02 0.12608820
71       1 0.08949131 0.1111111 0.067804798 0.1111111 4.977274e-02 0.12717676
72       1 0.08869254 0.1111111 0.065383060 0.1111111 4.793208e-02 0.12827334
73       1 0.08790021 0.1111111 0.063041969 0.1111111 4.615619e-02 0.12937797
74       1 0.08711428 0.1111111 0.060779251 0.1111111 4.444302e-02 0.13049070
75       1 0.08633471 0.1111111 0.058592668 0.1111111 4.279058e-02 0.13161154
76       1 0.08556147 0.1111111 0.056480019 0.1111111 4.119693e-02 0.13274054
77       1 0.08479450 0.1111111 0.054439139 0.1111111 3.966018e-02 0.13387774
78       1 0.08403378 0.1111111 0.052467905 0.1111111 3.817847e-02 0.13502316
79       1 0.08327927 0.1111111 0.050564233 0.1111111 3.675000e-02 0.13617684
80       1 0.08253092 0.1111111 0.048726078 0.1111111 3.537301e-02 0.13733881
81       1 0.08178869 0.1111111 0.046951441 0.1111111 3.404579e-02 0.13850911
82       1 0.08105255 0.1111111 0.045238364 0.1111111 3.276668e-02 0.13968776
83       1 0.08032245 0.1111111 0.043584932 0.1111111 3.153405e-02 0.14087480
84       1 0.07959836 0.1111111 0.041989275 0.1111111 3.034634e-02 0.14207027
85       1 0.07888024 0.1111111 0.040449564 0.1111111 2.920202e-02 0.14327419
86       1 0.07816805 0.1111111 0.038964016 0.1111111 2.809959e-02 0.14448659
87       1 0.07746175 0.1111111 0.037530893 0.1111111 2.703763e-02 0.14570751
88       1 0.07676130 0.1111111 0.036148499 0.1111111 2.601472e-02 0.14693697
89       1 0.07606665 0.1111111 0.034815181 0.1111111 2.502952e-02 0.14817500
90       1 0.07537779 0.1111111 0.033529330 0.1111111 2.408071e-02 0.14942165
91       1 0.07469465 0.1111111 0.032289383 0.1111111 2.316701e-02 0.15067692
92       1 0.07401721 0.1111111 0.031093814 0.1111111 2.228718e-02 0.15194085
93       1 0.07334543 0.1111111 0.029941144 0.1111111 2.144004e-02 0.15321348
94       1 0.07267927 0.1111111 0.028829933 0.1111111 2.062442e-02 0.15449482
95       1 0.07201869 0.1111111 0.027758782 0.1111111 1.983919e-02 0.15578491
96       1 0.07136365 0.1111111 0.026726333 0.1111111 1.908328e-02 0.15708377
97       1 0.07071411 0.1111111 0.025731269 0.1111111 1.835564e-02 0.15839142
98       1 0.07007004 0.1111111 0.024772309 0.1111111 1.765523e-02 0.15970790
99       1 0.06943140 0.1111111 0.023848214 0.1111111 1.698109e-02 0.16103323
100      1 0.06879814 0.1111111 0.022957779 0.1111111 1.633227e-02 0.16236743
101      1 0.06817024 0.1111111 0.022099838 0.1111111 1.570784e-02 0.16371053
102      1 0.16371053 0.1111111 0.499907374 0.1111111 1.146191e-01 0.06817024
103      1 0.16236743 0.1111111 0.490167575 0.1111111 1.106597e-01 0.06879814
104      1 0.16103323 0.1111111 0.480435235 0.1111111 1.068204e-01 0.06943140
105      1 0.15970790 0.1111111 0.470717721 0.1111111 1.030990e-01 0.07007004
106      1 0.15839142 0.1111111 0.461022352 0.1111111 9.949274e-02 0.07071411
107      1 0.15708377 0.1111111 0.451356385 0.1111111 9.599913e-02 0.07136365
108      1 0.15578491 0.1111111 0.441726985 0.1111111 9.261557e-02 0.07201869
109      1 0.15449482 0.1111111 0.432141209 0.1111111 8.933949e-02 0.07267927
110      1 0.15321348 0.1111111 0.422605984 0.1111111 8.616829e-02 0.07334543
111      1 0.15194085 0.1111111 0.413128087 0.1111111 8.309938e-02 0.07401721
112      1 0.15067692 0.1111111 0.403714129 0.1111111 8.013019e-02 0.07469465
113      1 0.14942165 0.1111111 0.394370535 0.1111111 7.725815e-02 0.07537779
114      1 0.14817500 0.1111111 0.385103529 0.1111111 7.448071e-02 0.07606665
115      1 0.14693697 0.1111111 0.375919116 0.1111111 7.179536e-02 0.07676130
116      1 0.14570751 0.1111111 0.366823074 0.1111111 6.919958e-02 0.07746175
117      1 0.14448659 0.1111111 0.357820933 0.1111111 6.669091e-02 0.07816805
118      1 0.14327419 0.1111111 0.348917972 0.1111111 6.426691e-02 0.07888024
119      1 0.14207027 0.1111111 0.340119205 0.1111111 6.192517e-02 0.07959836
120      1 0.14087480 0.1111111 0.331429372 0.1111111 5.966332e-02 0.08032245
121      1 0.13968776 0.1111111 0.322852933 0.1111111 5.747901e-02 0.08105255
122      1 0.13850911 0.1111111 0.314394064 0.1111111 5.536997e-02 0.08178869
123      1 0.13733881 0.1111111 0.306056650 0.1111111 5.333394e-02 0.08253092
124      1 0.13617684 0.1111111 0.297844284 0.1111111 5.136870e-02 0.08327927
125      1 0.13502316 0.1111111 0.289760267 0.1111111 4.947209e-02 0.08403378
126      1 0.13387774 0.1111111 0.281807603 0.1111111 4.764199e-02 0.08479450
127      1 0.13274054 0.1111111 0.273989005 0.1111111 4.587632e-02 0.08556147
128      1 0.13161154 0.1111111 0.266306894 0.1111111 4.417306e-02 0.08633471
129      1 0.13049070 0.1111111 0.258763405 0.1111111 4.253021e-02 0.08711428
130      1 0.12937797 0.1111111 0.251360389 0.1111111 4.094585e-02 0.08790021
131      1 0.12827334 0.1111111 0.244099421 0.1111111 3.941808e-02 0.08869254
132      1 0.12717676 0.1111111 0.236981804 0.1111111 3.794505e-02 0.08949131
133      1 0.12608820 0.1111111 0.230008575 0.1111111 3.652498e-02 0.09029657
134      1 0.12500762 0.1111111 0.223180518 0.1111111 3.515612e-02 0.09110834
135      1 0.12393499 0.1111111 0.216498167 0.1111111 3.383675e-02 0.09192668
136      1 0.12287027 0.1111111 0.209961817 0.1111111 3.256523e-02 0.09275161
137      1 0.12181343 0.1111111 0.203571534 0.1111111 3.133993e-02 0.09358318
138      1 0.12076442 0.1111111 0.197327164 0.1111111 3.015931e-02 0.09442144
139      1 0.11972322 0.1111111 0.191228344 0.1111111 2.902182e-02 0.09526641
140      1 0.11868978 0.1111111 0.185274512 0.1111111 2.792601e-02 0.09611815
141      1 0.11766407 0.1111111 0.179464917 0.1111111 2.687042e-02 0.09697668
142      1 0.11664605 0.1111111 0.173798632 0.1111111 2.585367e-02 0.09784205
143      1 0.11563569 0.1111111 0.168274559 0.1111111 2.487442e-02 0.09871430
144      1 0.11463294 0.1111111 0.162891450 0.1111111 2.393134e-02 0.09959346
145      1 0.11363777 0.1111111 0.157647905 0.1111111 2.302317e-02 0.10047958
146      1 0.11265013 0.1111111 0.152542394 0.1111111 2.214869e-02 0.10137270
147      1 0.11167000 0.1111111 0.147573261 0.1111111 2.130669e-02 0.10227286
148      1 0.11069734 0.1111111 0.142738736 0.1111111 2.049604e-02 0.10318009
149      1 0.10973210 0.1111111 0.138036943 0.1111111 1.971560e-02 0.10409443
150      1 0.10877425 0.1111111 0.133465914 0.1111111 1.896431e-02 0.10501593
151      1 0.10782374 0.1111111 0.129023594 0.1111111 1.824111e-02 0.10594462
152      1 0.10688055 0.1111111 0.124707855 0.1111111 1.754500e-02 0.10688055
153      1 0.10594462 0.1111111 0.120516500 0.1111111 1.687500e-02 0.10782374
154      1 0.10501593 0.1111111 0.116447272 0.1111111 1.623016e-02 0.10877425
155      1 0.10409443 0.1111111 0.112497867 0.1111111 1.560957e-02 0.10973210
156      1 0.10318009 0.1111111 0.108665935 0.1111111 1.501235e-02 0.11069734
157      1 0.10227286 0.1111111 0.104949092 0.1111111 1.443764e-02 0.11167000
158      1 0.10137270 0.1111111 0.101344927 0.1111111 1.388463e-02 0.11265013
159      1 0.10047958 0.1111111 0.097851004 0.1111111 1.335251e-02 0.11363777
160      1 0.09959346 0.1111111 0.094464874 0.1111111 1.284051e-02 0.11463294
161      1 0.09871430 0.1111111 0.091184078 0.1111111 1.234790e-02 0.11563569
162      1 0.09784205 0.1111111 0.088006151 0.1111111 1.187397e-02 0.11664605
163      1 0.09697668 0.1111111 0.084928630 0.1111111 1.141801e-02 0.11766407
164      1 0.09611815 0.1111111 0.081949058 0.1111111 1.097937e-02 0.11868978
165      1 0.09526641 0.1111111 0.079064987 0.1111111 1.055740e-02 0.11972322
166      1 0.09442144 0.1111111 0.076273983 0.1111111 1.015148e-02 0.12076442
167      1 0.09358318 0.1111111 0.073573632 0.1111111 9.761014e-03 0.12181343
168      1 0.09275161 0.1111111 0.070961537 0.1111111 9.385425e-03 0.12287027
169      1 0.09192668 0.1111111 0.068435330 0.1111111 9.024155e-03 0.12393499
170      1 0.09110834 0.1111111 0.065992666 0.1111111 8.676670e-03 0.12500762
171      1 0.09029657 0.1111111 0.063631233 0.1111111 8.342453e-03 0.12608820
172      1 0.08949131 0.1111111 0.061348750 0.1111111 8.021005e-03 0.12717676
173      1 0.08869254 0.1111111 0.059142969 0.1111111 7.711847e-03 0.12827334
174      1 0.08790021 0.1111111 0.057011680 0.1111111 7.414516e-03 0.12937797
175      1 0.08711428 0.1111111 0.054952708 0.1111111 7.128566e-03 0.13049070
176      1 0.08633471 0.1111111 0.052963919 0.1111111 6.853568e-03 0.13161154
177      1 0.08556147 0.1111111 0.051043219 0.1111111 6.589108e-03 0.13274054
178      1 0.08479450 0.1111111 0.049188554 0.1111111 6.334787e-03 0.13387774
179      1 0.08403378 0.1111111 0.047397913 0.1111111 6.090223e-03 0.13502316
180      1 0.08327927 0.1111111 0.045669327 0.1111111 5.855045e-03 0.13617684
181      1 0.08253092 0.1111111 0.044000869 0.1111111 5.628897e-03 0.13733881
182      1 0.08178869 0.1111111 0.042390659 0.1111111 5.411436e-03 0.13850911
183      1 0.08105255 0.1111111 0.040836857 0.1111111 5.202332e-03 0.13968776
184      1 0.08032245 0.1111111 0.039337669 0.1111111 5.001268e-03 0.14087480
185      1 0.07959836 0.1111111 0.037891344 0.1111111 4.807937e-03 0.14207027
186      1 0.07888024 0.1111111 0.036496177 0.1111111 4.622045e-03 0.14327419
187      1 0.07816805 0.1111111 0.035150502 0.1111111 4.443308e-03 0.14448659
188      1 0.07746175 0.1111111 0.033852702 0.1111111 4.271453e-03 0.14570751
189      1 0.07676130 0.1111111 0.032601199 0.1111111 4.106218e-03 0.14693697
190      1 0.07606665 0.1111111 0.031394460 0.1111111 3.947349e-03 0.14817500
191      1 0.07537779 0.1111111 0.030230992 0.1111111 3.794604e-03 0.14942165
192      1 0.07469465 0.1111111 0.029109346 0.1111111 3.647747e-03 0.15067692
193      1 0.07401721 0.1111111 0.028028113 0.1111111 3.506554e-03 0.15194085
194      1 0.07334543 0.1111111 0.026985926 0.1111111 3.370808e-03 0.15321348
195      1 0.07267927 0.1111111 0.025981454 0.1111111 3.240299e-03 0.15449482
196      1 0.07201869 0.1111111 0.025013410 0.1111111 3.114828e-03 0.15578491
197      1 0.07136365 0.1111111 0.024080543 0.1111111 2.994200e-03 0.15708377
198      1 0.07071411 0.1111111 0.023181639 0.1111111 2.878231e-03 0.15839142
199      1 0.07007004 0.1111111 0.022315524 0.1111111 2.766741e-03 0.15970790
200      1 0.06943140 0.1111111 0.021481056 0.1111111 2.659558e-03 0.16103323
201      1 0.06879814 0.1111111 0.020677133 0.1111111 2.556516e-03 0.16236743
202      1 0.06817024 0.1111111 0.019902685 0.1111111 2.457457e-03 0.16371053
203      1 0.16371053 0.1111111 0.473193121 0.1111111 1.959277e-02 0.06817024
204      1 0.16236743 0.1111111 0.463491415 0.1111111 1.884606e-02 0.06879814
205      1 0.16103323 0.1111111 0.453817269 0.1111111 1.812729e-02 0.06943140
206      1 0.15970790 0.1111111 0.444177872 0.1111111 1.743545e-02 0.07007004
207      1 0.15839142 0.1111111 0.434580312 0.1111111 1.676956e-02 0.07071411
208      1 0.15708377 0.1111111 0.425031550 0.1111111 1.612868e-02 0.07136365
209      1 0.15578491 0.1111111 0.415538404 0.1111111 1.551191e-02 0.07201869
210      1 0.15449482 0.1111111 0.406107529 0.1111111 1.491837e-02 0.07267927
211      1 0.15321348 0.1111111 0.396745399 0.1111111 1.434721e-02 0.07334543
212      1 0.15194085 0.1111111 0.387458289 0.1111111 1.379761e-02 0.07401721
213      1 0.15067692 0.1111111 0.378252264 0.1111111 1.326878e-02 0.07469465
214      1 0.14942165 0.1111111 0.369133158 0.1111111 1.275995e-02 0.07537779
215      1 0.14817500 0.1111111 0.360106568 0.1111111 1.227040e-02 0.07606665
216      1 0.14693697 0.1111111 0.351177838 0.1111111 1.179940e-02 0.07676130
217      1 0.14570751 0.1111111 0.342352048 0.1111111 1.134628e-02 0.07746175
218      1 0.14448659 0.1111111 0.333634010 0.1111111 1.091036e-02 0.07816805
219      1 0.14327419 0.1111111 0.325028256 0.1111111 1.049101e-02 0.07888024
220      1 0.14207027 0.1111111 0.316539035 0.1111111 1.008762e-02 0.07959836
221      1 0.14087480 0.1111111 0.308170307 0.1111111 9.699585e-03 0.08032245
222      1 0.13968776 0.1111111 0.299925739 0.1111111 9.326337e-03 0.08105255
223      1 0.13850911 0.1111111 0.291808706 0.1111111 8.967321e-03 0.08178869
224      1 0.13733881 0.1111111 0.283822287 0.1111111 8.622006e-03 0.08253092
225      1 0.13617684 0.1111111 0.275969271 0.1111111 8.289876e-03 0.08327927
226      1 0.13502316 0.1111111 0.268252152 0.1111111 7.970438e-03 0.08403378
227      1 0.13387774 0.1111111 0.260673138 0.1111111 7.663214e-03 0.08479450
228      1 0.13274054 0.1111111 0.253234153 0.1111111 7.367744e-03 0.08556147
229      1 0.13161154 0.1111111 0.245936839 0.1111111 7.083585e-03 0.08633471
230      1 0.13049070 0.1111111 0.238782569 0.1111111 6.810310e-03 0.08711428
231      1 0.12937797 0.1111111 0.231772449 0.1111111 6.547508e-03 0.08790021
232      1 0.12827334 0.1111111 0.224907324 0.1111111 6.294784e-03 0.08869254
233      1 0.12717676 0.1111111 0.218187791 0.1111111 6.051754e-03 0.08949131
234      1 0.12608820 0.1111111 0.211614207 0.1111111 5.818053e-03 0.09029657
235      1 0.12500762 0.1111111 0.205186694 0.1111111 5.593325e-03 0.09110834
236      1 0.12393499 0.1111111 0.198905154 0.1111111 5.377231e-03 0.09192668
237      1 0.12287027 0.1111111 0.192769276 0.1111111 5.169443e-03 0.09275161
238      1 0.12181343 0.1111111 0.186778547 0.1111111 4.969643e-03 0.09358318
239      1 0.12076442 0.1111111 0.180932265 0.1111111 4.777529e-03 0.09442144
240      1 0.11972322 0.1111111 0.175229544 0.1111111 4.592807e-03 0.09526641
241      1 0.11868978 0.1111111 0.169669331 0.1111111 4.415196e-03 0.09611815
242      1 0.11766407 0.1111111 0.164250414 0.1111111 4.244424e-03 0.09697668
243      1 0.11664605 0.1111111 0.158971431 0.1111111 4.080230e-03 0.09784205
244      1 0.11563569 0.1111111 0.153830885 0.1111111 3.922362e-03 0.09871430
245      1 0.11463294 0.1111111 0.148827150 0.1111111 3.770580e-03 0.09959346
246      1 0.11363777 0.1111111 0.143958484 0.1111111 3.624650e-03 0.10047958
247      1 0.11265013 0.1111111 0.139223038 0.1111111 3.484348e-03 0.10137270
248      1 0.11167000 0.1111111 0.134618866 0.1111111 3.349458e-03 0.10227286
249      1 0.11069734 0.1111111 0.130143935 0.1111111 3.219774e-03 0.10318009
250      1 0.10973210 0.1111111 0.125796134 0.1111111 3.095095e-03 0.10409443
251      1 0.10877425 0.1111111 0.121573282 0.1111111 2.975229e-03 0.10501593
252      1 0.10782374 0.1111111 0.117473138 0.1111111 2.859992e-03 0.10594462
253      1 0.10688055 0.1111111 0.113493409 0.1111111 2.749207e-03 0.10688055
254      1 0.10594462 0.1111111 0.109631756 0.1111111 2.642701e-03 0.10782374
255      1 0.10501593 0.1111111 0.105885802 0.1111111 2.540311e-03 0.10877425
256      1 0.10409443 0.1111111 0.102253143 0.1111111 2.441878e-03 0.10973210
257      1 0.10318009 0.1111111 0.098731349 0.1111111 2.347251e-03 0.11069734
258      1 0.10227286 0.1111111 0.095317974 0.1111111 2.256282e-03 0.11167000
259      1 0.10137270 0.1111111 0.092010560 0.1111111 2.168831e-03 0.11265013
260      1 0.10047958 0.1111111 0.088806643 0.1111111 2.084763e-03 0.11363777
261      1 0.09959346 0.1111111 0.085703760 0.1111111 2.003946e-03 0.11463294
262      1 0.09871430 0.1111111 0.082699452 0.1111111 1.926257e-03 0.11563569
263      1 0.09784205 0.1111111 0.079791267 0.1111111 1.851573e-03 0.11664605
264      1 0.09697668 0.1111111 0.076976769 0.1111111 1.779780e-03 0.11766407
265      1 0.09611815 0.1111111 0.074253536 0.1111111 1.710766e-03 0.11868978
266      1 0.09526641 0.1111111 0.071619169 0.1111111 1.644424e-03 0.11972322
267      1 0.09442144 0.1111111 0.069071290 0.1111111 1.580650e-03 0.12076442
268      1 0.09358318 0.1111111 0.066607550 0.1111111 1.519346e-03 0.12181343
269      1 0.09275161 0.1111111 0.064225628 0.1111111 1.460416e-03 0.12287027
270      1 0.09192668 0.1111111 0.061923233 0.1111111 1.403769e-03 0.12393499
271      1 0.09110834 0.1111111 0.059698111 0.1111111 1.349316e-03 0.12500762
272      1 0.09029657 0.1111111 0.057548040 0.1111111 1.296972e-03 0.12608820
273      1 0.08949131 0.1111111 0.055470837 0.1111111 1.246656e-03 0.12717676
274      1 0.08869254 0.1111111 0.053464358 0.1111111 1.198290e-03 0.12827334
275      1 0.08790021 0.1111111 0.051526497 0.1111111 1.151799e-03 0.12937797
276      1 0.08711428 0.1111111 0.049655191 0.1111111 1.107109e-03 0.13049070
277      1 0.08633471 0.1111111 0.047848417 0.1111111 1.064151e-03 0.13161154
278      1 0.08556147 0.1111111 0.046104196 0.1111111 1.022858e-03 0.13274054
279      1 0.08479450 0.1111111 0.044420591 0.1111111 9.831663e-04 0.13387774
280      1 0.08403378 0.1111111 0.042795708 0.1111111 9.450131e-04 0.13502316
281      1 0.08327927 0.1111111 0.041227699 0.1111111 9.083392e-04 0.13617684
282      1 0.08253092 0.1111111 0.039714757 0.1111111 8.730873e-04 0.13733881
283      1 0.08178869 0.1111111 0.038255120 0.1111111 8.392023e-04 0.13850911
284      1 0.08105255 0.1111111 0.036847071 0.1111111 8.066313e-04 0.13968776
285      1 0.08032245 0.1111111 0.035488935 0.1111111 7.753235e-04 0.14087480
286      1 0.07959836 0.1111111 0.034179082 0.1111111 7.452300e-04 0.14207027
287      1 0.07888024 0.1111111 0.032915924 0.1111111 7.163037e-04 0.14327419
288      1 0.07816805 0.1111111 0.031697917 0.1111111 6.884993e-04 0.14448659
289      1 0.07746175 0.1111111 0.030523557 0.1111111 6.617736e-04 0.14570751
290      1 0.07676130 0.1111111 0.029391386 0.1111111 6.360846e-04 0.14693697
291      1 0.07606665 0.1111111 0.028299982 0.1111111 6.113922e-04 0.14817500
292      1 0.07537779 0.1111111 0.027247969 0.1111111 5.876577e-04 0.14942165
293      1 0.07469465 0.1111111 0.026234007 0.1111111 5.648442e-04 0.15067692
294      1 0.07401721 0.1111111 0.025256797 0.1111111 5.429158e-04 0.15194085
295      1 0.07334543 0.1111111 0.024315079 0.1111111 5.218382e-04 0.15321348
296      1 0.07267927 0.1111111 0.023407630 0.1111111 5.015786e-04 0.15449482
297      1 0.07201869 0.1111111 0.022533266 0.1111111 4.821051e-04 0.15578491
298      1 0.07136365 0.1111111 0.021690837 0.1111111 4.633873e-04 0.15708377
299      1 0.07071411 0.1111111 0.020879230 0.1111111 4.453959e-04 0.15839142
300      1 0.07007004 0.1111111 0.020097368 0.1111111 4.281027e-04 0.15970790
301      1 0.06943140 0.1111111 0.019344205 0.1111111 4.114807e-04 0.16103323
302      1 0.06879814 0.1111111 0.018618732 0.1111111 3.955038e-04 0.16236743
303      1 0.06817024 0.1111111 0.017919968 0.1111111 3.801471e-04 0.16371053
304      1 0.16371053 0.1111111 0.446631479 0.1111111 3.075486e-03 0.06817024
305      1 0.16236743 0.1111111 0.437022587 0.1111111 2.956378e-03 0.06879814
306      1 0.16103323 0.1111111 0.427460731 0.1111111 2.841869e-03 0.06943140
307      1 0.15970790 0.1111111 0.417952769 0.1111111 2.731783e-03 0.07007004
308      1 0.15839142 0.1111111 0.408505398 0.1111111 2.625951e-03 0.07071411
309      1 0.15708377 0.1111111 0.399125138 0.1111111 2.524208e-03 0.07136365
310      1 0.15578491 0.1111111 0.389818320 0.1111111 2.426398e-03 0.07201869
311      1 0.15449482 0.1111111 0.380591061 0.1111111 2.332369e-03 0.07267927
312      1 0.15321348 0.1111111 0.371449256 0.1111111 2.241976e-03 0.07334543
313      1 0.15194085 0.1111111 0.362398564 0.1111111 2.155078e-03 0.07401721
314      1 0.15067692 0.1111111 0.353444394 0.1111111 2.071541e-03 0.07469465
315      1 0.14942165 0.1111111 0.344591894 0.1111111 1.991236e-03 0.07537779
316      1 0.14817500 0.1111111 0.335845946 0.1111111 1.914039e-03 0.07606665
317      1 0.14693697 0.1111111 0.327211154 0.1111111 1.839828e-03 0.07676130
318      1 0.14570751 0.1111111 0.318691839 0.1111111 1.768490e-03 0.07746175
319      1 0.14448659 0.1111111 0.310292034 0.1111111 1.699913e-03 0.07816805
320      1 0.14327419 0.1111111 0.302015483 0.1111111 1.633991e-03 0.07888024
321      1 0.14207027 0.1111111 0.293865634 0.1111111 1.570621e-03 0.07959836
322      1 0.14087480 0.1111111 0.285845642 0.1111111 1.509706e-03 0.08032245
323      1 0.13968776 0.1111111 0.277958370 0.1111111 1.451149e-03 0.08105255
324      1 0.13850911 0.1111111 0.270206387 0.1111111 1.394860e-03 0.08178869
325      1 0.13733881 0.1111111 0.262591974 0.1111111 1.340752e-03 0.08253092
326      1 0.13617684 0.1111111 0.255117124 0.1111111 1.288740e-03 0.08327927
327      1 0.13502316 0.1111111 0.247783554 0.1111111 1.238744e-03 0.08403378
328      1 0.13387774 0.1111111 0.240592704 0.1111111 1.190684e-03 0.08479450
329      1 0.13274054 0.1111111 0.233545746 0.1111111 1.144487e-03 0.08556147
330      1 0.13161154 0.1111111 0.226643592 0.1111111 1.100081e-03 0.08633471
331      1 0.13049070 0.1111111 0.219886901 0.1111111 1.057395e-03 0.08711428
332      1 0.12937797 0.1111111 0.213276091 0.1111111 1.016365e-03 0.08790021
333      1 0.12827334 0.1111111 0.206811342 0.1111111 9.769244e-04 0.08869254
334      1 0.12717676 0.1111111 0.200492611 0.1111111 9.390132e-04 0.08949131
335      1 0.12608820 0.1111111 0.194319641 0.1111111 9.025719e-04 0.09029657
336      1 0.12500762 0.1111111 0.188291970 0.1111111 8.675436e-04 0.09110834
337      1 0.12393499 0.1111111 0.182408942 0.1111111 8.338736e-04 0.09192668
338      1 0.12287027 0.1111111 0.176669718 0.1111111 8.015093e-04 0.09275161
339      1 0.12181343 0.1111111 0.171073285 0.1111111 7.704002e-04 0.09358318
340      1 0.12076442 0.1111111 0.165618472 0.1111111 7.404976e-04 0.09442144
341      1 0.11972322 0.1111111 0.160303954 0.1111111 7.117548e-04 0.09526641
342      1 0.11868978 0.1111111 0.155128267 0.1111111 6.841269e-04 0.09611815
343      1 0.11766407 0.1111111 0.150089817 0.1111111 6.575708e-04 0.09697668
344      1 0.11664605 0.1111111 0.145186890 0.1111111 6.320448e-04 0.09784205
345      1 0.11563569 0.1111111 0.140417664 0.1111111 6.075091e-04 0.09871430
346      1 0.11463294 0.1111111 0.135780217 0.1111111 5.839254e-04 0.09959346
347      1 0.11363777 0.1111111 0.131272537 0.1111111 5.612566e-04 0.10047958
348      1 0.11265013 0.1111111 0.126892533 0.1111111 5.394674e-04 0.10137270
349      1 0.11167000 0.1111111 0.122638039 0.1111111 5.185237e-04 0.10227286
350      1 0.11069734 0.1111111 0.118506830 0.1111111 4.983926e-04 0.10318009
351      1 0.10973210 0.1111111 0.114496625 0.1111111 4.790428e-04 0.10409443
352      1 0.10877425 0.1111111 0.110605095 0.1111111 4.604438e-04 0.10501593
353      1 0.10782374 0.1111111 0.106829875 0.1111111 4.425667e-04 0.10594462
354      1 0.10688055 0.1111111 0.103168565 0.1111111 4.253833e-04 0.10688055
355      1 0.10594462 0.1111111 0.099618740 0.1111111 4.088668e-04 0.10782374
356      1 0.10501593 0.1111111 0.096177960 0.1111111 3.929914e-04 0.10877425
357      1 0.10409443 0.1111111 0.092843767 0.1111111 3.777322e-04 0.10973210
358      1 0.10318009 0.1111111 0.089613701 0.1111111 3.630652e-04 0.11069734
359      1 0.10227286 0.1111111 0.086485296 0.1111111 3.489675e-04 0.11167000
360      1 0.10137270 0.1111111 0.083456092 0.1111111 3.354171e-04 0.11265013
361      1 0.10047958 0.1111111 0.080523635 0.1111111 3.223926e-04 0.11363777
362      1 0.09959346 0.1111111 0.077685485 0.1111111 3.098738e-04 0.11463294
363      1 0.09871430 0.1111111 0.074939215 0.1111111 2.978409e-04 0.11563569
364      1 0.09784205 0.1111111 0.072282421 0.1111111 2.862751e-04 0.11664605
365      1 0.09697668 0.1111111 0.069712719 0.1111111 2.751584e-04 0.11766407
366      1 0.09611815 0.1111111 0.067227752 0.1111111 2.644732e-04 0.11868978
367      1 0.09526641 0.1111111 0.064825191 0.1111111 2.542028e-04 0.11972322
368      1 0.09442144 0.1111111 0.062502738 0.1111111 2.443312e-04 0.12076442
369      1 0.09358318 0.1111111 0.060258130 0.1111111 2.348428e-04 0.12181343
370      1 0.09275161 0.1111111 0.058089135 0.1111111 2.257229e-04 0.12287027
371      1 0.09192668 0.1111111 0.055993562 0.1111111 2.169570e-04 0.12393499
372      1 0.09110834 0.1111111 0.053969255 0.1111111 2.085315e-04 0.12500762
373      1 0.09029657 0.1111111 0.052014100 0.1111111 2.004331e-04 0.12608820
374      1 0.08949131 0.1111111 0.050126021 0.1111111 1.926491e-04 0.12717676
375      1 0.08869254 0.1111111 0.048302986 0.1111111 1.851674e-04 0.12827334
376      1 0.08790021 0.1111111 0.046543005 0.1111111 1.779762e-04 0.12937797
377      1 0.08711428 0.1111111 0.044844129 0.1111111 1.710642e-04 0.13049070
378      1 0.08633471 0.1111111 0.043204454 0.1111111 1.644207e-04 0.13161154
379      1 0.08556147 0.1111111 0.041622119 0.1111111 1.580351e-04 0.13274054
380      1 0.08479450 0.1111111 0.040095308 0.1111111 1.518974e-04 0.13387774
381      1 0.08403378 0.1111111 0.038622248 0.1111111 1.459981e-04 0.13502316
382      1 0.08327927 0.1111111 0.037201208 0.1111111 1.403279e-04 0.13617684
383      1 0.08253092 0.1111111 0.035830505 0.1111111 1.348778e-04 0.13733881
384      1 0.08178869 0.1111111 0.034508496 0.1111111 1.296394e-04 0.13850911
385      1 0.08105255 0.1111111 0.033233583 0.1111111 1.246045e-04 0.13968776
386      1 0.08032245 0.1111111 0.032004210 0.1111111 1.197650e-04 0.14087480
387      1 0.07959836 0.1111111 0.030818864 0.1111111 1.151135e-04 0.14207027
388      1 0.07888024 0.1111111 0.029676074 0.1111111 1.106426e-04 0.14327419
389      1 0.07816805 0.1111111 0.028574411 0.1111111 1.063454e-04 0.14448659
390      1 0.07746175 0.1111111 0.027512485 0.1111111 1.022150e-04 0.14570751
391      1 0.07676130 0.1111111 0.026488947 0.1111111 9.824506e-05 0.14693697
392      1 0.07606665 0.1111111 0.025502490 0.1111111 9.442928e-05 0.14817500
393      1 0.07537779 0.1111111 0.024551842 0.1111111 9.076168e-05 0.14942165
394      1 0.07469465 0.1111111 0.023635771 0.1111111 8.723652e-05 0.15067692
395      1 0.07401721 0.1111111 0.022753083 0.1111111 8.384827e-05 0.15194085
396      1 0.07334543 0.1111111 0.021902620 0.1111111 8.059160e-05 0.15321348
397      1 0.07267927 0.1111111 0.021083260 0.1111111 7.746141e-05 0.15449482
398      1 0.07201869 0.1111111 0.020293916 0.1111111 7.445279e-05 0.15578491
399      1 0.07136365 0.1111111 0.019533534 0.1111111 7.156102e-05 0.15708377
400      1 0.07071411 0.1111111 0.018801096 0.1111111 6.878156e-05 0.15839142
401      1 0.07007004 0.1111111 0.018095615 0.1111111 6.611004e-05 0.15970790
402      1 0.06943140 0.1111111 0.017416136 0.1111111 6.354228e-05 0.16103323
403      1 0.06879814 0.1111111 0.016761736 0.1111111 6.107425e-05 0.16236743
404      1 0.06817024 0.1111111 0.016131520 0.1111111 5.870208e-05 0.16371053
405      1 0.16371053 0.1111111 0.420371072 0.1111111 4.759999e-04 0.06817024
406      1 0.16236743 0.1111111 0.410907628 0.1111111 4.575191e-04 0.06879814
407      1 0.16103323 0.1111111 0.401509652 0.1111111 4.397554e-04 0.06943140
408      1 0.15970790 0.1111111 0.392183522 0.1111111 4.226811e-04 0.07007004
409      1 0.15839142 0.1111111 0.382935412 0.1111111 4.062696e-04 0.07071411
410      1 0.15708377 0.1111111 0.373771276 0.1111111 3.904949e-04 0.07136365
411      1 0.15578491 0.1111111 0.364696834 0.1111111 3.753326e-04 0.07201869
412      1 0.15449482 0.1111111 0.355717559 0.1111111 3.607588e-04 0.07267927
413      1 0.15321348 0.1111111 0.346838667 0.1111111 3.467506e-04 0.07334543
414      1 0.15194085 0.1111111 0.338065108 0.1111111 3.332862e-04 0.07401721
415      1 0.15067692 0.1111111 0.329401558 0.1111111 3.203445e-04 0.07469465
416      1 0.14942165 0.1111111 0.320852410 0.1111111 3.079051e-04 0.07537779
417      1 0.14817500 0.1111111 0.312421772 0.1111111 2.959487e-04 0.07606665
418      1 0.14693697 0.1111111 0.304113462 0.1111111 2.844564e-04 0.07676130
419      1 0.14570751 0.1111111 0.295931002 0.1111111 2.734102e-04 0.07746175
420      1 0.14448659 0.1111111 0.287877624 0.1111111 2.627929e-04 0.07816805
421      1 0.14327419 0.1111111 0.279956263 0.1111111 2.525878e-04 0.07888024
422      1 0.14207027 0.1111111 0.272169564 0.1111111 2.427789e-04 0.07959836
423      1 0.14087480 0.1111111 0.264519880 0.1111111 2.333508e-04 0.08032245
424      1 0.13968776 0.1111111 0.257009278 0.1111111 2.242887e-04 0.08105255
425      1 0.13850911 0.1111111 0.249639546 0.1111111 2.155785e-04 0.08178869
426      1 0.13733881 0.1111111 0.242412191 0.1111111 2.072065e-04 0.08253092
427      1 0.13617684 0.1111111 0.235328455 0.1111111 1.991596e-04 0.08327927
428      1 0.13502316 0.1111111 0.228389314 0.1111111 1.914251e-04 0.08403378
429      1 0.13387774 0.1111111 0.221595493 0.1111111 1.839909e-04 0.08479450
430      1 0.13274054 0.1111111 0.214947468 0.1111111 1.768454e-04 0.08556147
431      1 0.13161154 0.1111111 0.208445480 0.1111111 1.699773e-04 0.08633471
432      1 0.13049070 0.1111111 0.202089542 0.1111111 1.633760e-04 0.08711428
433      1 0.12937797 0.1111111 0.195879450 0.1111111 1.570309e-04 0.08790021
434      1 0.12827334 0.1111111 0.189814794 0.1111111 1.509323e-04 0.08869254
435      1 0.12717676 0.1111111 0.183894966 0.1111111 1.450704e-04 0.08949131
436      1 0.12608820 0.1111111 0.178119172 0.1111111 1.394362e-04 0.09029657
437      1 0.12500762 0.1111111 0.172486444 0.1111111 1.340208e-04 0.09110834
438      1 0.12393499 0.1111111 0.166995648 0.1111111 1.288157e-04 0.09192668
439      1 0.12287027 0.1111111 0.161645500 0.1111111 1.238127e-04 0.09275161
440      1 0.12181343 0.1111111 0.156434568 0.1111111 1.190040e-04 0.09358318
441      1 0.12076442 0.1111111 0.151361291 0.1111111 1.143821e-04 0.09442144
442      1 0.11972322 0.1111111 0.146423985 0.1111111 1.099396e-04 0.09526641
443      1 0.11868978 0.1111111 0.141620855 0.1111111 1.056696e-04 0.09611815
444      1 0.11766407 0.1111111 0.136950002 0.1111111 1.015655e-04 0.09697668
445      1 0.11664605 0.1111111 0.132409437 0.1111111 9.762078e-05 0.09784205
446      1 0.11563569 0.1111111 0.127997088 0.1111111 9.382924e-05 0.09871430
447      1 0.11463294 0.1111111 0.123710808 0.1111111 9.018495e-05 0.09959346
448      1 0.11363777 0.1111111 0.119548386 0.1111111 8.668218e-05 0.10047958
449      1 0.11265013 0.1111111 0.115507553 0.1111111 8.331546e-05 0.10137270
450      1 0.11167000 0.1111111 0.111585994 0.1111111 8.007948e-05 0.10227286
451      1 0.11069734 0.1111111 0.107781350 0.1111111 7.696918e-05 0.10318009
452      1 0.10973210 0.1111111 0.104091231 0.1111111 7.397968e-05 0.10409443
453      1 0.10877425 0.1111111 0.100513218 0.1111111 7.110628e-05 0.10501593
454      1 0.10782374 0.1111111 0.097044872 0.1111111 6.834448e-05 0.10594462
455      1 0.10688055 0.1111111 0.093683742 0.1111111 6.568994e-05 0.10688055
456      1 0.10594462 0.1111111 0.090427365 0.1111111 6.313850e-05 0.10782374
457      1 0.10501593 0.1111111 0.087273278 0.1111111 6.068615e-05 0.10877425
458      1 0.10409443 0.1111111 0.084219019 0.1111111 5.832905e-05 0.10973210
459      1 0.10318009 0.1111111 0.081262132 0.1111111 5.606350e-05 0.11069734
460      1 0.10227286 0.1111111 0.078400171 0.1111111 5.388593e-05 0.11167000
461      1 0.10137270 0.1111111 0.075630709 0.1111111 5.179294e-05 0.11265013
462      1 0.10047958 0.1111111 0.072951332 0.1111111 4.978124e-05 0.11363777
463      1 0.09959346 0.1111111 0.070359653 0.1111111 4.784767e-05 0.11463294
464      1 0.09871430 0.1111111 0.067853308 0.1111111 4.598921e-05 0.11563569
465      1 0.09784205 0.1111111 0.065429959 0.1111111 4.420292e-05 0.11664605
466      1 0.09697668 0.1111111 0.063087302 0.1111111 4.248601e-05 0.11766407
467      1 0.09611815 0.1111111 0.060823062 0.1111111 4.083579e-05 0.11868978
468      1 0.09526641 0.1111111 0.058635002 0.1111111 3.924966e-05 0.11972322
469      1 0.09442144 0.1111111 0.056520918 0.1111111 3.772514e-05 0.12076442
470      1 0.09358318 0.1111111 0.054478646 0.1111111 3.625983e-05 0.12181343
471      1 0.09275161 0.1111111 0.052506061 0.1111111 3.485144e-05 0.12287027
472      1 0.09192668 0.1111111 0.050601078 0.1111111 3.349774e-05 0.12393499
473      1 0.09110834 0.1111111 0.048761652 0.1111111 3.219663e-05 0.12500762
474      1 0.09029657 0.1111111 0.046985784 0.1111111 3.094605e-05 0.12608820
475      1 0.08949131 0.1111111 0.045271513 0.1111111 2.974404e-05 0.12717676
476      1 0.08869254 0.1111111 0.043616925 0.1111111 2.858872e-05 0.12827334
477      1 0.08790021 0.1111111 0.042020148 0.1111111 2.747828e-05 0.12937797
478      1 0.08711428 0.1111111 0.040479353 0.1111111 2.641097e-05 0.13049070
479      1 0.08633471 0.1111111 0.038992756 0.1111111 2.538511e-05 0.13161154
480      1 0.08556147 0.1111111 0.037558617 0.1111111 2.439909e-05 0.13274054
481      1 0.08479450 0.1111111 0.036175239 0.1111111 2.345138e-05 0.13387774
482      1 0.08403378 0.1111111 0.034840971 0.1111111 2.254047e-05 0.13502316
483      1 0.08327927 0.1111111 0.033554201 0.1111111 2.166495e-05 0.13617684
484      1 0.08253092 0.1111111 0.032313364 0.1111111 2.082343e-05 0.13733881
485      1 0.08178869 0.1111111 0.031116937 0.1111111 2.001460e-05 0.13850911
486      1 0.08105255 0.1111111 0.029963436 0.1111111 1.923719e-05 0.13968776
487      1 0.08032245 0.1111111 0.028851422 0.1111111 1.848997e-05 0.14087480
488      1 0.07959836 0.1111111 0.027779495 0.1111111 1.777177e-05 0.14207027
489      1 0.07888024 0.1111111 0.026746297 0.1111111 1.708147e-05 0.14327419
490      1 0.07816805 0.1111111 0.025750509 0.1111111 1.641799e-05 0.14448659
491      1 0.07746175 0.1111111 0.024790851 0.1111111 1.578027e-05 0.14570751
492      1 0.07676130 0.1111111 0.023866081 0.1111111 1.516733e-05 0.14693697
493      1 0.07606665 0.1111111 0.022974995 0.1111111 1.457819e-05 0.14817500
494      1 0.07537779 0.1111111 0.022116425 0.1111111 1.401193e-05 0.14942165
495      1 0.07469465 0.1111111 0.021289241 0.1111111 1.346767e-05 0.15067692
496      1 0.07401721 0.1111111 0.020492346 0.1111111 1.294455e-05 0.15194085
497      1 0.07334543 0.1111111 0.019724679 0.1111111 1.244175e-05 0.15321348
498      1 0.07267927 0.1111111 0.018985212 0.1111111 1.195848e-05 0.15449482
499      1 0.07201869 0.1111111 0.018272951 0.1111111 1.149398e-05 0.15578491
500      1 0.07136365 0.1111111 0.017586933 0.1111111 1.104753e-05 0.15708377
501      1 0.07071411 0.1111111 0.016926225 0.1111111 1.061841e-05 0.15839142
502      1 0.07007004 0.1111111 0.016289928 0.1111111 1.020596e-05 0.15970790
503      1 0.06943140 0.1111111 0.015677169 0.1111111 9.809534e-06 0.16103323
504      1 0.06879814 0.1111111 0.015087106 0.1111111 9.428504e-06 0.16236743
505      1 0.06817024 0.1111111 0.014518924 0.1111111 9.062275e-06 0.16371053
506      1 0.16371053 0.1111111 0.394553795 0.1111111 7.350958e-05 0.06817024
507      1 0.16236743 0.1111111 0.385285222 0.1111111 7.065444e-05 0.06879814
508      1 0.16103323 0.1111111 0.376099127 0.1111111 6.791019e-05 0.06943140
509      1 0.15970790 0.1111111 0.367001289 0.1111111 6.527251e-05 0.07007004
510      1 0.15839142 0.1111111 0.357997248 0.1111111 6.273728e-05 0.07071411
511      1 0.15708377 0.1111111 0.349092285 0.1111111 6.030052e-05 0.07136365
512      1 0.15578491 0.1111111 0.340291420 0.1111111 5.795839e-05 0.07201869
513      1 0.15449482 0.1111111 0.331599397 0.1111111 5.570723e-05 0.07267927
514      1 0.15321348 0.1111111 0.323020684 0.1111111 5.354351e-05 0.07334543
515      1 0.15194085 0.1111111 0.314559462 0.1111111 5.146382e-05 0.07401721
516      1 0.15067692 0.1111111 0.306219621 0.1111111 4.946490e-05 0.07469465
517      1 0.14942165 0.1111111 0.298004760 0.1111111 4.754362e-05 0.07537779
518      1 0.14817500 0.1111111 0.289918186 0.1111111 4.569696e-05 0.07606665
519      1 0.14693697 0.1111111 0.281962908 0.1111111 4.392203e-05 0.07676130
520      1 0.14570751 0.1111111 0.274141646 0.1111111 4.221603e-05 0.07746175
521      1 0.14448659 0.1111111 0.266456826 0.1111111 4.057629e-05 0.07816805
522      1 0.14327419 0.1111111 0.258910588 0.1111111 3.900024e-05 0.07888024
523      1 0.14207027 0.1111111 0.251504791 0.1111111 3.748541e-05 0.07959836
524      1 0.14087480 0.1111111 0.244241012 0.1111111 3.602941e-05 0.08032245
525      1 0.13968776 0.1111111 0.237120561 0.1111111 3.462996e-05 0.08105255
526      1 0.13850911 0.1111111 0.230144481 0.1111111 3.328487e-05 0.08178869
527      1 0.13733881 0.1111111 0.223313560 0.1111111 3.199203e-05 0.08253092
528      1 0.13617684 0.1111111 0.216628336 0.1111111 3.074939e-05 0.08327927
529      1 0.13502316 0.1111111 0.210089110 0.1111111 2.955503e-05 0.08403378
530      1 0.13387774 0.1111111 0.203695951 0.1111111 2.840705e-05 0.08479450
531      1 0.13274054 0.1111111 0.197448711 0.1111111 2.730366e-05 0.08556147
532      1 0.13161154 0.1111111 0.191347030 0.1111111 2.624313e-05 0.08633471
533      1 0.13049070 0.1111111 0.185390350 0.1111111 2.522379e-05 0.08711428
534      1 0.12937797 0.1111111 0.179577924 0.1111111 2.424404e-05 0.08790021
535      1 0.12827334 0.1111111 0.173908826 0.1111111 2.330235e-05 0.08869254
536      1 0.12717676 0.1111111 0.168381966 0.1111111 2.239723e-05 0.08949131
537      1 0.12608820 0.1111111 0.162996093 0.1111111 2.152727e-05 0.09029657
538      1 0.12500762 0.1111111 0.157749815 0.1111111 2.069110e-05 0.09110834
539      1 0.12393499 0.1111111 0.152641602 0.1111111 1.988741e-05 0.09192668
540      1 0.12287027 0.1111111 0.147669800 0.1111111 1.911494e-05 0.09275161
541      1 0.12181343 0.1111111 0.142832642 0.1111111 1.837247e-05 0.09358318
542      1 0.12076442 0.1111111 0.138128254 0.1111111 1.765884e-05 0.09442144
543      1 0.11972322 0.1111111 0.133554670 0.1111111 1.697292e-05 0.09526641
544      1 0.11868978 0.1111111 0.129109836 0.1111111 1.631365e-05 0.09611815
545      1 0.11766407 0.1111111 0.124791626 0.1111111 1.567999e-05 0.09697668
546      1 0.11664605 0.1111111 0.120597843 0.1111111 1.507094e-05 0.09784205
547      1 0.11563569 0.1111111 0.116526233 0.1111111 1.448555e-05 0.09871430
548      1 0.11463294 0.1111111 0.112574490 0.1111111 1.392289e-05 0.09959346
549      1 0.11363777 0.1111111 0.108740268 0.1111111 1.338209e-05 0.10047958
550      1 0.11265013 0.1111111 0.105021183 0.1111111 1.286229e-05 0.10137270
551      1 0.11167000 0.1111111 0.101414822 0.1111111 1.236269e-05 0.10227286
552      1 0.11069734 0.1111111 0.097918752 0.1111111 1.188249e-05 0.10318009
553      1 0.10973210 0.1111111 0.094530524 0.1111111 1.142094e-05 0.10409443
554      1 0.10877425 0.1111111 0.091247677 0.1111111 1.097732e-05 0.10501593
555      1 0.10782374 0.1111111 0.088067748 0.1111111 1.055093e-05 0.10594462
556      1 0.10688055 0.1111111 0.084988274 0.1111111 1.014110e-05 0.10688055
557      1 0.10594462 0.1111111 0.082006797 0.1111111 9.747195e-06 0.10782374
558      1 0.10501593 0.1111111 0.079120869 0.1111111 9.368587e-06 0.10877425
559      1 0.10409443 0.1111111 0.076328056 0.1111111 9.004685e-06 0.10973210
560      1 0.10318009 0.1111111 0.073625943 0.1111111 8.654918e-06 0.11069734
561      1 0.10227286 0.1111111 0.071012134 0.1111111 8.318737e-06 0.11167000
562      1 0.10137270 0.1111111 0.068484258 0.1111111 7.995614e-06 0.11265013
563      1 0.10047958 0.1111111 0.066039971 0.1111111 7.685041e-06 0.11363777
564      1 0.09959346 0.1111111 0.063676961 0.1111111 7.386533e-06 0.11463294
565      1 0.09871430 0.1111111 0.061392945 0.1111111 7.099619e-06 0.11563569
566      1 0.09784205 0.1111111 0.059185676 0.1111111 6.823849e-06 0.11664605
567      1 0.09697668 0.1111111 0.057052940 0.1111111 6.558791e-06 0.11766407
568      1 0.09611815 0.1111111 0.054992565 0.1111111 6.304029e-06 0.11868978
569      1 0.09526641 0.1111111 0.053002415 0.1111111 6.059162e-06 0.11972322
570      1 0.09442144 0.1111111 0.051080394 0.1111111 5.823807e-06 0.12076442
571      1 0.09358318 0.1111111 0.049224449 0.1111111 5.597593e-06 0.12181343
572      1 0.09275161 0.1111111 0.047432566 0.1111111 5.380166e-06 0.12287027
573      1 0.09192668 0.1111111 0.045702776 0.1111111 5.171185e-06 0.12393499
574      1 0.09110834 0.1111111 0.044033153 0.1111111 4.970321e-06 0.12500762
575      1 0.09029657 0.1111111 0.042421814 0.1111111 4.777259e-06 0.12608820
576      1 0.08949131 0.1111111 0.040866919 0.1111111 4.591696e-06 0.12717676
577      1 0.08869254 0.1111111 0.039366673 0.1111111 4.413341e-06 0.12827334
578      1 0.08790021 0.1111111 0.037919324 0.1111111 4.241914e-06 0.12937797
579      1 0.08711428 0.1111111 0.036523165 0.1111111 4.077145e-06 0.13049070
580      1 0.08633471 0.1111111 0.035176532 0.1111111 3.918777e-06 0.13161154
581      1 0.08556147 0.1111111 0.033877804 0.1111111 3.766560e-06 0.13274054
582      1 0.08479450 0.1111111 0.032625405 0.1111111 3.620255e-06 0.13387774
583      1 0.08403378 0.1111111 0.031417798 0.1111111 3.479634e-06 0.13502316
584      1 0.08327927 0.1111111 0.030253493 0.1111111 3.344474e-06 0.13617684
585      1 0.08253092 0.1111111 0.029131037 0.1111111 3.214565e-06 0.13733881
586      1 0.08178869 0.1111111 0.028049022 0.1111111 3.089702e-06 0.13850911
587      1 0.08105255 0.1111111 0.027006078 0.1111111 2.969688e-06 0.13968776
588      1 0.08032245 0.1111111 0.026000877 0.1111111 2.854337e-06 0.14087480
589      1 0.07959836 0.1111111 0.025032128 0.1111111 2.743466e-06 0.14207027
590      1 0.07888024 0.1111111 0.024098580 0.1111111 2.636901e-06 0.14327419
591      1 0.07816805 0.1111111 0.023199019 0.1111111 2.534476e-06 0.14448659
592      1 0.07746175 0.1111111 0.022332269 0.1111111 2.436029e-06 0.14570751
593      1 0.07676130 0.1111111 0.021497189 0.1111111 2.341406e-06 0.14693697
594      1 0.07606665 0.1111111 0.020692675 0.1111111 2.250459e-06 0.14817500
595      1 0.07537779 0.1111111 0.019917656 0.1111111 2.163044e-06 0.14942165
596      1 0.07469465 0.1111111 0.019171097 0.1111111 2.079025e-06 0.15067692
597      1 0.07401721 0.1111111 0.018451993 0.1111111 1.998269e-06 0.15194085
598      1 0.07334543 0.1111111 0.017759374 0.1111111 1.920651e-06 0.15321348
599      1 0.07267927 0.1111111 0.017092301 0.1111111 1.846047e-06 0.15449482
600      1 0.07201869 0.1111111 0.016449865 0.1111111 1.774340e-06 0.15578491
601      1 0.07136365 0.1111111 0.015831187 0.1111111 1.705420e-06 0.15708377
602      1 0.07071411 0.1111111 0.015235416 0.1111111 1.639176e-06 0.15839142
603      1 0.07007004 0.1111111 0.014661732 0.1111111 1.575505e-06 0.15970790
604      1 0.06943140 0.1111111 0.014109341 0.1111111 1.514308e-06 0.16103323
605      1 0.06879814 0.1111111 0.013577474 0.1111111 1.455487e-06 0.16236743
606      1 0.06817024 0.1111111 0.013065391 0.1111111 1.398952e-06 0.16371053
607      1 0.16371053 0.1111111 0.369311842 0.1111111 1.134836e-05 0.06817024
608      1 0.16236743 0.1111111 0.360283378 0.1111111 1.090756e-05 0.06879814
609      1 0.16103323 0.1111111 0.351352670 0.1111111 1.048388e-05 0.06943140
610      1 0.15970790 0.1111111 0.342524806 0.1111111 1.007666e-05 0.07007004
611      1 0.15839142 0.1111111 0.333804602 0.1111111 9.685253e-06 0.07071411
612      1 0.15708377 0.1111111 0.325196595 0.1111111 9.309051e-06 0.07136365
613      1 0.15578491 0.1111111 0.316705041 0.1111111 8.947461e-06 0.07201869
614      1 0.15449482 0.1111111 0.308333903 0.1111111 8.599917e-06 0.07267927
615      1 0.15321348 0.1111111 0.300086857 0.1111111 8.265872e-06 0.07334543
616      1 0.15194085 0.1111111 0.291967282 0.1111111 7.944802e-06 0.07401721
617      1 0.15067692 0.1111111 0.283978264 0.1111111 7.636204e-06 0.07469465
618      1 0.14942165 0.1111111 0.276122596 0.1111111 7.339592e-06 0.07537779
619      1 0.14817500 0.1111111 0.268402779 0.1111111 7.054501e-06 0.07606665
620      1 0.14693697 0.1111111 0.260821026 0.1111111 6.780484e-06 0.07676130
621      1 0.14570751 0.1111111 0.253379267 0.1111111 6.517111e-06 0.07746175
622      1 0.14448659 0.1111111 0.246079149 0.1111111 6.263967e-06 0.07816805
623      1 0.14327419 0.1111111 0.238922051 0.1111111 6.020657e-06 0.07888024
624      1 0.14207027 0.1111111 0.231909083 0.1111111 5.786797e-06 0.07959836
625      1 0.14087480 0.1111111 0.225041097 0.1111111 5.562021e-06 0.08032245
626      1 0.13968776 0.1111111 0.218318693 0.1111111 5.345976e-06 0.08105255
627      1 0.13850911 0.1111111 0.211742233 0.1111111 5.138322e-06 0.08178869
628      1 0.13733881 0.1111111 0.205311845 0.1111111 4.938735e-06 0.08253092
629      1 0.13617684 0.1111111 0.199027433 0.1111111 4.746900e-06 0.08327927
630      1 0.13502316 0.1111111 0.192888691 0.1111111 4.562516e-06 0.08403378
631      1 0.13387774 0.1111111 0.186895110 0.1111111 4.385294e-06 0.08479450
632      1 0.13274054 0.1111111 0.181045991 0.1111111 4.214957e-06 0.08556147
633      1 0.13161154 0.1111111 0.175340453 0.1111111 4.051235e-06 0.08633471
634      1 0.13049070 0.1111111 0.169777446 0.1111111 3.893873e-06 0.08711428
635      1 0.12937797 0.1111111 0.164355759 0.1111111 3.742624e-06 0.08790021
636      1 0.12827334 0.1111111 0.159074035 0.1111111 3.597249e-06 0.08869254
637      1 0.12717676 0.1111111 0.153930778 0.1111111 3.457521e-06 0.08949131
638      1 0.12608820 0.1111111 0.148924366 0.1111111 3.323220e-06 0.09029657
639      1 0.12500762 0.1111111 0.144053058 0.1111111 3.194137e-06 0.09110834
640      1 0.12393499 0.1111111 0.139315007 0.1111111 3.070067e-06 0.09192668
641      1 0.12287027 0.1111111 0.134708269 0.1111111 2.950816e-06 0.09275161
642      1 0.12181343 0.1111111 0.130230814 0.1111111 2.836197e-06 0.09358318
643      1 0.12076442 0.1111111 0.125880530 0.1111111 2.726031e-06 0.09442144
644      1 0.11972322 0.1111111 0.121655240 0.1111111 2.620144e-06 0.09526641
645      1 0.11868978 0.1111111 0.117552702 0.1111111 2.518369e-06 0.09611815
646      1 0.11766407 0.1111111 0.113570624 0.1111111 2.420548e-06 0.09697668
647      1 0.11664605 0.1111111 0.109706668 0.1111111 2.326527e-06 0.09784205
648      1 0.11563569 0.1111111 0.105958460 0.1111111 2.236157e-06 0.09871430
649      1 0.11463294 0.1111111 0.102323594 0.1111111 2.149298e-06 0.09959346
650      1 0.11363777 0.1111111 0.098799640 0.1111111 2.065813e-06 0.10047958
651      1 0.11265013 0.1111111 0.095384154 0.1111111 1.985570e-06 0.10137270
652      1 0.11167000 0.1111111 0.092074677 0.1111111 1.908445e-06 0.10227286
653      1 0.11069734 0.1111111 0.088868746 0.1111111 1.834315e-06 0.10318009
654      1 0.10973210 0.1111111 0.085763898 0.1111111 1.763065e-06 0.10409443
655      1 0.10877425 0.1111111 0.082757672 0.1111111 1.694582e-06 0.10501593
656      1 0.10782374 0.1111111 0.079847618 0.1111111 1.628759e-06 0.10594462
657      1 0.10688055 0.1111111 0.077031298 0.1111111 1.565493e-06 0.10688055
658      1 0.10594462 0.1111111 0.074306292 0.1111111 1.504684e-06 0.10782374
659      1 0.10501593 0.1111111 0.071670198 0.1111111 1.446238e-06 0.10877425
660      1 0.10409443 0.1111111 0.069120639 0.1111111 1.390062e-06 0.10973210
661      1 0.10318009 0.1111111 0.066655265 0.1111111 1.336067e-06 0.11069734
662      1 0.10227286 0.1111111 0.064271754 0.1111111 1.284170e-06 0.11167000
663      1 0.10137270 0.1111111 0.061967815 0.1111111 1.234289e-06 0.11265013
664      1 0.10047958 0.1111111 0.059741193 0.1111111 1.186346e-06 0.11363777
665      1 0.09959346 0.1111111 0.057589665 0.1111111 1.140264e-06 0.11463294
666      1 0.09871430 0.1111111 0.055511048 0.1111111 1.095973e-06 0.11563569
667      1 0.09784205 0.1111111 0.053503197 0.1111111 1.053402e-06 0.11664605
668      1 0.09697668 0.1111111 0.051564005 0.1111111 1.012485e-06 0.11766407
669      1 0.09611815 0.1111111 0.049691408 0.1111111 9.731565e-07 0.11868978
670      1 0.09526641 0.1111111 0.047883383 0.1111111 9.353561e-07 0.11972322
671      1 0.09442144 0.1111111 0.046137949 0.1111111 8.990240e-07 0.12076442
672      1 0.09358318 0.1111111 0.044453169 0.1111111 8.641031e-07 0.12181343
673      1 0.09275161 0.1111111 0.042827148 0.1111111 8.305387e-07 0.12287027
674      1 0.09192668 0.1111111 0.041258036 0.1111111 7.982780e-07 0.12393499
675      1 0.09110834 0.1111111 0.039744027 0.1111111 7.672704e-07 0.12500762
676      1 0.09029657 0.1111111 0.038283357 0.1111111 7.374672e-07 0.12608820
677      1 0.08949131 0.1111111 0.036874309 0.1111111 7.088217e-07 0.12717676
678      1 0.08869254 0.1111111 0.035515206 0.1111111 6.812889e-07 0.12827334
679      1 0.08790021 0.1111111 0.034204418 0.1111111 6.548255e-07 0.12937797
680      1 0.08711428 0.1111111 0.032940355 0.1111111 6.293901e-07 0.13049070
681      1 0.08633471 0.1111111 0.031721474 0.1111111 6.049426e-07 0.13161154
682      1 0.08556147 0.1111111 0.030546269 0.1111111 5.814447e-07 0.13274054
683      1 0.08479450 0.1111111 0.029413281 0.1111111 5.588596e-07 0.13387774
684      1 0.08403378 0.1111111 0.028321088 0.1111111 5.371518e-07 0.13502316
685      1 0.08327927 0.1111111 0.027268312 0.1111111 5.162871e-07 0.13617684
686      1 0.08253092 0.1111111 0.026253613 0.1111111 4.962329e-07 0.13733881
687      1 0.08178869 0.1111111 0.025275692 0.1111111 4.769577e-07 0.13850911
688      1 0.08105255 0.1111111 0.024333287 0.1111111 4.584312e-07 0.13968776
689      1 0.08032245 0.1111111 0.023425175 0.1111111 4.406243e-07 0.14087480
690      1 0.07959836 0.1111111 0.022550171 0.1111111 4.235091e-07 0.14207027
691      1 0.07888024 0.1111111 0.021707124 0.1111111 4.070587e-07 0.14327419
692      1 0.07816805 0.1111111 0.020894921 0.1111111 3.912472e-07 0.14448659
693      1 0.07746175 0.1111111 0.020112483 0.1111111 3.760500e-07 0.14570751
694      1 0.07676130 0.1111111 0.019358765 0.1111111 3.614430e-07 0.14693697
695      1 0.07606665 0.1111111 0.018632755 0.1111111 3.474035e-07 0.14817500
696      1 0.07537779 0.1111111 0.017933476 0.1111111 3.339092e-07 0.14942165
697      1 0.07469465 0.1111111 0.017259978 0.1111111 3.209391e-07 0.15067692
698      1 0.07401721 0.1111111 0.016611346 0.1111111 3.084729e-07 0.15194085
699      1 0.07334543 0.1111111 0.015986693 0.1111111 2.964908e-07 0.15321348
700      1 0.07267927 0.1111111 0.015385162 0.1111111 2.849742e-07 0.15449482
701      1 0.07201869 0.1111111 0.014805924 0.1111111 2.739049e-07 0.15578491
702      1 0.07136365 0.1111111 0.014248179 0.1111111 2.632656e-07 0.15708377
703      1 0.07071411 0.1111111 0.013711151 0.1111111 2.530395e-07 0.15839142
704      1 0.07007004 0.1111111 0.013194094 0.1111111 2.432107e-07 0.15970790
705      1 0.06943140 0.1111111 0.012696284 0.1111111 2.337636e-07 0.16103323
706      1 0.06879814 0.1111111 0.012217024 0.1111111 2.246835e-07 0.16236743
707      1 0.06817024 0.1111111 0.011755640 0.1111111 2.159561e-07 0.16371053
708      1 0.16371053 0.1111111 0.344765190 0.1111111 1.751860e-06 0.06817024
709      1 0.16236743 0.1111111 0.336017099 0.1111111 1.683813e-06 0.06879814
710      1 0.16103323 0.1111111 0.327380075 0.1111111 1.618408e-06 0.06943140
711      1 0.15970790 0.1111111 0.318858446 0.1111111 1.555544e-06 0.07007004
712      1 0.15839142 0.1111111 0.310456251 0.1111111 1.495122e-06 0.07071411
713      1 0.15708377 0.1111111 0.302177239 0.1111111 1.437047e-06 0.07136365
714      1 0.15578491 0.1111111 0.294024864 0.1111111 1.381228e-06 0.07201869
715      1 0.15449482 0.1111111 0.286002287 0.1111111 1.327577e-06 0.07267927
716      1 0.15321348 0.1111111 0.278112376 0.1111111 1.276010e-06 0.07334543
717      1 0.15194085 0.1111111 0.270357706 0.1111111 1.226445e-06 0.07401721
718      1 0.15067692 0.1111111 0.262740563 0.1111111 1.178806e-06 0.07469465
719      1 0.14942165 0.1111111 0.255262948 0.1111111 1.133018e-06 0.07537779
720      1 0.14817500 0.1111111 0.247926582 0.1111111 1.089008e-06 0.07606665
721      1 0.14693697 0.1111111 0.240732909 0.1111111 1.046708e-06 0.07676130
722      1 0.14570751 0.1111111 0.233683108 0.1111111 1.006050e-06 0.07746175
723      1 0.14448659 0.1111111 0.226778095 0.1111111 9.669722e-07 0.07816805
724      1 0.14327419 0.1111111 0.220018536 0.1111111 9.294120e-07 0.07888024
725      1 0.14207027 0.1111111 0.213404851 0.1111111 8.933107e-07 0.07959836
726      1 0.14087480 0.1111111 0.206937225 0.1111111 8.586118e-07 0.08032245
727      1 0.13968776 0.1111111 0.200615621 0.1111111 8.252606e-07 0.08105255
728      1 0.13850911 0.1111111 0.194439785 0.1111111 7.932050e-07 0.08178869
729      1 0.13733881 0.1111111 0.188409259 0.1111111 7.623944e-07 0.08253092
730      1 0.13617684 0.1111111 0.182523390 0.1111111 7.327807e-07 0.08327927
731      1 0.13502316 0.1111111 0.176781343 0.1111111 7.043172e-07 0.08403378
732      1 0.13387774 0.1111111 0.171182110 0.1111111 6.769593e-07 0.08479450
733      1 0.13274054 0.1111111 0.165724521 0.1111111 6.506641e-07 0.08556147
734      1 0.13161154 0.1111111 0.160407254 0.1111111 6.253903e-07 0.08633471
735      1 0.13049070 0.1111111 0.155228848 0.1111111 6.010982e-07 0.08711428
736      1 0.12937797 0.1111111 0.150187712 0.1111111 5.777497e-07 0.08790021
737      1 0.12827334 0.1111111 0.145282134 0.1111111 5.553081e-07 0.08869254
738      1 0.12717676 0.1111111 0.140510293 0.1111111 5.337382e-07 0.08949131
739      1 0.12608820 0.1111111 0.135870271 0.1111111 5.130062e-07 0.09029657
740      1 0.12500762 0.1111111 0.131360056 0.1111111 4.930794e-07 0.09110834
741      1 0.12393499 0.1111111 0.126977558 0.1111111 4.739267e-07 0.09192668
742      1 0.12287027 0.1111111 0.122720614 0.1111111 4.555179e-07 0.09275161
743      1 0.12181343 0.1111111 0.118587000 0.1111111 4.378241e-07 0.09358318
744      1 0.12076442 0.1111111 0.114574434 0.1111111 4.208177e-07 0.09442144
745      1 0.11972322 0.1111111 0.110680591 0.1111111 4.044718e-07 0.09526641
746      1 0.11868978 0.1111111 0.106903103 0.1111111 3.887609e-07 0.09611815
747      1 0.11766407 0.1111111 0.103239573 0.1111111 3.736602e-07 0.09697668
748      1 0.11664605 0.1111111 0.099687577 0.1111111 3.591461e-07 0.09784205
749      1 0.11563569 0.1111111 0.096244673 0.1111111 3.451957e-07 0.09871430
750      1 0.11463294 0.1111111 0.092908406 0.1111111 3.317872e-07 0.09959346
751      1 0.11363777 0.1111111 0.089676313 0.1111111 3.188996e-07 0.10047958
752      1 0.11265013 0.1111111 0.086545930 0.1111111 3.065125e-07 0.10137270
753      1 0.11167000 0.1111111 0.083514796 0.1111111 2.946066e-07 0.10227286
754      1 0.11069734 0.1111111 0.080580458 0.1111111 2.831632e-07 0.10318009
755      1 0.10973210 0.1111111 0.077740474 0.1111111 2.721643e-07 0.10409443
756      1 0.10877425 0.1111111 0.074992419 0.1111111 2.615925e-07 0.10501593
757      1 0.10782374 0.1111111 0.072333886 0.1111111 2.514315e-07 0.10594462
758      1 0.10688055 0.1111111 0.069762492 0.1111111 2.416651e-07 0.10688055
759      1 0.10594462 0.1111111 0.067275879 0.1111111 2.322781e-07 0.10782374
760      1 0.10501593 0.1111111 0.064871717 0.1111111 2.232557e-07 0.10877425
761      1 0.10409443 0.1111111 0.062547710 0.1111111 2.145837e-07 0.10973210
762      1 0.10318009 0.1111111 0.060301590 0.1111111 2.062486e-07 0.11069734
763      1 0.10227286 0.1111111 0.058131128 0.1111111 1.982373e-07 0.11167000
764      1 0.10137270 0.1111111 0.056034130 0.1111111 1.905371e-07 0.11265013
765      1 0.10047958 0.1111111 0.054008440 0.1111111 1.831361e-07 0.11363777
766      1 0.09959346 0.1111111 0.052051943 0.1111111 1.760225e-07 0.11463294
767      1 0.09871430 0.1111111 0.050162563 0.1111111 1.691852e-07 0.11563569
768      1 0.09784205 0.1111111 0.048338267 0.1111111 1.626135e-07 0.11664605
769      1 0.09697668 0.1111111 0.046577063 0.1111111 1.562971e-07 0.11766407
770      1 0.09611815 0.1111111 0.044877003 0.1111111 1.502261e-07 0.11868978
771      1 0.09526641 0.1111111 0.043236180 0.1111111 1.443908e-07 0.11972322
772      1 0.09442144 0.1111111 0.041652734 0.1111111 1.387822e-07 0.12076442
773      1 0.09358318 0.1111111 0.040124847 0.1111111 1.333915e-07 0.12181343
774      1 0.09275161 0.1111111 0.038650745 0.1111111 1.282101e-07 0.12287027
775      1 0.09192668 0.1111111 0.037228698 0.1111111 1.232301e-07 0.12393499
776      1 0.09110834 0.1111111 0.035857019 0.1111111 1.184434e-07 0.12500762
777      1 0.09029657 0.1111111 0.034534067 0.1111111 1.138427e-07 0.12608820
778      1 0.08949131 0.1111111 0.033258242 0.1111111 1.094207e-07 0.12717676
779      1 0.08869254 0.1111111 0.032027987 0.1111111 1.051705e-07 0.12827334
780      1 0.08790021 0.1111111 0.030841789 0.1111111 1.010853e-07 0.12937797
781      1 0.08711428 0.1111111 0.029698175 0.1111111 9.715884e-08 0.13049070
782      1 0.08633471 0.1111111 0.028595715 0.1111111 9.338489e-08 0.13161154
783      1 0.08556147 0.1111111 0.027533020 0.1111111 8.975752e-08 0.13274054
784      1 0.08479450 0.1111111 0.026508739 0.1111111 8.627106e-08 0.13387774
785      1 0.08403378 0.1111111 0.025521564 0.1111111 8.292002e-08 0.13502316
786      1 0.08327927 0.1111111 0.024570223 0.1111111 7.969915e-08 0.13617684
787      1 0.08253092 0.1111111 0.023653483 0.1111111 7.660339e-08 0.13733881
788      1 0.08178869 0.1111111 0.022770149 0.1111111 7.362787e-08 0.13850911
789      1 0.08105255 0.1111111 0.021919063 0.1111111 7.076794e-08 0.13968776
790      1 0.08032245 0.1111111 0.021099101 0.1111111 6.801909e-08 0.14087480
791      1 0.07959836 0.1111111 0.020309175 0.1111111 6.537701e-08 0.14207027
792      1 0.07888024 0.1111111 0.019548233 0.1111111 6.283757e-08 0.14327419
793      1 0.07816805 0.1111111 0.018815255 0.1111111 6.039676e-08 0.14448659
794      1 0.07746175 0.1111111 0.018109252 0.1111111 5.805076e-08 0.14570751
795      1 0.07676130 0.1111111 0.017429270 0.1111111 5.579589e-08 0.14693697
796      1 0.07606665 0.1111111 0.016774385 0.1111111 5.362860e-08 0.14817500
797      1 0.07537779 0.1111111 0.016143702 0.1111111 5.154550e-08 0.14942165
798      1 0.07469465 0.1111111 0.015536356 0.1111111 4.954331e-08 0.15067692
799      1 0.07401721 0.1111111 0.014951512 0.1111111 4.761889e-08 0.15194085
800      1 0.07334543 0.1111111 0.014388363 0.1111111 4.576923e-08 0.15321348
801      1 0.07267927 0.1111111 0.013846126 0.1111111 4.399141e-08 0.15449482
802      1 0.07201869 0.1111111 0.013324047 0.1111111 4.228264e-08 0.15578491
803      1 0.07136365 0.1111111 0.012821398 0.1111111 4.064025e-08 0.15708377
804      1 0.07071411 0.1111111 0.012337474 0.1111111 3.906166e-08 0.15839142
805      1 0.07007004 0.1111111 0.011871596 0.1111111 3.754438e-08 0.15970790
806      1 0.06943140 0.1111111 0.011423106 0.1111111 3.608604e-08 0.16103323
807      1 0.06879814 0.1111111 0.010991371 0.1111111 3.468434e-08 0.16236743
808      1 0.06817024 0.1111111 0.010575779 0.1111111 3.333710e-08 0.16371053
809      1 0.16371053 0.1111111 0.321019615 0.1111111 2.704347e-07 0.06817024
810      1 0.16236743 0.1111111 0.312586606 0.1111111 2.599301e-07 0.06879814
811      1 0.16103323 0.1111111 0.304275852 0.1111111 2.498336e-07 0.06943140
812      1 0.15970790 0.1111111 0.296090882 0.1111111 2.401293e-07 0.07007004
813      1 0.15839142 0.1111111 0.288034933 0.1111111 2.308019e-07 0.07071411
814      1 0.15708377 0.1111111 0.280110946 0.1111111 2.218369e-07 0.07136365
815      1 0.15578491 0.1111111 0.272321572 0.1111111 2.132200e-07 0.07201869
816      1 0.15449482 0.1111111 0.264669169 0.1111111 2.049379e-07 0.07267927
817      1 0.15321348 0.1111111 0.257155811 0.1111111 1.969775e-07 0.07334543
818      1 0.15194085 0.1111111 0.249783289 0.1111111 1.893263e-07 0.07401721
819      1 0.15067692 0.1111111 0.242553118 0.1111111 1.819722e-07 0.07469465
820      1 0.14942165 0.1111111 0.235466543 0.1111111 1.749039e-07 0.07537779
821      1 0.14817500 0.1111111 0.228524548 0.1111111 1.681101e-07 0.07606665
822      1 0.14693697 0.1111111 0.221727860 0.1111111 1.615801e-07 0.07676130
823      1 0.14570751 0.1111111 0.215076961 0.1111111 1.553039e-07 0.07746175
824      1 0.14448659 0.1111111 0.208572096 0.1111111 1.492714e-07 0.07816805
825      1 0.14327419 0.1111111 0.202213284 0.1111111 1.434732e-07 0.07888024
826      1 0.14207027 0.1111111 0.196000324 0.1111111 1.379003e-07 0.07959836
827      1 0.14087480 0.1111111 0.189932809 0.1111111 1.325438e-07 0.08032245
828      1 0.13968776 0.1111111 0.184010136 0.1111111 1.273954e-07 0.08105255
829      1 0.13850911 0.1111111 0.178231515 0.1111111 1.224469e-07 0.08178869
830      1 0.13733881 0.1111111 0.172595980 0.1111111 1.176907e-07 0.08253092
831      1 0.13617684 0.1111111 0.167102402 0.1111111 1.131192e-07 0.08327927
832      1 0.13502316 0.1111111 0.161749497 0.1111111 1.087253e-07 0.08403378
833      1 0.13387774 0.1111111 0.156535839 0.1111111 1.045021e-07 0.08479450
834      1 0.13274054 0.1111111 0.151459868 0.1111111 1.004429e-07 0.08556147
835      1 0.13161154 0.1111111 0.146519901 0.1111111 9.654140e-08 0.08633471
836      1 0.13049070 0.1111111 0.141714147 0.1111111 9.279143e-08 0.08711428
837      1 0.12937797 0.1111111 0.137040709 0.1111111 8.918712e-08 0.08790021
838      1 0.12827334 0.1111111 0.132497598 0.1111111 8.572281e-08 0.08869254
839      1 0.12717676 0.1111111 0.128082745 0.1111111 8.239307e-08 0.08949131
840      1 0.12608820 0.1111111 0.123794004 0.1111111 7.919267e-08 0.09029657
841      1 0.12500762 0.1111111 0.119629164 0.1111111 7.611658e-08 0.09110834
842      1 0.12393499 0.1111111 0.115585960 0.1111111 7.315997e-08 0.09192668
843      1 0.12287027 0.1111111 0.111662075 0.1111111 7.031821e-08 0.09275161
844      1 0.12181343 0.1111111 0.107855152 0.1111111 6.758683e-08 0.09358318
845      1 0.12076442 0.1111111 0.104162801 0.1111111 6.496155e-08 0.09442144
846      1 0.11972322 0.1111111 0.100582604 0.1111111 6.243824e-08 0.09526641
847      1 0.11868978 0.1111111 0.097112122 0.1111111 6.001294e-08 0.09611815
848      1 0.11766407 0.1111111 0.093748905 0.1111111 5.768185e-08 0.09697668
849      1 0.11664605 0.1111111 0.090490489 0.1111111 5.544131e-08 0.09784205
850      1 0.11563569 0.1111111 0.087334412 0.1111111 5.328779e-08 0.09871430
851      1 0.11463294 0.1111111 0.084278211 0.1111111 5.121793e-08 0.09959346
852      1 0.11363777 0.1111111 0.081319430 0.1111111 4.922846e-08 0.10047958
853      1 0.11265013 0.1111111 0.078455624 0.1111111 4.731628e-08 0.10137270
854      1 0.11167000 0.1111111 0.075684363 0.1111111 4.547836e-08 0.10227286
855      1 0.11069734 0.1111111 0.073003236 0.1111111 4.371184e-08 0.10318009
856      1 0.10973210 0.1111111 0.070409853 0.1111111 4.201394e-08 0.10409443
857      1 0.10877425 0.1111111 0.067901850 0.1111111 4.038198e-08 0.10501593
858      1 0.10782374 0.1111111 0.065476890 0.1111111 3.881342e-08 0.10594462
859      1 0.10688055 0.1111111 0.063132665 0.1111111 3.730579e-08 0.10688055
860      1 0.10594462 0.1111111 0.060866903 0.1111111 3.585671e-08 0.10782374
861      1 0.10501593 0.1111111 0.058677364 0.1111111 3.446393e-08 0.10877425
862      1 0.10409443 0.1111111 0.056561845 0.1111111 3.312524e-08 0.10973210
863      1 0.10318009 0.1111111 0.054518180 0.1111111 3.183855e-08 0.11069734
864      1 0.10227286 0.1111111 0.052544243 0.1111111 3.060184e-08 0.11167000
865      1 0.10137270 0.1111111 0.050637948 0.1111111 2.941317e-08 0.11265013
866      1 0.10047958 0.1111111 0.048797252 0.1111111 2.827067e-08 0.11363777
867      1 0.09959346 0.1111111 0.047020151 0.1111111 2.717255e-08 0.11463294
868      1 0.09871430 0.1111111 0.045304686 0.1111111 2.611708e-08 0.11563569
869      1 0.09784205 0.1111111 0.043648941 0.1111111 2.510262e-08 0.11664605
870      1 0.09697668 0.1111111 0.042051043 0.1111111 2.412755e-08 0.11766407
871      1 0.09611815 0.1111111 0.040509163 0.1111111 2.319036e-08 0.11868978
872      1 0.09526641 0.1111111 0.039021515 0.1111111 2.228958e-08 0.11972322
873      1 0.09442144 0.1111111 0.037586360 0.1111111 2.142378e-08 0.12076442
874      1 0.09358318 0.1111111 0.036201999 0.1111111 2.059161e-08 0.12181343
875      1 0.09275161 0.1111111 0.034866779 0.1111111 1.979177e-08 0.12287027
876      1 0.09192668 0.1111111 0.033579090 0.1111111 1.902300e-08 0.12393499
877      1 0.09110834 0.1111111 0.032337363 0.1111111 1.828408e-08 0.12500762
878      1 0.09029657 0.1111111 0.031140076 0.1111111 1.757387e-08 0.12608820
879      1 0.08949131 0.1111111 0.029985743 0.1111111 1.689125e-08 0.12717676
880      1 0.08869254 0.1111111 0.028872926 0.1111111 1.623514e-08 0.12827334
881      1 0.08790021 0.1111111 0.027800224 0.1111111 1.560452e-08 0.12937797
882      1 0.08711428 0.1111111 0.026766276 0.1111111 1.499839e-08 0.13049070
883      1 0.08633471 0.1111111 0.025769764 0.1111111 1.441580e-08 0.13161154
884      1 0.08556147 0.1111111 0.024809407 0.1111111 1.385585e-08 0.13274054
885      1 0.08479450 0.1111111 0.023883961 0.1111111 1.331764e-08 0.13387774
886      1 0.08403378 0.1111111 0.022992223 0.1111111 1.280034e-08 0.13502316
887      1 0.08327927 0.1111111 0.022133024 0.1111111 1.230314e-08 0.13617684
888      1 0.08253092 0.1111111 0.021305232 0.1111111 1.182525e-08 0.13733881
889      1 0.08178869 0.1111111 0.020507751 0.1111111 1.136592e-08 0.13850911
890      1 0.08105255 0.1111111 0.019739519 0.1111111 1.092443e-08 0.13968776
891      1 0.08032245 0.1111111 0.018999507 0.1111111 1.050009e-08 0.14087480
892      1 0.07959836 0.1111111 0.018286720 0.1111111 1.009223e-08 0.14207027
893      1 0.07888024 0.1111111 0.017600194 0.1111111 9.700220e-09 0.14327419
894      1 0.07816805 0.1111111 0.016938996 0.1111111 9.323433e-09 0.14448659
895      1 0.07746175 0.1111111 0.016302227 0.1111111 8.961282e-09 0.14570751
896      1 0.07676130 0.1111111 0.015689013 0.1111111 8.613198e-09 0.14693697
897      1 0.07606665 0.1111111 0.015098510 0.1111111 8.278634e-09 0.14817500
898      1 0.07537779 0.1111111 0.014529906 0.1111111 7.957066e-09 0.14942165
899      1 0.07469465 0.1111111 0.013982410 0.1111111 7.647989e-09 0.15067692
900      1 0.07401721 0.1111111 0.013455263 0.1111111 7.350917e-09 0.15194085
901      1 0.07334543 0.1111111 0.012947729 0.1111111 7.065384e-09 0.15321348
902      1 0.07267927 0.1111111 0.012459097 0.1111111 6.790943e-09 0.15449482
903      1 0.07201869 0.1111111 0.011988682 0.1111111 6.527161e-09 0.15578491
904      1 0.07136365 0.1111111 0.011535820 0.1111111 6.273626e-09 0.15708377
905      1 0.07071411 0.1111111 0.011099873 0.1111111 6.029939e-09 0.15839142
906      1 0.07007004 0.1111111 0.010680223 0.1111111 5.795717e-09 0.15970790
907      1 0.06943140 0.1111111 0.010276273 0.1111111 5.570593e-09 0.16103323
908      1 0.06879814 0.1111111 0.009887449 0.1111111 5.354214e-09 0.16236743
909      1 0.06817024 0.1111111 0.009513195 0.1111111 5.146239e-09 0.16371053
910      1 0.16371053 0.1111111 0.298165286 0.1111111 4.174694e-08 0.06817024
911      1 0.16236743 0.1111111 0.290076156 0.1111111 4.012536e-08 0.06879814
912      1 0.16103323 0.1111111 0.282118266 0.1111111 3.856676e-08 0.06943140
913      1 0.15970790 0.1111111 0.274294340 0.1111111 3.706871e-08 0.07007004
914      1 0.15839142 0.1111111 0.266606812 0.1111111 3.562885e-08 0.07071411
915      1 0.15708377 0.1111111 0.259057827 0.1111111 3.424491e-08 0.07136365
916      1 0.15578491 0.1111111 0.251649248 0.1111111 3.291473e-08 0.07201869
917      1 0.15449482 0.1111111 0.244382659 0.1111111 3.163622e-08 0.07267927
918      1 0.15321348 0.1111111 0.237259375 0.1111111 3.040737e-08 0.07334543
919      1 0.15194085 0.1111111 0.230280444 0.1111111 2.922625e-08 0.07401721
920      1 0.15067692 0.1111111 0.223446659 0.1111111 2.809101e-08 0.07469465
921      1 0.14942165 0.1111111 0.216758562 0.1111111 2.699987e-08 0.07537779
922      1 0.14817500 0.1111111 0.210216460 0.1111111 2.595111e-08 0.07606665
923      1 0.14693697 0.1111111 0.203820426 0.1111111 2.494309e-08 0.07676130
924      1 0.14570751 0.1111111 0.197570315 0.1111111 2.397422e-08 0.07746175
925      1 0.14448659 0.1111111 0.191465773 0.1111111 2.304299e-08 0.07816805
926      1 0.14327419 0.1111111 0.185506244 0.1111111 2.214793e-08 0.07888024
927      1 0.14207027 0.1111111 0.179690986 0.1111111 2.128763e-08 0.07959836
928      1 0.14087480 0.1111111 0.174019076 0.1111111 2.046075e-08 0.08032245
929      1 0.13968776 0.1111111 0.168489426 0.1111111 1.966599e-08 0.08105255
930      1 0.13850911 0.1111111 0.163100791 0.1111111 1.890210e-08 0.08178869
931      1 0.13733881 0.1111111 0.157851778 0.1111111 1.816789e-08 0.08253092
932      1 0.13617684 0.1111111 0.152740862 0.1111111 1.746219e-08 0.08327927
933      1 0.13502316 0.1111111 0.147766391 0.1111111 1.678390e-08 0.08403378
934      1 0.13387774 0.1111111 0.142926599 0.1111111 1.613196e-08 0.08479450
935      1 0.13274054 0.1111111 0.138219616 0.1111111 1.550535e-08 0.08556147
936      1 0.13161154 0.1111111 0.133643476 0.1111111 1.490307e-08 0.08633471
937      1 0.13049070 0.1111111 0.129196128 0.1111111 1.432419e-08 0.08711428
938      1 0.12937797 0.1111111 0.124875445 0.1111111 1.376779e-08 0.08790021
939      1 0.12827334 0.1111111 0.120679233 0.1111111 1.323301e-08 0.08869254
940      1 0.12717676 0.1111111 0.116605240 0.1111111 1.271900e-08 0.08949131
941      1 0.12608820 0.1111111 0.112651160 0.1111111 1.222495e-08 0.09029657
942      1 0.12500762 0.1111111 0.108814646 0.1111111 1.175010e-08 0.09110834
943      1 0.12393499 0.1111111 0.105093317 0.1111111 1.129369e-08 0.09192668
944      1 0.12287027 0.1111111 0.101484760 0.1111111 1.085500e-08 0.09275161
945      1 0.12181343 0.1111111 0.097986542 0.1111111 1.043336e-08 0.09358318
946      1 0.12076442 0.1111111 0.094596214 0.1111111 1.002810e-08 0.09442144
947      1 0.11972322 0.1111111 0.091311316 0.1111111 9.638575e-09 0.09526641
948      1 0.11868978 0.1111111 0.088129385 0.1111111 9.264183e-09 0.09611815
949      1 0.11766407 0.1111111 0.085047956 0.1111111 8.904333e-09 0.09697668
950      1 0.11664605 0.1111111 0.082064573 0.1111111 8.558461e-09 0.09784205
951      1 0.11563569 0.1111111 0.079176787 0.1111111 8.226024e-09 0.09871430
952      1 0.11463294 0.1111111 0.076382165 0.1111111 7.906499e-09 0.09959346
953      1 0.11363777 0.1111111 0.073678288 0.1111111 7.599386e-09 0.10047958
954      1 0.11265013 0.1111111 0.071062763 0.1111111 7.304202e-09 0.10137270
955      1 0.11167000 0.1111111 0.068533218 0.1111111 7.020484e-09 0.10227286
956      1 0.11069734 0.1111111 0.066087308 0.1111111 6.747786e-09 0.10318009
957      1 0.10973210 0.1111111 0.063722720 0.1111111 6.485681e-09 0.10409443
958      1 0.10877425 0.1111111 0.061437170 0.1111111 6.233757e-09 0.10501593
959      1 0.10782374 0.1111111 0.059228411 0.1111111 5.991619e-09 0.10594462
960      1 0.10688055 0.1111111 0.057094229 0.1111111 5.758885e-09 0.10688055
961      1 0.10594462 0.1111111 0.055032450 0.1111111 5.535192e-09 0.10782374
962      1 0.10501593 0.1111111 0.053040938 0.1111111 5.320188e-09 0.10877425
963      1 0.10409443 0.1111111 0.051117595 0.1111111 5.113535e-09 0.10973210
964      1 0.10318009 0.1111111 0.049260368 0.1111111 4.914910e-09 0.11069734
965      1 0.10227286 0.1111111 0.047467243 0.1111111 4.723999e-09 0.11167000
966      1 0.10137270 0.1111111 0.045736250 0.1111111 4.540504e-09 0.11265013
967      1 0.10047958 0.1111111 0.044065460 0.1111111 4.364137e-09 0.11363777
968      1 0.09959346 0.1111111 0.042452991 0.1111111 4.194620e-09 0.11463294
969      1 0.09871430 0.1111111 0.040897002 0.1111111 4.031688e-09 0.11563569
970      1 0.09784205 0.1111111 0.039395697 0.1111111 3.875085e-09 0.11664605
971      1 0.09697668 0.1111111 0.037947323 0.1111111 3.724564e-09 0.11766407
972      1 0.09611815 0.1111111 0.036550172 0.1111111 3.579890e-09 0.11868978
973      1 0.09526641 0.1111111 0.035202580 0.1111111 3.440836e-09 0.11972322
974      1 0.09442144 0.1111111 0.033902924 0.1111111 3.307183e-09 0.12076442
975      1 0.09358318 0.1111111 0.032649627 0.1111111 3.178722e-09 0.12181343
976      1 0.09275161 0.1111111 0.031441154 0.1111111 3.055251e-09 0.12287027
977      1 0.09192668 0.1111111 0.030276010 0.1111111 2.936575e-09 0.12393499
978      1 0.09110834 0.1111111 0.029152744 0.1111111 2.822509e-09 0.12500762
979      1 0.09029657 0.1111111 0.028069946 0.1111111 2.712874e-09 0.12608820
980      1 0.08949131 0.1111111 0.027026246 0.1111111 2.607498e-09 0.12717676
981      1 0.08869254 0.1111111 0.026020314 0.1111111 2.506214e-09 0.12827334
982      1 0.08790021 0.1111111 0.025050859 0.1111111 2.408865e-09 0.12937797
983      1 0.08711428 0.1111111 0.024116630 0.1111111 2.315297e-09 0.13049070
984      1 0.08633471 0.1111111 0.023216411 0.1111111 2.225364e-09 0.13161154
985      1 0.08556147 0.1111111 0.022349026 0.1111111 2.138924e-09 0.13274054
986      1 0.08479450 0.1111111 0.021513334 0.1111111 2.055841e-09 0.13387774
987      1 0.08403378 0.1111111 0.020708228 0.1111111 1.975986e-09 0.13502316
988      1 0.08327927 0.1111111 0.019932639 0.1111111 1.899233e-09 0.13617684
989      1 0.08253092 0.1111111 0.019185528 0.1111111 1.825460e-09 0.13733881
990      1 0.08178869 0.1111111 0.018465894 0.1111111 1.754554e-09 0.13850911
991      1 0.08105255 0.1111111 0.017772763 0.1111111 1.686401e-09 0.13968776
992      1 0.08032245 0.1111111 0.017105195 0.1111111 1.620896e-09 0.14087480
993      1 0.07959836 0.1111111 0.016462283 0.1111111 1.557936e-09 0.14207027
994      1 0.07888024 0.1111111 0.015843145 0.1111111 1.497421e-09 0.14327419
995      1 0.07816805 0.1111111 0.015246931 0.1111111 1.439256e-09 0.14448659
996      1 0.07746175 0.1111111 0.014672820 0.1111111 1.383351e-09 0.14570751
997      1 0.07676130 0.1111111 0.014120017 0.1111111 1.329617e-09 0.14693697
998      1 0.07606665 0.1111111 0.013587753 0.1111111 1.277971e-09 0.14817500
999      1 0.07537779 0.1111111 0.013075288 0.1111111 1.228330e-09 0.14942165
1000     1 0.07469465 0.1111111 0.012581904 0.1111111 1.180618e-09 0.15067692
1001     1 0.07401721 0.1111111 0.012106908 0.1111111 1.134759e-09 0.15194085
1002     1 0.07334543 0.1111111 0.011649634 0.1111111 1.090682e-09 0.15321348
1003     1 0.07267927 0.1111111 0.011209434 0.1111111 1.048316e-09 0.15449482
1004     1 0.07201869 0.1111111 0.010785687 0.1111111 1.007596e-09 0.15578491
1005     1 0.07136365 0.1111111 0.010377790 0.1111111 9.684581e-10 0.15708377
1006     1 0.07071411 0.1111111 0.009985163 0.1111111 9.308401e-10 0.15839142
1007     1 0.07007004 0.1111111 0.009607247 0.1111111 8.946834e-10 0.15970790
1008     1 0.06943140 0.1111111 0.009243501 0.1111111 8.599311e-10 0.16103323
1009     1 0.06879814 0.1111111 0.008893402 0.1111111 8.265287e-10 0.16236743
1010     1 0.06817024 0.1111111 0.008556450 0.1111111 7.944237e-10 0.16371053
1011     1 0.16371053 0.1111111 0.276275973 0.1111111 6.444465e-09 0.06817024
1012     1 0.16236743 0.1111111 0.268553459 0.1111111 6.194142e-09 0.06879814
1013     1 0.16103323 0.1111111 0.260968969 0.1111111 5.953542e-09 0.06943140
1014     1 0.15970790 0.1111111 0.253524435 0.1111111 5.722288e-09 0.07007004
1015     1 0.15839142 0.1111111 0.246221515 0.1111111 5.500016e-09 0.07071411
1016     1 0.15708377 0.1111111 0.239061589 0.1111111 5.286378e-09 0.07136365
1017     1 0.15578491 0.1111111 0.232045774 0.1111111 5.081039e-09 0.07201869
1018     1 0.15449482 0.1111111 0.225174926 0.1111111 4.883675e-09 0.07267927
1019     1 0.15321348 0.1111111 0.218449652 0.1111111 4.693978e-09 0.07334543
1020     1 0.15194085 0.1111111 0.211870317 0.1111111 4.511649e-09 0.07401721
1021     1 0.15067692 0.1111111 0.205437052 0.1111111 4.336403e-09 0.07469465
1022     1 0.14942165 0.1111111 0.199149768 0.1111111 4.167963e-09 0.07537779
1023     1 0.14817500 0.1111111 0.193008162 0.1111111 4.006067e-09 0.07606665
1024     1 0.14693697 0.1111111 0.187011729 0.1111111 3.850459e-09 0.07676130
1025     1 0.14570751 0.1111111 0.181159774 0.1111111 3.700895e-09 0.07746175
1026     1 0.14448659 0.1111111 0.175451418 0.1111111 3.557140e-09 0.07816805
1027     1 0.14327419 0.1111111 0.169885615 0.1111111 3.418970e-09 0.07888024
1028     1 0.14207027 0.1111111 0.164461158 0.1111111 3.286166e-09 0.07959836
1029     1 0.14087480 0.1111111 0.159176692 0.1111111 3.158521e-09 0.08032245
1030     1 0.13968776 0.1111111 0.154030725 0.1111111 3.035835e-09 0.08105255
1031     1 0.13850911 0.1111111 0.149021634 0.1111111 2.917913e-09 0.08178869
1032     1 0.13733881 0.1111111 0.144147683 0.1111111 2.804572e-09 0.08253092
1033     1 0.13617684 0.1111111 0.139407027 0.1111111 2.695634e-09 0.08327927
1034     1 0.13502316 0.1111111 0.134797723 0.1111111 2.590927e-09 0.08403378
1035     1 0.13387774 0.1111111 0.130317742 0.1111111 2.490287e-09 0.08479450
1036     1 0.13274054 0.1111111 0.125964976 0.1111111 2.393557e-09 0.08556147
1037     1 0.13161154 0.1111111 0.121737245 0.1111111 2.300584e-09 0.08633471
1038     1 0.13049070 0.1111111 0.117632312 0.1111111 2.211222e-09 0.08711428
1039     1 0.12937797 0.1111111 0.113647885 0.1111111 2.125331e-09 0.08790021
1040     1 0.12827334 0.1111111 0.109781626 0.1111111 2.042777e-09 0.08869254
1041     1 0.12717676 0.1111111 0.106031162 0.1111111 1.963429e-09 0.08949131
1042     1 0.12608820 0.1111111 0.102394087 0.1111111 1.887163e-09 0.09029657
1043     1 0.12500762 0.1111111 0.098867973 0.1111111 1.813860e-09 0.09110834
1044     1 0.12393499 0.1111111 0.095450375 0.1111111 1.743404e-09 0.09192668
1045     1 0.12287027 0.1111111 0.092138834 0.1111111 1.675684e-09 0.09275161
1046     1 0.12181343 0.1111111 0.088930888 0.1111111 1.610596e-09 0.09358318
1047     1 0.12076442 0.1111111 0.085824073 0.1111111 1.548035e-09 0.09442144
1048     1 0.11972322 0.1111111 0.082815929 0.1111111 1.487904e-09 0.09526641
1049     1 0.11868978 0.1111111 0.079904005 0.1111111 1.430110e-09 0.09611815
1050     1 0.11766407 0.1111111 0.077085863 0.1111111 1.374560e-09 0.09697668
1051     1 0.11664605 0.1111111 0.074359082 0.1111111 1.321168e-09 0.09784205
1052     1 0.11563569 0.1111111 0.071721261 0.1111111 1.269849e-09 0.09871430
1053     1 0.11463294 0.1111111 0.069170021 0.1111111 1.220524e-09 0.09959346
1054     1 0.11363777 0.1111111 0.066703012 0.1111111 1.173115e-09 0.10047958
1055     1 0.11265013 0.1111111 0.064317911 0.1111111 1.127548e-09 0.10137270
1056     1 0.11167000 0.1111111 0.062012427 0.1111111 1.083750e-09 0.10227286
1057     1 0.11069734 0.1111111 0.059784304 0.1111111 1.041654e-09 0.10318009
1058     1 0.10973210 0.1111111 0.057631319 0.1111111 1.001193e-09 0.10409443
1059     1 0.10877425 0.1111111 0.055551287 0.1111111 9.623035e-10 0.10501593
1060     1 0.10782374 0.1111111 0.053542063 0.1111111 9.249247e-10 0.10594462
1061     1 0.10688055 0.1111111 0.051601539 0.1111111 8.889977e-10 0.10688055
1062     1 0.10594462 0.1111111 0.049727650 0.1111111 8.544662e-10 0.10782374
1063     1 0.10501593 0.1111111 0.047918373 0.1111111 8.212761e-10 0.10877425
1064     1 0.10409443 0.1111111 0.046171726 0.1111111 7.893752e-10 0.10973210
1065     1 0.10318009 0.1111111 0.044485770 0.1111111 7.587134e-10 0.11069734
1066     1 0.10227286 0.1111111 0.042858610 0.1111111 7.292426e-10 0.11167000
1067     1 0.10137270 0.1111111 0.041288395 0.1111111 7.009165e-10 0.11265013
1068     1 0.10047958 0.1111111 0.039773318 0.1111111 6.736907e-10 0.11363777
1069     1 0.09959346 0.1111111 0.038311615 0.1111111 6.475225e-10 0.11463294
1070     1 0.09871430 0.1111111 0.036901566 0.1111111 6.223707e-10 0.11563569
1071     1 0.09784205 0.1111111 0.035541496 0.1111111 5.981958e-10 0.11664605
1072     1 0.09697668 0.1111111 0.034229771 0.1111111 5.749600e-10 0.11766407
1073     1 0.09611815 0.1111111 0.032964804 0.1111111 5.526268e-10 0.11868978
1074     1 0.09526641 0.1111111 0.031745047 0.1111111 5.311610e-10 0.11972322
1075     1 0.09442144 0.1111111 0.030568997 0.1111111 5.105291e-10 0.12076442
1076     1 0.09358318 0.1111111 0.029435191 0.1111111 4.906985e-10 0.12181343
1077     1 0.09275161 0.1111111 0.028342209 0.1111111 4.716383e-10 0.12287027
1078     1 0.09192668 0.1111111 0.027288670 0.1111111 4.533184e-10 0.12393499
1079     1 0.09110834 0.1111111 0.026273234 0.1111111 4.357101e-10 0.12500762
1080     1 0.09029657 0.1111111 0.025294601 0.1111111 4.187857e-10 0.12608820
1081     1 0.08949131 0.1111111 0.024351508 0.1111111 4.025188e-10 0.12717676
1082     1 0.08869254 0.1111111 0.023442733 0.1111111 3.868837e-10 0.12827334
1083     1 0.08790021 0.1111111 0.022567088 0.1111111 3.718559e-10 0.12937797
1084     1 0.08711428 0.1111111 0.021723422 0.1111111 3.574119e-10 0.13049070
1085     1 0.08633471 0.1111111 0.020910623 0.1111111 3.435289e-10 0.13161154
1086     1 0.08556147 0.1111111 0.020127609 0.1111111 3.301851e-10 0.13274054
1087     1 0.08479450 0.1111111 0.019373335 0.1111111 3.173597e-10 0.13387774
1088     1 0.08403378 0.1111111 0.018646790 0.1111111 3.050325e-10 0.13502316
1089     1 0.08327927 0.1111111 0.017946993 0.1111111 2.931841e-10 0.13617684
1090     1 0.08253092 0.1111111 0.017272996 0.1111111 2.817959e-10 0.13733881
1091     1 0.08178869 0.1111111 0.016623883 0.1111111 2.708500e-10 0.13850911
1092     1 0.08105255 0.1111111 0.015998767 0.1111111 2.603294e-10 0.13968776
1093     1 0.08032245 0.1111111 0.015396788 0.1111111 2.502174e-10 0.14087480
1094     1 0.07959836 0.1111111 0.014817120 0.1111111 2.404981e-10 0.14207027
1095     1 0.07888024 0.1111111 0.014258958 0.1111111 2.311564e-10 0.14327419
1096     1 0.07816805 0.1111111 0.013721530 0.1111111 2.221776e-10 0.14448659
1097     1 0.07746175 0.1111111 0.013204087 0.1111111 2.135475e-10 0.14570751
1098     1 0.07676130 0.1111111 0.012705905 0.1111111 2.052527e-10 0.14693697
1099     1 0.07606665 0.1111111 0.012226286 0.1111111 1.972800e-10 0.14817500
1100     1 0.07537779 0.1111111 0.011764556 0.1111111 1.896170e-10 0.14942165
1101     1 0.07469465 0.1111111 0.011320064 0.1111111 1.822517e-10 0.15067692
1102     1 0.07401721 0.1111111 0.010892181 0.1111111 1.751725e-10 0.15194085
1103     1 0.07334543 0.1111111 0.010480299 0.1111111 1.683682e-10 0.15321348
1104     1 0.07267927 0.1111111 0.010083834 0.1111111 1.618283e-10 0.15449482
1105     1 0.07201869 0.1111111 0.009702220 0.1111111 1.555424e-10 0.15578491
1106     1 0.07136365 0.1111111 0.009334911 0.1111111 1.495006e-10 0.15708377
1107     1 0.07071411 0.1111111 0.008981382 0.1111111 1.436936e-10 0.15839142
1108     1 0.07007004 0.1111111 0.008641125 0.1111111 1.381120e-10 0.15970790
1109     1 0.06943140 0.1111111 0.008313651 0.1111111 1.327473e-10 0.16103323
1110     1 0.06879814 0.1111111 0.007998486 0.1111111 1.275910e-10 0.16236743
1111     1 0.06817024 0.1111111 0.007695177 0.1111111 1.226350e-10 0.16371053
1112     1 0.16371053 0.1111111 0.255408827 0.1111111 9.948305e-10 0.06817024
1113     1 0.16236743 0.1111111 0.248069665 0.1111111 9.561881e-10 0.06879814
1114     1 0.16103323 0.1111111 0.240873170 0.1111111 9.190468e-10 0.06943140
1115     1 0.15970790 0.1111111 0.233820526 0.1111111 8.833481e-10 0.07007004
1116     1 0.15839142 0.1111111 0.226912656 0.1111111 8.490361e-10 0.07071411
1117     1 0.15708377 0.1111111 0.220150227 0.1111111 8.160569e-10 0.07136365
1118     1 0.15578491 0.1111111 0.213533667 0.1111111 7.843587e-10 0.07201869
1119     1 0.15449482 0.1111111 0.207063165 0.1111111 7.538918e-10 0.07267927
1120     1 0.15321348 0.1111111 0.200738688 0.1111111 7.246083e-10 0.07334543
1121     1 0.15194085 0.1111111 0.194559985 0.1111111 6.964622e-10 0.07401721
1122     1 0.15067692 0.1111111 0.188526604 0.1111111 6.694094e-10 0.07469465
1123     1 0.14942165 0.1111111 0.182637894 0.1111111 6.434075e-10 0.07537779
1124     1 0.14817500 0.1111111 0.176893024 0.1111111 6.184155e-10 0.07606665
1125     1 0.14693697 0.1111111 0.171290990 0.1111111 5.943943e-10 0.07676130
1126     1 0.14570751 0.1111111 0.165830624 0.1111111 5.713062e-10 0.07746175
1127     1 0.14448659 0.1111111 0.160510608 0.1111111 5.491149e-10 0.07816805
1128     1 0.14327419 0.1111111 0.155329482 0.1111111 5.277855e-10 0.07888024
1129     1 0.14207027 0.1111111 0.150285659 0.1111111 5.072847e-10 0.07959836
1130     1 0.14087480 0.1111111 0.145377429 0.1111111 4.875802e-10 0.08032245
1131     1 0.13968776 0.1111111 0.140602974 0.1111111 4.686410e-10 0.08105255
1132     1 0.13850911 0.1111111 0.135960375 0.1111111 4.504375e-10 0.08178869
1133     1 0.13733881 0.1111111 0.131447624 0.1111111 4.329411e-10 0.08253092
1134     1 0.13617684 0.1111111 0.127062632 0.1111111 4.161244e-10 0.08327927
1135     1 0.13502316 0.1111111 0.122803237 0.1111111 3.999608e-10 0.08403378
1136     1 0.13387774 0.1111111 0.118667216 0.1111111 3.844251e-10 0.08479450
1137     1 0.13274054 0.1111111 0.114652290 0.1111111 3.694928e-10 0.08556147
1138     1 0.13161154 0.1111111 0.110756131 0.1111111 3.551405e-10 0.08633471
1139     1 0.13049070 0.1111111 0.106976375 0.1111111 3.413458e-10 0.08711428
1140     1 0.12937797 0.1111111 0.103310625 0.1111111 3.280868e-10 0.08790021
1141     1 0.12827334 0.1111111 0.099756456 0.1111111 3.153429e-10 0.08869254
1142     1 0.12717676 0.1111111 0.096311428 0.1111111 3.030940e-10 0.08949131
1143     1 0.12608820 0.1111111 0.092973085 0.1111111 2.913209e-10 0.09029657
1144     1 0.12500762 0.1111111 0.089738964 0.1111111 2.800051e-10 0.09110834
1145     1 0.12393499 0.1111111 0.086606602 0.1111111 2.691288e-10 0.09192668
1146     1 0.12287027 0.1111111 0.083573538 0.1111111 2.586750e-10 0.09275161
1147     1 0.12181343 0.1111111 0.080637317 0.1111111 2.486272e-10 0.09358318
1148     1 0.12076442 0.1111111 0.077795499 0.1111111 2.389698e-10 0.09442144
1149     1 0.11972322 0.1111111 0.075045657 0.1111111 2.296874e-10 0.09526641
1150     1 0.11868978 0.1111111 0.072385384 0.1111111 2.207657e-10 0.09611815
1151     1 0.11766407 0.1111111 0.069812297 0.1111111 2.121904e-10 0.09697668
1152     1 0.11664605 0.1111111 0.067324037 0.1111111 2.039483e-10 0.09784205
1153     1 0.11563569 0.1111111 0.064918275 0.1111111 1.960263e-10 0.09871430
1154     1 0.11463294 0.1111111 0.062592711 0.1111111 1.884120e-10 0.09959346
1155     1 0.11363777 0.1111111 0.060345079 0.1111111 1.810935e-10 0.10047958
1156     1 0.11265013 0.1111111 0.058173149 0.1111111 1.740593e-10 0.10137270
1157     1 0.11167000 0.1111111 0.056074725 0.1111111 1.672983e-10 0.10227286
1158     1 0.11069734 0.1111111 0.054047652 0.1111111 1.607999e-10 0.10318009
1159     1 0.10973210 0.1111111 0.052089813 0.1111111 1.545539e-10 0.10409443
1160     1 0.10877425 0.1111111 0.050199131 0.1111111 1.485506e-10 0.10501593
1161     1 0.10782374 0.1111111 0.048373573 0.1111111 1.427804e-10 0.10594462
1162     1 0.10688055 0.1111111 0.046611146 0.1111111 1.372344e-10 0.10688055
1163     1 0.10594462 0.1111111 0.044909900 0.1111111 1.319037e-10 0.10782374
1164     1 0.10501593 0.1111111 0.043267929 0.1111111 1.267802e-10 0.10877425
1165     1 0.10409443 0.1111111 0.041683371 0.1111111 1.218556e-10 0.10973210
1166     1 0.10318009 0.1111111 0.040154407 0.1111111 1.171224e-10 0.11069734
1167     1 0.10227286 0.1111111 0.038679263 0.1111111 1.125730e-10 0.11167000
1168     1 0.10137270 0.1111111 0.037256207 0.1111111 1.082003e-10 0.11265013
1169     1 0.10047958 0.1111111 0.035883553 0.1111111 1.039975e-10 0.11363777
1170     1 0.09959346 0.1111111 0.034559657 0.1111111 9.995788e-11 0.11463294
1171     1 0.09871430 0.1111111 0.033282919 0.1111111 9.607520e-11 0.11563569
1172     1 0.09784205 0.1111111 0.032051781 0.1111111 9.234334e-11 0.11664605
1173     1 0.09697668 0.1111111 0.030864730 0.1111111 8.875644e-11 0.11766407
1174     1 0.09611815 0.1111111 0.029720291 0.1111111 8.530886e-11 0.11868978
1175     1 0.09526641 0.1111111 0.028617035 0.1111111 8.199520e-11 0.11972322
1176     1 0.09442144 0.1111111 0.027553569 0.1111111 7.881025e-11 0.12076442
1177     1 0.09358318 0.1111111 0.026528545 0.1111111 7.574901e-11 0.12181343
1178     1 0.09275161 0.1111111 0.025540652 0.1111111 7.280668e-11 0.12287027
1179     1 0.09192668 0.1111111 0.024588617 0.1111111 6.997864e-11 0.12393499
1180     1 0.09110834 0.1111111 0.023671207 0.1111111 6.726045e-11 0.12500762
1181     1 0.09029657 0.1111111 0.022787227 0.1111111 6.464785e-11 0.12608820
1182     1 0.08949131 0.1111111 0.021935517 0.1111111 6.213672e-11 0.12717676
1183     1 0.08869254 0.1111111 0.021114953 0.1111111 5.972314e-11 0.12827334
1184     1 0.08790021 0.1111111 0.020324446 0.1111111 5.740330e-11 0.12937797
1185     1 0.08711428 0.1111111 0.019562943 0.1111111 5.517358e-11 0.13049070
1186     1 0.08633471 0.1111111 0.018829424 0.1111111 5.303047e-11 0.13161154
1187     1 0.08556147 0.1111111 0.018122899 0.1111111 5.097060e-11 0.13274054
1188     1 0.08479450 0.1111111 0.017442414 0.1111111 4.899074e-11 0.13387774
1189     1 0.08403378 0.1111111 0.016787043 0.1111111 4.708779e-11 0.13502316
1190     1 0.08327927 0.1111111 0.016155892 0.1111111 4.525875e-11 0.13617684
1191     1 0.08253092 0.1111111 0.015548095 0.1111111 4.350076e-11 0.13733881
1192     1 0.08178869 0.1111111 0.014962816 0.1111111 4.181105e-11 0.13850911
1193     1 0.08105255 0.1111111 0.014399247 0.1111111 4.018698e-11 0.13968776
1194     1 0.08032245 0.1111111 0.013856606 0.1111111 3.862599e-11 0.14087480
1195     1 0.07959836 0.1111111 0.013334137 0.1111111 3.712564e-11 0.14207027
1196     1 0.07888024 0.1111111 0.012831113 0.1111111 3.568356e-11 0.14327419
1197     1 0.07816805 0.1111111 0.012346827 0.1111111 3.429750e-11 0.14448659
1198     1 0.07746175 0.1111111 0.011880599 0.1111111 3.296528e-11 0.14570751
1199     1 0.07676130 0.1111111 0.011431773 0.1111111 3.168480e-11 0.14693697
1200     1 0.07606665 0.1111111 0.010999714 0.1111111 3.045407e-11 0.14817500
1201     1 0.07537779 0.1111111 0.010583810 0.1111111 2.927114e-11 0.14942165
1202     1 0.07469465 0.1111111 0.010183469 0.1111111 2.813415e-11 0.15067692
1203     1 0.07401721 0.1111111 0.009798122 0.1111111 2.704133e-11 0.15194085
1204     1 0.07334543 0.1111111 0.009427217 0.1111111 2.599096e-11 0.15321348
1205     1 0.07267927 0.1111111 0.009070224 0.1111111 2.498139e-11 0.15449482
1206     1 0.07201869 0.1111111 0.008726631 0.1111111 2.401104e-11 0.15578491
1207     1 0.07136365 0.1111111 0.008395944 0.1111111 2.307837e-11 0.15708377
1208     1 0.07071411 0.1111111 0.008077685 0.1111111 2.218194e-11 0.15839142
1209     1 0.07007004 0.1111111 0.007771396 0.1111111 2.132032e-11 0.15970790
1210     1 0.06943140 0.1111111 0.007476633 0.1111111 2.049217e-11 0.16103323
1211     1 0.06879814 0.1111111 0.007192969 0.1111111 1.969619e-11 0.16236743
1212     1 0.06817024 0.1111111 0.006919993 0.1111111 1.893113e-11 0.16371053
1213     1 0.16371053 0.1111111 0.235604688 0.1111111 1.535717e-10 0.06817024
1214     1 0.16236743 0.1111111 0.228659838 0.1111111 1.476065e-10 0.06879814
1215     1 0.16103323 0.1111111 0.221860283 0.1111111 1.418730e-10 0.06943140
1216     1 0.15970790 0.1111111 0.215206510 0.1111111 1.363622e-10 0.07007004
1217     1 0.15839142 0.1111111 0.208698769 0.1111111 1.310655e-10 0.07071411
1218     1 0.15708377 0.1111111 0.202337083 0.1111111 1.259745e-10 0.07136365
1219     1 0.15578491 0.1111111 0.196121254 0.1111111 1.210813e-10 0.07201869
1220     1 0.15449482 0.1111111 0.190050881 0.1111111 1.163781e-10 0.07267927
1221     1 0.15321348 0.1111111 0.184125363 0.1111111 1.118576e-10 0.07334543
1222     1 0.15194085 0.1111111 0.178343914 0.1111111 1.075127e-10 0.07401721
1223     1 0.15067692 0.1111111 0.172705572 0.1111111 1.033366e-10 0.07469465
1224     1 0.14942165 0.1111111 0.167209211 0.1111111 9.932265e-11 0.07537779
1225     1 0.14817500 0.1111111 0.161853549 0.1111111 9.546465e-11 0.07606665
1226     1 0.14693697 0.1111111 0.156637164 0.1111111 9.175650e-11 0.07676130
1227     1 0.14570751 0.1111111 0.151558497 0.1111111 8.819239e-11 0.07746175
1228     1 0.14448659 0.1111111 0.146615870 0.1111111 8.476673e-11 0.07816805
1229     1 0.14327419 0.1111111 0.141807491 0.1111111 8.147412e-11 0.07888024
1230     1 0.14207027 0.1111111 0.137131466 0.1111111 7.830941e-11 0.07959836
1231     1 0.14087480 0.1111111 0.132585809 0.1111111 7.526763e-11 0.08032245
1232     1 0.13968776 0.1111111 0.128168451 0.1111111 7.234400e-11 0.08105255
1233     1 0.13850911 0.1111111 0.123877247 0.1111111 6.953393e-11 0.08178869
1234     1 0.13733881 0.1111111 0.119709990 0.1111111 6.683302e-11 0.08253092
1235     1 0.13617684 0.1111111 0.115664413 0.1111111 6.423701e-11 0.08327927
1236     1 0.13502316 0.1111111 0.111738201 0.1111111 6.174185e-11 0.08403378
1237     1 0.13387774 0.1111111 0.107928998 0.1111111 5.934360e-11 0.08479450
1238     1 0.13274054 0.1111111 0.104234414 0.1111111 5.703851e-11 0.08556147
1239     1 0.13161154 0.1111111 0.100652032 0.1111111 5.482295e-11 0.08633471
1240     1 0.13049070 0.1111111 0.097179414 0.1111111 5.269346e-11 0.08711428
1241     1 0.12937797 0.1111111 0.093814108 0.1111111 5.064668e-11 0.08790021
1242     1 0.12827334 0.1111111 0.090553653 0.1111111 4.867940e-11 0.08869254
1243     1 0.12717676 0.1111111 0.087395584 0.1111111 4.678854e-11 0.08949131
1244     1 0.12608820 0.1111111 0.084337440 0.1111111 4.497113e-11 0.09029657
1245     1 0.12500762 0.1111111 0.081376764 0.1111111 4.322431e-11 0.09110834
1246     1 0.12393499 0.1111111 0.078511112 0.1111111 4.154534e-11 0.09192668
1247     1 0.12287027 0.1111111 0.075738052 0.1111111 3.993159e-11 0.09275161
1248     1 0.12181343 0.1111111 0.073055174 0.1111111 3.838053e-11 0.09358318
1249     1 0.12076442 0.1111111 0.070460086 0.1111111 3.688971e-11 0.09442144
1250     1 0.11972322 0.1111111 0.067950424 0.1111111 3.545679e-11 0.09526641
1251     1 0.11868978 0.1111111 0.065523851 0.1111111 3.407954e-11 0.09611815
1252     1 0.11766407 0.1111111 0.063178059 0.1111111 3.275579e-11 0.09697668
1253     1 0.11664605 0.1111111 0.060910774 0.1111111 3.148345e-11 0.09784205
1254     1 0.11563569 0.1111111 0.058719756 0.1111111 3.026053e-11 0.09871430
1255     1 0.11463294 0.1111111 0.056602800 0.1111111 2.908512e-11 0.09959346
1256     1 0.11363777 0.1111111 0.054557740 0.1111111 2.795536e-11 0.10047958
1257     1 0.11265013 0.1111111 0.052582451 0.1111111 2.686949e-11 0.10137270
1258     1 0.11167000 0.1111111 0.050674844 0.1111111 2.582579e-11 0.10227286
1259     1 0.11069734 0.1111111 0.048832875 0.1111111 2.482264e-11 0.10318009
1260     1 0.10973210 0.1111111 0.047054541 0.1111111 2.385845e-11 0.10409443
1261     1 0.10877425 0.1111111 0.045337881 0.1111111 2.293171e-11 0.10501593
1262     1 0.10782374 0.1111111 0.043680979 0.1111111 2.204097e-11 0.10594462
1263     1 0.10688055 0.1111111 0.042081959 0.1111111 2.118483e-11 0.10688055
1264     1 0.10594462 0.1111111 0.040538994 0.1111111 2.036195e-11 0.10782374
1265     1 0.10501593 0.1111111 0.039050295 0.1111111 1.957103e-11 0.10877425
1266     1 0.10409443 0.1111111 0.037614123 0.1111111 1.881083e-11 0.10973210
1267     1 0.10318009 0.1111111 0.036228778 0.1111111 1.808015e-11 0.11069734
1268     1 0.10227286 0.1111111 0.034892606 0.1111111 1.737786e-11 0.11167000
1269     1 0.10137270 0.1111111 0.033603996 0.1111111 1.670285e-11 0.11265013
1270     1 0.10047958 0.1111111 0.032361380 0.1111111 1.605406e-11 0.11363777
1271     1 0.09959346 0.1111111 0.031163231 0.1111111 1.543047e-11 0.11463294
1272     1 0.09871430 0.1111111 0.030008067 0.1111111 1.483111e-11 0.11563569
1273     1 0.09784205 0.1111111 0.028894446 0.1111111 1.425502e-11 0.11664605
1274     1 0.09697668 0.1111111 0.027820967 0.1111111 1.370131e-11 0.11766407
1275     1 0.09611815 0.1111111 0.026786269 0.1111111 1.316911e-11 0.11868978
1276     1 0.09526641 0.1111111 0.025789033 0.1111111 1.265758e-11 0.11972322
1277     1 0.09442144 0.1111111 0.024827975 0.1111111 1.216592e-11 0.12076442
1278     1 0.09358318 0.1111111 0.023901854 0.1111111 1.169336e-11 0.12181343
1279     1 0.09275161 0.1111111 0.023009464 0.1111111 1.123915e-11 0.12287027
1280     1 0.09192668 0.1111111 0.022149635 0.1111111 1.080259e-11 0.12393499
1281     1 0.09110834 0.1111111 0.021321236 0.1111111 1.038298e-11 0.12500762
1282     1 0.09029657 0.1111111 0.020523168 0.1111111 9.979672e-12 0.12608820
1283     1 0.08949131 0.1111111 0.019754370 0.1111111 9.592030e-12 0.12717676
1284     1 0.08869254 0.1111111 0.019013812 0.1111111 9.219446e-12 0.12827334
1285     1 0.08790021 0.1111111 0.018300498 0.1111111 8.861334e-12 0.12937797
1286     1 0.08711428 0.1111111 0.017613464 0.1111111 8.517132e-12 0.13049070
1287     1 0.08633471 0.1111111 0.016951777 0.1111111 8.186300e-12 0.13161154
1288     1 0.08556147 0.1111111 0.016314535 0.1111111 7.868318e-12 0.13274054
1289     1 0.08479450 0.1111111 0.015700865 0.1111111 7.562688e-12 0.13387774
1290     1 0.08403378 0.1111111 0.015109924 0.1111111 7.268930e-12 0.13502316
1291     1 0.08327927 0.1111111 0.014540895 0.1111111 6.986582e-12 0.13617684
1292     1 0.08253092 0.1111111 0.013992992 0.1111111 6.715201e-12 0.13733881
1293     1 0.08178869 0.1111111 0.013465451 0.1111111 6.454362e-12 0.13850911
1294     1 0.08105255 0.1111111 0.012957538 0.1111111 6.203654e-12 0.13968776
1295     1 0.08032245 0.1111111 0.012468540 0.1111111 5.962685e-12 0.14087480
1296     1 0.07959836 0.1111111 0.011997773 0.1111111 5.731075e-12 0.14207027
1297     1 0.07888024 0.1111111 0.011544572 0.1111111 5.508463e-12 0.14327419
1298     1 0.07816805 0.1111111 0.011108298 0.1111111 5.294497e-12 0.14448659
1299     1 0.07746175 0.1111111 0.010688332 0.1111111 5.088842e-12 0.14570751
1300     1 0.07676130 0.1111111 0.010284079 0.1111111 4.891175e-12 0.14693697
1301     1 0.07606665 0.1111111 0.009894962 0.1111111 4.701187e-12 0.14817500
1302     1 0.07537779 0.1111111 0.009520427 0.1111111 4.518578e-12 0.14942165
1303     1 0.07469465 0.1111111 0.009159937 0.1111111 4.343062e-12 0.15067692
1304     1 0.07401721 0.1111111 0.008812976 0.1111111 4.174364e-12 0.15194085
1305     1 0.07334543 0.1111111 0.008479044 0.1111111 4.012219e-12 0.15321348
1306     1 0.07267927 0.1111111 0.008157662 0.1111111 3.856372e-12 0.15449482
1307     1 0.07201869 0.1111111 0.007848364 0.1111111 3.706578e-12 0.15578491
1308     1 0.07136365 0.1111111 0.007550704 0.1111111 3.562603e-12 0.15708377
1309     1 0.07071411 0.1111111 0.007264251 0.1111111 3.424220e-12 0.15839142
1310     1 0.07007004 0.1111111 0.006988588 0.1111111 3.291213e-12 0.15970790
1311     1 0.06943140 0.1111111 0.006723315 0.1111111 3.163372e-12 0.16103323
1312     1 0.06879814 0.1111111 0.006468046 0.1111111 3.040497e-12 0.16236743
1313     1 0.06817024 0.1111111 0.006222408 0.1111111 2.922394e-12 0.16371053
1314     1 0.16371053 0.1111111 0.216888845 0.1111111 2.370683e-11 0.06817024
1315     1 0.16236743 0.1111111 0.210343866 0.1111111 2.278598e-11 0.06879814
1316     1 0.16103323 0.1111111 0.203944957 0.1111111 2.190090e-11 0.06943140
1317     1 0.15970790 0.1111111 0.197691976 0.1111111 2.105020e-11 0.07007004
1318     1 0.15839142 0.1111111 0.191584572 0.1111111 2.023255e-11 0.07071411
1319     1 0.15708377 0.1111111 0.185622195 0.1111111 1.944665e-11 0.07136365
1320     1 0.15578491 0.1111111 0.179804104 0.1111111 1.869128e-11 0.07201869
1321     1 0.15449482 0.1111111 0.174129381 0.1111111 1.796526e-11 0.07267927
1322     1 0.15321348 0.1111111 0.168596942 0.1111111 1.726743e-11 0.07334543
1323     1 0.15194085 0.1111111 0.163205543 0.1111111 1.659671e-11 0.07401721
1324     1 0.15067692 0.1111111 0.157953795 0.1111111 1.595204e-11 0.07469465
1325     1 0.14942165 0.1111111 0.152840176 0.1111111 1.533241e-11 0.07537779
1326     1 0.14817500 0.1111111 0.147863035 0.1111111 1.473685e-11 0.07606665
1327     1 0.14693697 0.1111111 0.143020609 0.1111111 1.416443e-11 0.07676130
1328     1 0.14570751 0.1111111 0.138311029 0.1111111 1.361424e-11 0.07746175
1329     1 0.14448659 0.1111111 0.133732332 0.1111111 1.308542e-11 0.07816805
1330     1 0.14327419 0.1111111 0.129282468 0.1111111 1.257714e-11 0.07888024
1331     1 0.14207027 0.1111111 0.124959312 0.1111111 1.208860e-11 0.07959836
1332     1 0.14087480 0.1111111 0.120760671 0.1111111 1.161905e-11 0.08032245
1333     1 0.13968776 0.1111111 0.116684293 0.1111111 1.116773e-11 0.08105255
1334     1 0.13850911 0.1111111 0.112727874 0.1111111 1.073394e-11 0.08178869
1335     1 0.13733881 0.1111111 0.108889069 0.1111111 1.031700e-11 0.08253092
1336     1 0.13617684 0.1111111 0.105165495 0.1111111 9.916252e-12 0.08327927
1337     1 0.13502316 0.1111111 0.101554741 0.1111111 9.531073e-12 0.08403378
1338     1 0.13387774 0.1111111 0.098054374 0.1111111 9.160857e-12 0.08479450
1339     1 0.13274054 0.1111111 0.094661945 0.1111111 8.805020e-12 0.08556147
1340     1 0.13161154 0.1111111 0.091374995 0.1111111 8.463006e-12 0.08633471
1341     1 0.13049070 0.1111111 0.088191060 0.1111111 8.134276e-12 0.08711428
1342     1 0.12937797 0.1111111 0.085107676 0.1111111 7.818315e-12 0.08790021
1343     1 0.12827334 0.1111111 0.082122386 0.1111111 7.514628e-12 0.08869254
1344     1 0.12717676 0.1111111 0.079232742 0.1111111 7.222736e-12 0.08949131
1345     1 0.12608820 0.1111111 0.076436308 0.1111111 6.942182e-12 0.09029657
1346     1 0.12500762 0.1111111 0.073730668 0.1111111 6.672526e-12 0.09110834
1347     1 0.12393499 0.1111111 0.071113426 0.1111111 6.413344e-12 0.09192668
1348     1 0.12287027 0.1111111 0.068582211 0.1111111 6.164230e-12 0.09275161
1349     1 0.12181343 0.1111111 0.066134677 0.1111111 5.924792e-12 0.09358318
1350     1 0.12076442 0.1111111 0.063768509 0.1111111 5.694655e-12 0.09442144
1351     1 0.11972322 0.1111111 0.061481425 0.1111111 5.473456e-12 0.09526641
1352     1 0.11868978 0.1111111 0.059271175 0.1111111 5.260850e-12 0.09611815
1353     1 0.11766407 0.1111111 0.057135546 0.1111111 5.056502e-12 0.09697668
1354     1 0.11664605 0.1111111 0.055072362 0.1111111 4.860092e-12 0.09784205
1355     1 0.11563569 0.1111111 0.053079487 0.1111111 4.671311e-12 0.09871430
1356     1 0.11463294 0.1111111 0.051154822 0.1111111 4.489863e-12 0.09959346
1357     1 0.11363777 0.1111111 0.049296313 0.1111111 4.315462e-12 0.10047958
1358     1 0.11265013 0.1111111 0.047501944 0.1111111 4.147836e-12 0.10137270
1359     1 0.11167000 0.1111111 0.045769746 0.1111111 3.986721e-12 0.10227286
1360     1 0.11069734 0.1111111 0.044097790 0.1111111 3.831864e-12 0.10318009
1361     1 0.10973210 0.1111111 0.042484190 0.1111111 3.683023e-12 0.10409443
1362     1 0.10877425 0.1111111 0.040927106 0.1111111 3.539963e-12 0.10501593
1363     1 0.10782374 0.1111111 0.039424742 0.1111111 3.402460e-12 0.10594462
1364     1 0.10688055 0.1111111 0.037975342 0.1111111 3.270297e-12 0.10688055
1365     1 0.10594462 0.1111111 0.036577199 0.1111111 3.143269e-12 0.10782374
1366     1 0.10501593 0.1111111 0.035228647 0.1111111 3.021174e-12 0.10877425
1367     1 0.10409443 0.1111111 0.033928063 0.1111111 2.903823e-12 0.10973210
1368     1 0.10318009 0.1111111 0.032673868 0.1111111 2.791029e-12 0.11069734
1369     1 0.10227286 0.1111111 0.031464526 0.1111111 2.682617e-12 0.11167000
1370     1 0.10137270 0.1111111 0.030298543 0.1111111 2.578415e-12 0.11265013
1371     1 0.10047958 0.1111111 0.029174466 0.1111111 2.478262e-12 0.11363777
1372     1 0.09959346 0.1111111 0.028090885 0.1111111 2.381998e-12 0.11463294
1373     1 0.09871430 0.1111111 0.027046428 0.1111111 2.289474e-12 0.11563569
1374     1 0.09784205 0.1111111 0.026039765 0.1111111 2.200544e-12 0.11664605
1375     1 0.09697668 0.1111111 0.025069604 0.1111111 2.115068e-12 0.11766407
1376     1 0.09611815 0.1111111 0.024134693 0.1111111 2.032912e-12 0.11868978
1377     1 0.09526641 0.1111111 0.023233816 0.1111111 1.953947e-12 0.11972322
1378     1 0.09442144 0.1111111 0.022365796 0.1111111 1.878050e-12 0.12076442
1379     1 0.09358318 0.1111111 0.021529490 0.1111111 1.805100e-12 0.12181343
1380     1 0.09275161 0.1111111 0.020723792 0.1111111 1.734985e-12 0.12287027
1381     1 0.09192668 0.1111111 0.019947632 0.1111111 1.667592e-12 0.12393499
1382     1 0.09110834 0.1111111 0.019199971 0.1111111 1.602818e-12 0.12500762
1383     1 0.09029657 0.1111111 0.018479805 0.1111111 1.540559e-12 0.12608820
1384     1 0.08949131 0.1111111 0.017786161 0.1111111 1.480719e-12 0.12717676
1385     1 0.08869254 0.1111111 0.017118099 0.1111111 1.423204e-12 0.12827334
1386     1 0.08790021 0.1111111 0.016474710 0.1111111 1.367922e-12 0.12937797
1387     1 0.08711428 0.1111111 0.015855112 0.1111111 1.314788e-12 0.13049070
1388     1 0.08633471 0.1111111 0.015258455 0.1111111 1.263717e-12 0.13161154
1389     1 0.08556147 0.1111111 0.014683917 0.1111111 1.214630e-12 0.13274054
1390     1 0.08479450 0.1111111 0.014130701 0.1111111 1.167450e-12 0.13387774
1391     1 0.08403378 0.1111111 0.013598040 0.1111111 1.122103e-12 0.13502316
1392     1 0.08327927 0.1111111 0.013085192 0.1111111 1.078517e-12 0.13617684
1393     1 0.08253092 0.1111111 0.012591439 0.1111111 1.036624e-12 0.13733881
1394     1 0.08178869 0.1111111 0.012116088 0.1111111 9.963582e-13 0.13850911
1395     1 0.08105255 0.1111111 0.011658471 0.1111111 9.576565e-13 0.13968776
1396     1 0.08032245 0.1111111 0.011217941 0.1111111 9.204582e-13 0.14087480
1397     1 0.07959836 0.1111111 0.010793875 0.1111111 8.847047e-13 0.14207027
1398     1 0.07888024 0.1111111 0.010385672 0.1111111 8.503400e-13 0.14327419
1399     1 0.07816805 0.1111111 0.009992751 0.1111111 8.173101e-13 0.14448659
1400     1 0.07746175 0.1111111 0.009614550 0.1111111 7.855632e-13 0.14570751
1401     1 0.07676130 0.1111111 0.009250529 0.1111111 7.550495e-13 0.14693697
1402     1 0.07606665 0.1111111 0.008900167 0.1111111 7.257210e-13 0.14817500
1403     1 0.07537779 0.1111111 0.008562961 0.1111111 6.975317e-13 0.14942165
1404     1 0.07469465 0.1111111 0.008238424 0.1111111 6.704374e-13 0.15067692
1405     1 0.07401721 0.1111111 0.007926088 0.1111111 6.443955e-13 0.15194085
1406     1 0.07334543 0.1111111 0.007625503 0.1111111 6.193652e-13 0.15321348
1407     1 0.07267927 0.1111111 0.007336233 0.1111111 5.953071e-13 0.15449482
1408     1 0.07201869 0.1111111 0.007057858 0.1111111 5.721835e-13 0.15578491
1409     1 0.07136365 0.1111111 0.006789974 0.1111111 5.499581e-13 0.15708377
1410     1 0.07071411 0.1111111 0.006532191 0.1111111 5.285960e-13 0.15839142
1411     1 0.07007004 0.1111111 0.006284132 0.1111111 5.080637e-13 0.15970790
1412     1 0.06943140 0.1111111 0.006045436 0.1111111 4.883289e-13 0.16103323
1413     1 0.06879814 0.1111111 0.005815754 0.1111111 4.693607e-13 0.16236743
1414     1 0.06817024 0.1111111 0.005594749 0.1111111 4.511293e-13 0.16371053
1415     1 0.16371053 0.1111111 0.199272159 0.1111111 3.659617e-12 0.06817024
1416     1 0.16236743 0.1111111 0.193127689 0.1111111 3.517466e-12 0.06879814
1417     1 0.16103323 0.1111111 0.187128404 0.1111111 3.380837e-12 0.06943140
1418     1 0.15970790 0.1111111 0.181273612 0.1111111 3.249515e-12 0.07007004
1419     1 0.15839142 0.1111111 0.175562438 0.1111111 3.123293e-12 0.07071411
1420     1 0.15708377 0.1111111 0.169993839 0.1111111 3.001975e-12 0.07136365
1421     1 0.15578491 0.1111111 0.164566612 0.1111111 2.885369e-12 0.07201869
1422     1 0.15449482 0.1111111 0.159279404 0.1111111 2.773292e-12 0.07267927
1423     1 0.15321348 0.1111111 0.154130724 0.1111111 2.665569e-12 0.07334543
1424     1 0.15194085 0.1111111 0.149118955 0.1111111 2.562030e-12 0.07401721
1425     1 0.15067692 0.1111111 0.144242360 0.1111111 2.462512e-12 0.07469465
1426     1 0.14942165 0.1111111 0.139499098 0.1111111 2.366861e-12 0.07537779
1427     1 0.14817500 0.1111111 0.134887227 0.1111111 2.274925e-12 0.07606665
1428     1 0.14693697 0.1111111 0.130404720 0.1111111 2.186559e-12 0.07676130
1429     1 0.14570751 0.1111111 0.126049469 0.1111111 2.101627e-12 0.07746175
1430     1 0.14448659 0.1111111 0.121819298 0.1111111 2.019993e-12 0.07816805
1431     1 0.14327419 0.1111111 0.117711969 0.1111111 1.941530e-12 0.07888024
1432     1 0.14207027 0.1111111 0.113725191 0.1111111 1.866115e-12 0.07959836
1433     1 0.14087480 0.1111111 0.109856629 0.1111111 1.793629e-12 0.08032245
1434     1 0.13968776 0.1111111 0.106103907 0.1111111 1.723959e-12 0.08105255
1435     1 0.13850911 0.1111111 0.102464623 0.1111111 1.656995e-12 0.08178869
1436     1 0.13733881 0.1111111 0.098936348 0.1111111 1.592632e-12 0.08253092
1437     1 0.13617684 0.1111111 0.095516637 0.1111111 1.530769e-12 0.08327927
1438     1 0.13502316 0.1111111 0.092203032 0.1111111 1.471309e-12 0.08403378
1439     1 0.13387774 0.1111111 0.088993070 0.1111111 1.414159e-12 0.08479450
1440     1 0.13274054 0.1111111 0.085884287 0.1111111 1.359229e-12 0.08556147
1441     1 0.13161154 0.1111111 0.082874224 0.1111111 1.306432e-12 0.08633471
1442     1 0.13049070 0.1111111 0.079960429 0.1111111 1.255686e-12 0.08711428
1443     1 0.12937797 0.1111111 0.077140464 0.1111111 1.206911e-12 0.08790021
1444     1 0.12827334 0.1111111 0.074411907 0.1111111 1.160031e-12 0.08869254
1445     1 0.12717676 0.1111111 0.071772357 0.1111111 1.114972e-12 0.08949131
1446     1 0.12608820 0.1111111 0.069219435 0.1111111 1.071663e-12 0.09029657
1447     1 0.12500762 0.1111111 0.066750790 0.1111111 1.030036e-12 0.09110834
1448     1 0.12393499 0.1111111 0.064364098 0.1111111 9.900264e-13 0.09192668
1449     1 0.12287027 0.1111111 0.062057069 0.1111111 9.515707e-13 0.09275161
1450     1 0.12181343 0.1111111 0.059827444 0.1111111 9.146087e-13 0.09358318
1451     1 0.12076442 0.1111111 0.057673001 0.1111111 8.790824e-13 0.09442144
1452     1 0.11972322 0.1111111 0.055591553 0.1111111 8.449361e-13 0.09526641
1453     1 0.11868978 0.1111111 0.053580955 0.1111111 8.121161e-13 0.09611815
1454     1 0.11766407 0.1111111 0.051639099 0.1111111 7.805710e-13 0.09697668
1455     1 0.11664605 0.1111111 0.049763918 0.1111111 7.502512e-13 0.09784205
1456     1 0.11563569 0.1111111 0.047953388 0.1111111 7.211091e-13 0.09871430
1457     1 0.11463294 0.1111111 0.046205526 0.1111111 6.930990e-13 0.09959346
1458     1 0.11363777 0.1111111 0.044518393 0.1111111 6.661768e-13 0.10047958
1459     1 0.11265013 0.1111111 0.042890094 0.1111111 6.403004e-13 0.10137270
1460     1 0.11167000 0.1111111 0.041318775 0.1111111 6.154292e-13 0.10227286
1461     1 0.11069734 0.1111111 0.039802629 0.1111111 5.915240e-13 0.10318009
1462     1 0.10973210 0.1111111 0.038339892 0.1111111 5.685473e-13 0.10409443
1463     1 0.10877425 0.1111111 0.036928842 0.1111111 5.464632e-13 0.10501593
1464     1 0.10782374 0.1111111 0.035567804 0.1111111 5.252368e-13 0.10594462
1465     1 0.10688055 0.1111111 0.034255143 0.1111111 5.048350e-13 0.10688055
1466     1 0.10594462 0.1111111 0.032989270 0.1111111 4.852256e-13 0.10782374
1467     1 0.10501593 0.1111111 0.031768638 0.1111111 4.663779e-13 0.10877425
1468     1 0.10409443 0.1111111 0.030591742 0.1111111 4.482624e-13 0.10973210
1469     1 0.10318009 0.1111111 0.029457118 0.1111111 4.308504e-13 0.11069734
1470     1 0.10227286 0.1111111 0.028363345 0.1111111 4.141149e-13 0.11167000
1471     1 0.10137270 0.1111111 0.027309042 0.1111111 3.980294e-13 0.11265013
1472     1 0.10047958 0.1111111 0.026292869 0.1111111 3.825686e-13 0.11363777
1473     1 0.09959346 0.1111111 0.025313523 0.1111111 3.677085e-13 0.11463294
1474     1 0.09871430 0.1111111 0.024369743 0.1111111 3.534255e-13 0.11563569
1475     1 0.09784205 0.1111111 0.023460303 0.1111111 3.396974e-13 0.11664605
1476     1 0.09697668 0.1111111 0.022584017 0.1111111 3.265025e-13 0.11766407
1477     1 0.09611815 0.1111111 0.021739733 0.1111111 3.138201e-13 0.11868978
1478     1 0.09526641 0.1111111 0.020926336 0.1111111 3.016303e-13 0.11972322
1479     1 0.09442144 0.1111111 0.020142746 0.1111111 2.899141e-13 0.12076442
1480     1 0.09358318 0.1111111 0.019387916 0.1111111 2.786529e-13 0.12181343
1481     1 0.09275161 0.1111111 0.018660834 0.1111111 2.678292e-13 0.12287027
1482     1 0.09192668 0.1111111 0.017960520 0.1111111 2.574258e-13 0.12393499
1483     1 0.09110834 0.1111111 0.017286024 0.1111111 2.474266e-13 0.12500762
1484     1 0.09029657 0.1111111 0.016636430 0.1111111 2.378158e-13 0.12608820
1485     1 0.08949131 0.1111111 0.016010849 0.1111111 2.285783e-13 0.12717676
1486     1 0.08869254 0.1111111 0.015408424 0.1111111 2.196996e-13 0.12827334
1487     1 0.08790021 0.1111111 0.014828323 0.1111111 2.111658e-13 0.12937797
1488     1 0.08711428 0.1111111 0.014269746 0.1111111 2.029634e-13 0.13049070
1489     1 0.08633471 0.1111111 0.013731917 0.1111111 1.950797e-13 0.13161154
1490     1 0.08556147 0.1111111 0.013214087 0.1111111 1.875022e-13 0.13274054
1491     1 0.08479450 0.1111111 0.012715533 0.1111111 1.802190e-13 0.13387774
1492     1 0.08403378 0.1111111 0.012235555 0.1111111 1.732187e-13 0.13502316
1493     1 0.08327927 0.1111111 0.011773480 0.1111111 1.664904e-13 0.13617684
1494     1 0.08253092 0.1111111 0.011328654 0.1111111 1.600234e-13 0.13733881
1495     1 0.08178869 0.1111111 0.010900449 0.1111111 1.538076e-13 0.13850911
1496     1 0.08105255 0.1111111 0.010488258 0.1111111 1.478332e-13 0.13968776
1497     1 0.08032245 0.1111111 0.010091495 0.1111111 1.420909e-13 0.14087480
1498     1 0.07959836 0.1111111 0.009709594 0.1111111 1.365716e-13 0.14207027
1499     1 0.07888024 0.1111111 0.009342009 0.1111111 1.312668e-13 0.14327419
1500     1 0.07816805 0.1111111 0.008988214 0.1111111 1.261680e-13 0.14448659
1501     1 0.07746175 0.1111111 0.008647700 0.1111111 1.212672e-13 0.14570751
1502     1 0.07676130 0.1111111 0.008319978 0.1111111 1.165568e-13 0.14693697
1503     1 0.07606665 0.1111111 0.008004576 0.1111111 1.120294e-13 0.14817500
1504     1 0.07537779 0.1111111 0.007701037 0.1111111 1.076778e-13 0.14942165
1505     1 0.07469465 0.1111111 0.007408923 0.1111111 1.034953e-13 0.15067692
1506     1 0.07401721 0.1111111 0.007127810 0.1111111 9.947518e-14 0.15194085
1507     1 0.07334543 0.1111111 0.006857289 0.1111111 9.561125e-14 0.15321348
1508     1 0.07267927 0.1111111 0.006596967 0.1111111 9.189741e-14 0.15449482
1509     1 0.07201869 0.1111111 0.006346464 0.1111111 8.832783e-14 0.15578491
1510     1 0.07136365 0.1111111 0.006105416 0.1111111 8.489690e-14 0.15708377
1511     1 0.07071411 0.1111111 0.005873468 0.1111111 8.159924e-14 0.15839142
1512     1 0.07007004 0.1111111 0.005650282 0.1111111 7.842967e-14 0.15970790
1513     1 0.06943140 0.1111111 0.005435531 0.1111111 7.538322e-14 0.16103323
1514     1 0.06879814 0.1111111 0.005228898 0.1111111 7.245510e-14 0.16236743
1515     1 0.06817024 0.1111111 0.005030082 0.1111111 6.964071e-14 0.16371053
1516     1 0.16371053 0.1111111 0.182752453 0.1111111 5.649342e-13 0.06817024
1517     1 0.16236743 0.1111111 0.177004761 0.1111111 5.429904e-13 0.06879814
1518     1 0.16103323 0.1111111 0.171399925 0.1111111 5.218990e-13 0.06943140
1519     1 0.15970790 0.1111111 0.165936781 0.1111111 5.016268e-13 0.07007004
1520     1 0.15839142 0.1111111 0.160614015 0.1111111 4.821420e-13 0.07071411
1521     1 0.15708377 0.1111111 0.155430170 0.1111111 4.634141e-13 0.07136365
1522     1 0.15578491 0.1111111 0.150383660 0.1111111 4.454137e-13 0.07201869
1523     1 0.15449482 0.1111111 0.145472777 0.1111111 4.281124e-13 0.07267927
1524     1 0.15321348 0.1111111 0.140695706 0.1111111 4.114832e-13 0.07334543
1525     1 0.15194085 0.1111111 0.136050530 0.1111111 3.954999e-13 0.07401721
1526     1 0.15067692 0.1111111 0.131535242 0.1111111 3.801374e-13 0.07469465
1527     1 0.14942165 0.1111111 0.127147755 0.1111111 3.653717e-13 0.07537779
1528     1 0.14817500 0.1111111 0.122885908 0.1111111 3.511795e-13 0.07606665
1529     1 0.14693697 0.1111111 0.118747480 0.1111111 3.375386e-13 0.07676130
1530     1 0.14570751 0.1111111 0.114730191 0.1111111 3.244276e-13 0.07746175
1531     1 0.14448659 0.1111111 0.110831717 0.1111111 3.118258e-13 0.07816805
1532     1 0.14327419 0.1111111 0.107049692 0.1111111 2.997135e-13 0.07888024
1533     1 0.14207027 0.1111111 0.103381720 0.1111111 2.880717e-13 0.07959836
1534     1 0.14087480 0.1111111 0.099825378 0.1111111 2.768821e-13 0.08032245
1535     1 0.13968776 0.1111111 0.096378224 0.1111111 2.661271e-13 0.08105255
1536     1 0.13850911 0.1111111 0.093037804 0.1111111 2.557899e-13 0.08178869
1537     1 0.13733881 0.1111111 0.089801655 0.1111111 2.458542e-13 0.08253092
1538     1 0.13617684 0.1111111 0.086667313 0.1111111 2.363045e-13 0.08327927
1539     1 0.13502316 0.1111111 0.083632317 0.1111111 2.271257e-13 0.08403378
1540     1 0.13387774 0.1111111 0.080694214 0.1111111 2.183034e-13 0.08479450
1541     1 0.13274054 0.1111111 0.077850560 0.1111111 2.098238e-13 0.08556147
1542     1 0.13161154 0.1111111 0.075098930 0.1111111 2.016736e-13 0.08633471
1543     1 0.13049070 0.1111111 0.072436917 0.1111111 1.938400e-13 0.08711428
1544     1 0.12937797 0.1111111 0.069862136 0.1111111 1.863106e-13 0.08790021
1545     1 0.12827334 0.1111111 0.067372228 0.1111111 1.790737e-13 0.08869254
1546     1 0.12717676 0.1111111 0.064964864 0.1111111 1.721179e-13 0.08949131
1547     1 0.12608820 0.1111111 0.062637743 0.1111111 1.654323e-13 0.09029657
1548     1 0.12500762 0.1111111 0.060388598 0.1111111 1.590064e-13 0.09110834
1549     1 0.12393499 0.1111111 0.058215198 0.1111111 1.528301e-13 0.09192668
1550     1 0.12287027 0.1111111 0.056115348 0.1111111 1.468937e-13 0.09275161
1551     1 0.12181343 0.1111111 0.054086891 0.1111111 1.411879e-13 0.09358318
1552     1 0.12076442 0.1111111 0.052127708 0.1111111 1.357037e-13 0.09442144
1553     1 0.11972322 0.1111111 0.050235724 0.1111111 1.304326e-13 0.09526641
1554     1 0.11868978 0.1111111 0.048408903 0.1111111 1.253662e-13 0.09611815
1555     1 0.11766407 0.1111111 0.046645252 0.1111111 1.204966e-13 0.09697668
1556     1 0.11664605 0.1111111 0.044942819 0.1111111 1.158161e-13 0.09784205
1557     1 0.11563569 0.1111111 0.043299700 0.1111111 1.113174e-13 0.09871430
1558     1 0.11463294 0.1111111 0.041714029 0.1111111 1.069935e-13 0.09959346
1559     1 0.11363777 0.1111111 0.040183988 0.1111111 1.028376e-13 0.10047958
1560     1 0.11265013 0.1111111 0.038707800 0.1111111 9.884302e-14 0.10137270
1561     1 0.11167000 0.1111111 0.037283735 0.1111111 9.500365e-14 0.10227286
1562     1 0.11069734 0.1111111 0.035910105 0.1111111 9.131341e-14 0.10318009
1563     1 0.10973210 0.1111111 0.034585264 0.1111111 8.776651e-14 0.10409443
1564     1 0.10877425 0.1111111 0.033307613 0.1111111 8.435738e-14 0.10501593
1565     1 0.10782374 0.1111111 0.032075592 0.1111111 8.108068e-14 0.10594462
1566     1 0.10688055 0.1111111 0.030887687 0.1111111 7.793125e-14 0.10688055
1567     1 0.10594462 0.1111111 0.029742424 0.1111111 7.490416e-14 0.10782374
1568     1 0.10501593 0.1111111 0.028638370 0.1111111 7.199465e-14 0.10877425
1569     1 0.10409443 0.1111111 0.027574134 0.1111111 6.919815e-14 0.10973210
1570     1 0.10318009 0.1111111 0.026548366 0.1111111 6.651028e-14 0.11069734
1571     1 0.10227286 0.1111111 0.025559753 0.1111111 6.392681e-14 0.11167000
1572     1 0.10137270 0.1111111 0.024607025 0.1111111 6.144369e-14 0.11265013
1573     1 0.10047958 0.1111111 0.023688945 0.1111111 5.905703e-14 0.11363777
1574     1 0.09959346 0.1111111 0.022804318 0.1111111 5.676307e-14 0.11463294
1575     1 0.09871430 0.1111111 0.021951983 0.1111111 5.455821e-14 0.11563569
1576     1 0.09784205 0.1111111 0.021130816 0.1111111 5.243900e-14 0.11664605
1577     1 0.09697668 0.1111111 0.020339728 0.1111111 5.040211e-14 0.11766407
1578     1 0.09611815 0.1111111 0.019577664 0.1111111 4.844433e-14 0.11868978
1579     1 0.09526641 0.1111111 0.018843603 0.1111111 4.656260e-14 0.11972322
1580     1 0.09442144 0.1111111 0.018136557 0.1111111 4.475396e-14 0.12076442
1581     1 0.09358318 0.1111111 0.017455568 0.1111111 4.301558e-14 0.12181343
1582     1 0.09275161 0.1111111 0.016799711 0.1111111 4.134472e-14 0.12287027
1583     1 0.09192668 0.1111111 0.016168091 0.1111111 3.973876e-14 0.12393499
1584     1 0.09110834 0.1111111 0.015559843 0.1111111 3.819518e-14 0.12500762
1585     1 0.09029657 0.1111111 0.014974128 0.1111111 3.671156e-14 0.12608820
1586     1 0.08949131 0.1111111 0.014410139 0.1111111 3.528557e-14 0.12717676
1587     1 0.08869254 0.1111111 0.013867093 0.1111111 3.391497e-14 0.12827334
1588     1 0.08790021 0.1111111 0.013344235 0.1111111 3.259761e-14 0.12937797
1589     1 0.08711428 0.1111111 0.012840834 0.1111111 3.133141e-14 0.13049070
1590     1 0.08633471 0.1111111 0.012356186 0.1111111 3.011440e-14 0.13161154
1591     1 0.08556147 0.1111111 0.011889609 0.1111111 2.894467e-14 0.13274054
1592     1 0.08479450 0.1111111 0.011440447 0.1111111 2.782036e-14 0.13387774
1593     1 0.08403378 0.1111111 0.011008064 0.1111111 2.673973e-14 0.13502316
1594     1 0.08327927 0.1111111 0.010591847 0.1111111 2.570108e-14 0.13617684
1595     1 0.08253092 0.1111111 0.010191206 0.1111111 2.470277e-14 0.13733881
1596     1 0.08178869 0.1111111 0.009805568 0.1111111 2.374324e-14 0.13850911
1597     1 0.08105255 0.1111111 0.009434384 0.1111111 2.282097e-14 0.13968776
1598     1 0.08032245 0.1111111 0.009077123 0.1111111 2.193454e-14 0.14087480
1599     1 0.07959836 0.1111111 0.008733271 0.1111111 2.108253e-14 0.14207027
1600     1 0.07888024 0.1111111 0.008402334 0.1111111 2.026362e-14 0.14327419
1601     1 0.07816805 0.1111111 0.008083835 0.1111111 1.947652e-14 0.14448659
1602     1 0.07746175 0.1111111 0.007777314 0.1111111 1.871999e-14 0.14570751
1603     1 0.07676130 0.1111111 0.007482329 0.1111111 1.799284e-14 0.14693697
1604     1 0.07606665 0.1111111 0.007198450 0.1111111 1.729395e-14 0.14817500
1605     1 0.07537779 0.1111111 0.006925267 0.1111111 1.662220e-14 0.14942165
1606     1 0.07469465 0.1111111 0.006662382 0.1111111 1.597654e-14 0.15067692
1607     1 0.07401721 0.1111111 0.006409411 0.1111111 1.535596e-14 0.15194085
1608     1 0.07334543 0.1111111 0.006165986 0.1111111 1.475949e-14 0.15321348
1609     1 0.07267927 0.1111111 0.005931751 0.1111111 1.418618e-14 0.15449482
1610     1 0.07201869 0.1111111 0.005706363 0.1111111 1.363514e-14 0.15578491
1611     1 0.07136365 0.1111111 0.005489492 0.1111111 1.310551e-14 0.15708377
1612     1 0.07071411 0.1111111 0.005280819 0.1111111 1.259645e-14 0.15839142
1613     1 0.07007004 0.1111111 0.005080039 0.1111111 1.210717e-14 0.15970790
1614     1 0.06943140 0.1111111 0.004886854 0.1111111 1.163689e-14 0.16103323
1615     1 0.06879814 0.1111111 0.004700981 0.1111111 1.118487e-14 0.16236743
1616     1 0.06817024 0.1111111 0.004522146 0.1111111 1.075042e-14 0.16371053
1617     1 0.16371053 0.1111111 0.167316074 0.1111111 8.720876e-14 0.06817024
1618     1 0.16236743 0.1111111 0.161957655 0.1111111 8.382130e-14 0.06879814
1619     1 0.16103323 0.1111111 0.156738542 0.1111111 8.056541e-14 0.06943140
1620     1 0.15970790 0.1111111 0.151657179 0.1111111 7.743600e-14 0.07007004
1621     1 0.15839142 0.1111111 0.146711890 0.1111111 7.442814e-14 0.07071411
1622     1 0.15708377 0.1111111 0.141900885 0.1111111 7.153712e-14 0.07136365
1623     1 0.15578491 0.1111111 0.137222273 0.1111111 6.875840e-14 0.07201869
1624     1 0.15449482 0.1111111 0.132674069 0.1111111 6.608761e-14 0.07267927
1625     1 0.15321348 0.1111111 0.128254205 0.1111111 6.352056e-14 0.07334543
1626     1 0.15194085 0.1111111 0.123960539 0.1111111 6.105322e-14 0.07401721
1627     1 0.15067692 0.1111111 0.119790863 0.1111111 5.868172e-14 0.07469465
1628     1 0.14942165 0.1111111 0.115742912 0.1111111 5.640234e-14 0.07537779
1629     1 0.14817500 0.1111111 0.111814372 0.1111111 5.421150e-14 0.07606665
1630     1 0.14693697 0.1111111 0.108002888 0.1111111 5.210575e-14 0.07676130
1631     1 0.14570751 0.1111111 0.104306071 0.1111111 5.008180e-14 0.07746175
1632     1 0.14448659 0.1111111 0.100721503 0.1111111 4.813647e-14 0.07816805
1633     1 0.14327419 0.1111111 0.097246747 0.1111111 4.626670e-14 0.07888024
1634     1 0.14207027 0.1111111 0.093879352 0.1111111 4.446955e-14 0.07959836
1635     1 0.14087480 0.1111111 0.090616856 0.1111111 4.274222e-14 0.08032245
1636     1 0.13968776 0.1111111 0.087456795 0.1111111 4.108198e-14 0.08105255
1637     1 0.13850911 0.1111111 0.084396707 0.1111111 3.948622e-14 0.08178869
1638     1 0.13733881 0.1111111 0.081434136 0.1111111 3.795245e-14 0.08253092
1639     1 0.13617684 0.1111111 0.078566636 0.1111111 3.647826e-14 0.08327927
1640     1 0.13502316 0.1111111 0.075791777 0.1111111 3.506133e-14 0.08403378
1641     1 0.13387774 0.1111111 0.073107145 0.1111111 3.369944e-14 0.08479450
1642     1 0.13274054 0.1111111 0.070510352 0.1111111 3.239045e-14 0.08556147
1643     1 0.13161154 0.1111111 0.067999031 0.1111111 3.113230e-14 0.08633471
1644     1 0.13049070 0.1111111 0.065570844 0.1111111 2.992303e-14 0.08711428
1645     1 0.12937797 0.1111111 0.063223484 0.1111111 2.876072e-14 0.08790021
1646     1 0.12827334 0.1111111 0.060954675 0.1111111 2.764357e-14 0.08869254
1647     1 0.12717676 0.1111111 0.058762176 0.1111111 2.656980e-14 0.08949131
1648     1 0.12608820 0.1111111 0.056643782 0.1111111 2.553775e-14 0.09029657
1649     1 0.12500762 0.1111111 0.054597328 0.1111111 2.454578e-14 0.09110834
1650     1 0.12393499 0.1111111 0.052620685 0.1111111 2.359235e-14 0.09192668
1651     1 0.12287027 0.1111111 0.050711765 0.1111111 2.267595e-14 0.09275161
1652     1 0.12181343 0.1111111 0.048868524 0.1111111 2.179514e-14 0.09358318
1653     1 0.12076442 0.1111111 0.047088956 0.1111111 2.094855e-14 0.09442144
1654     1 0.11972322 0.1111111 0.045371100 0.1111111 2.013484e-14 0.09526641
1655     1 0.11868978 0.1111111 0.043713039 0.1111111 1.935274e-14 0.09611815
1656     1 0.11766407 0.1111111 0.042112898 0.1111111 1.860102e-14 0.09697668
1657     1 0.11664605 0.1111111 0.040568846 0.1111111 1.787850e-14 0.09784205
1658     1 0.11563569 0.1111111 0.039079096 0.1111111 1.718404e-14 0.09871430
1659     1 0.11463294 0.1111111 0.037641906 0.1111111 1.651656e-14 0.09959346
1660     1 0.11363777 0.1111111 0.036255576 0.1111111 1.587501e-14 0.10047958
1661     1 0.11265013 0.1111111 0.034918452 0.1111111 1.525837e-14 0.10137270
1662     1 0.11167000 0.1111111 0.033628920 0.1111111 1.466569e-14 0.10227286
1663     1 0.11069734 0.1111111 0.032385413 0.1111111 1.409603e-14 0.10318009
1664     1 0.10973210 0.1111111 0.031186404 0.1111111 1.354849e-14 0.10409443
1665     1 0.10877425 0.1111111 0.030030407 0.1111111 1.302223e-14 0.10501593
1666     1 0.10782374 0.1111111 0.028915982 0.1111111 1.251640e-14 0.10594462
1667     1 0.10688055 0.1111111 0.027841725 0.1111111 1.203023e-14 0.10688055
1668     1 0.10594462 0.1111111 0.026806277 0.1111111 1.156294e-14 0.10782374
1669     1 0.10501593 0.1111111 0.025808315 0.1111111 1.111380e-14 0.10877425
1670     1 0.10409443 0.1111111 0.024846558 0.1111111 1.068210e-14 0.10973210
1671     1 0.10318009 0.1111111 0.023919760 0.1111111 1.026717e-14 0.11069734
1672     1 0.10227286 0.1111111 0.023026717 0.1111111 9.868366e-15 0.11167000
1673     1 0.10137270 0.1111111 0.022166258 0.1111111 9.485047e-15 0.11265013
1674     1 0.10047958 0.1111111 0.021337251 0.1111111 9.116618e-15 0.11363777
1675     1 0.09959346 0.1111111 0.020538597 0.1111111 8.762500e-15 0.11463294
1676     1 0.09871430 0.1111111 0.019769232 0.1111111 8.422138e-15 0.11563569
1677     1 0.09784205 0.1111111 0.019028128 0.1111111 8.094995e-15 0.11664605
1678     1 0.09697668 0.1111111 0.018314287 0.1111111 7.780560e-15 0.11766407
1679     1 0.09611815 0.1111111 0.017626744 0.1111111 7.478339e-15 0.11868978
1680     1 0.09526641 0.1111111 0.016964567 0.1111111 7.187857e-15 0.11972322
1681     1 0.09442144 0.1111111 0.016326852 0.1111111 6.908658e-15 0.12076442
1682     1 0.09358318 0.1111111 0.015712726 0.1111111 6.640304e-15 0.12181343
1683     1 0.09275161 0.1111111 0.015121345 0.1111111 6.382374e-15 0.12287027
1684     1 0.09192668 0.1111111 0.014551893 0.1111111 6.134463e-15 0.12393499
1685     1 0.09110834 0.1111111 0.014003581 0.1111111 5.896181e-15 0.12500762
1686     1 0.09029657 0.1111111 0.013475647 0.1111111 5.667155e-15 0.12608820
1687     1 0.08949131 0.1111111 0.012967354 0.1111111 5.447025e-15 0.12717676
1688     1 0.08869254 0.1111111 0.012477991 0.1111111 5.235445e-15 0.12827334
1689     1 0.08790021 0.1111111 0.012006871 0.1111111 5.032084e-15 0.12937797
1690     1 0.08711428 0.1111111 0.011553330 0.1111111 4.836622e-15 0.13049070
1691     1 0.08633471 0.1111111 0.011116729 0.1111111 4.648753e-15 0.13161154
1692     1 0.08556147 0.1111111 0.010696448 0.1111111 4.468181e-15 0.13274054
1693     1 0.08479450 0.1111111 0.010291891 0.1111111 4.294623e-15 0.13387774
1694     1 0.08403378 0.1111111 0.009902482 0.1111111 4.127806e-15 0.13502316
1695     1 0.08327927 0.1111111 0.009527665 0.1111111 3.967469e-15 0.13617684
1696     1 0.08253092 0.1111111 0.009166903 0.1111111 3.813360e-15 0.13733881
1697     1 0.08178869 0.1111111 0.008819680 0.1111111 3.665237e-15 0.13850911
1698     1 0.08105255 0.1111111 0.008485497 0.1111111 3.522868e-15 0.13968776
1699     1 0.08032245 0.1111111 0.008163872 0.1111111 3.386029e-15 0.14087480
1700     1 0.07959836 0.1111111 0.007854340 0.1111111 3.254505e-15 0.14207027
1701     1 0.07888024 0.1111111 0.007556455 0.1111111 3.128090e-15 0.14327419
1702     1 0.07816805 0.1111111 0.007269785 0.1111111 3.006585e-15 0.14448659
1703     1 0.07746175 0.1111111 0.006993914 0.1111111 2.889800e-15 0.14570751
1704     1 0.07676130 0.1111111 0.006728441 0.1111111 2.777551e-15 0.14693697
1705     1 0.07606665 0.1111111 0.006472978 0.1111111 2.669662e-15 0.14817500
1706     1 0.07537779 0.1111111 0.006227154 0.1111111 2.565964e-15 0.14942165
1707     1 0.07469465 0.1111111 0.005990609 0.1111111 2.466294e-15 0.15067692
1708     1 0.07401721 0.1111111 0.005762998 0.1111111 2.370496e-15 0.15194085
1709     1 0.07334543 0.1111111 0.005543987 0.1111111 2.278418e-15 0.15321348
1710     1 0.07267927 0.1111111 0.005333253 0.1111111 2.189917e-15 0.15449482
1711     1 0.07201869 0.1111111 0.005130489 0.1111111 2.104854e-15 0.15578491
1712     1 0.07136365 0.1111111 0.004935396 0.1111111 2.023095e-15 0.15708377
1713     1 0.07071411 0.1111111 0.004747685 0.1111111 1.944511e-15 0.15839142
1714     1 0.07007004 0.1111111 0.004567081 0.1111111 1.868981e-15 0.15970790
1715     1 0.06943140 0.1111111 0.004393318 0.1111111 1.796384e-15 0.16103323
1716     1 0.06879814 0.1111111 0.004226137 0.1111111 1.726606e-15 0.16236743
1717     1 0.06817024 0.1111111 0.004065292 0.1111111 1.659540e-15 0.16371053
1718     1 0.16371053 0.1111111 0.152939542 0.1111111 1.346239e-14 0.06817024
1719     1 0.16236743 0.1111111 0.147959730 0.1111111 1.293947e-14 0.06879814
1720     1 0.16103323 0.1111111 0.143114669 0.1111111 1.243686e-14 0.06943140
1721     1 0.15970790 0.1111111 0.138402492 0.1111111 1.195378e-14 0.07007004
1722     1 0.15839142 0.1111111 0.133821238 0.1111111 1.148945e-14 0.07071411
1723     1 0.15708377 0.1111111 0.129368857 0.1111111 1.104317e-14 0.07136365
1724     1 0.15578491 0.1111111 0.125043228 0.1111111 1.061422e-14 0.07201869
1725     1 0.15449482 0.1111111 0.120842156 0.1111111 1.020193e-14 0.07267927
1726     1 0.15321348 0.1111111 0.116763393 0.1111111 9.805652e-15 0.07334543
1727     1 0.15194085 0.1111111 0.112804635 0.1111111 9.424770e-15 0.07401721
1728     1 0.15067692 0.1111111 0.108963536 0.1111111 9.058683e-15 0.07469465
1729     1 0.14942165 0.1111111 0.105237716 0.1111111 8.706815e-15 0.07537779
1730     1 0.14817500 0.1111111 0.101624765 0.1111111 8.368615e-15 0.07606665
1731     1 0.14693697 0.1111111 0.098122248 0.1111111 8.043552e-15 0.07676130
1732     1 0.14570751 0.1111111 0.094727717 0.1111111 7.731115e-15 0.07746175
1733     1 0.14448659 0.1111111 0.091438714 0.1111111 7.430815e-15 0.07816805
1734     1 0.14327419 0.1111111 0.088252774 0.1111111 7.142178e-15 0.07888024
1735     1 0.14207027 0.1111111 0.085167434 0.1111111 6.864754e-15 0.07959836
1736     1 0.14087480 0.1111111 0.082180237 0.1111111 6.598105e-15 0.08032245
1737     1 0.13968776 0.1111111 0.079288732 0.1111111 6.341814e-15 0.08105255
1738     1 0.13850911 0.1111111 0.076490487 0.1111111 6.095478e-15 0.08178869
1739     1 0.13733881 0.1111111 0.073783082 0.1111111 5.858711e-15 0.08253092
1740     1 0.13617684 0.1111111 0.071164123 0.1111111 5.631140e-15 0.08327927
1741     1 0.13502316 0.1111111 0.068631236 0.1111111 5.412409e-15 0.08403378
1742     1 0.13387774 0.1111111 0.066182077 0.1111111 5.202174e-15 0.08479450
1743     1 0.13274054 0.1111111 0.063814329 0.1111111 5.000106e-15 0.08556147
1744     1 0.13161154 0.1111111 0.061525710 0.1111111 4.805886e-15 0.08633471
1745     1 0.13049070 0.1111111 0.059313968 0.1111111 4.619210e-15 0.08711428
1746     1 0.12937797 0.1111111 0.057176891 0.1111111 4.439786e-15 0.08790021
1747     1 0.12827334 0.1111111 0.055112302 0.1111111 4.267330e-15 0.08869254
1748     1 0.12717676 0.1111111 0.053118062 0.1111111 4.101574e-15 0.08949131
1749     1 0.12608820 0.1111111 0.051192074 0.1111111 3.942256e-15 0.09029657
1750     1 0.12500762 0.1111111 0.049332282 0.1111111 3.789126e-15 0.09110834
1751     1 0.12393499 0.1111111 0.047536670 0.1111111 3.641945e-15 0.09192668
1752     1 0.12287027 0.1111111 0.045803266 0.1111111 3.500480e-15 0.09275161
1753     1 0.12181343 0.1111111 0.044130142 0.1111111 3.364511e-15 0.09358318
1754     1 0.12076442 0.1111111 0.042515411 0.1111111 3.233823e-15 0.09442144
1755     1 0.11972322 0.1111111 0.040957232 0.1111111 3.108211e-15 0.09526641
1756     1 0.11868978 0.1111111 0.039453807 0.1111111 2.987478e-15 0.09611815
1757     1 0.11766407 0.1111111 0.038003381 0.1111111 2.871435e-15 0.09697668
1758     1 0.11664605 0.1111111 0.036604245 0.1111111 2.759900e-15 0.09784205
1759     1 0.11563569 0.1111111 0.035254732 0.1111111 2.652697e-15 0.09871430
1760     1 0.11463294 0.1111111 0.033953219 0.1111111 2.549658e-15 0.09959346
1761     1 0.11363777 0.1111111 0.032698125 0.1111111 2.450621e-15 0.10047958
1762     1 0.11265013 0.1111111 0.031487915 0.1111111 2.355431e-15 0.10137270
1763     1 0.11167000 0.1111111 0.030321092 0.1111111 2.263939e-15 0.10227286
1764     1 0.11069734 0.1111111 0.029196204 0.1111111 2.176000e-15 0.10318009
1765     1 0.10973210 0.1111111 0.028111839 0.1111111 2.091478e-15 0.10409443
1766     1 0.10877425 0.1111111 0.027066624 0.1111111 2.010238e-15 0.10501593
1767     1 0.10782374 0.1111111 0.026059230 0.1111111 1.932154e-15 0.10594462
1768     1 0.10688055 0.1111111 0.025088363 0.1111111 1.857103e-15 0.10688055
1769     1 0.10594462 0.1111111 0.024152769 0.1111111 1.784968e-15 0.10782374
1770     1 0.10501593 0.1111111 0.023251234 0.1111111 1.715634e-15 0.10877425
1771     1 0.10409443 0.1111111 0.022382577 0.1111111 1.648993e-15 0.10973210
1772     1 0.10318009 0.1111111 0.021545658 0.1111111 1.584941e-15 0.11069734
1773     1 0.10227286 0.1111111 0.020739368 0.1111111 1.523377e-15 0.11167000
1774     1 0.10137270 0.1111111 0.019962636 0.1111111 1.464204e-15 0.11265013
1775     1 0.10047958 0.1111111 0.019214424 0.1111111 1.407330e-15 0.11363777
1776     1 0.09959346 0.1111111 0.018493726 0.1111111 1.352665e-15 0.11463294
1777     1 0.09871430 0.1111111 0.017799569 0.1111111 1.300123e-15 0.11563569
1778     1 0.09784205 0.1111111 0.017131012 0.1111111 1.249622e-15 0.11664605
1779     1 0.09697668 0.1111111 0.016487146 0.1111111 1.201083e-15 0.11766407
1780     1 0.09611815 0.1111111 0.015867088 0.1111111 1.154429e-15 0.11868978
1781     1 0.09526641 0.1111111 0.015269987 0.1111111 1.109588e-15 0.11972322
1782     1 0.09442144 0.1111111 0.014695021 0.1111111 1.066488e-15 0.12076442
1783     1 0.09358318 0.1111111 0.014141393 0.1111111 1.025062e-15 0.12181343
1784     1 0.09275161 0.1111111 0.013608335 0.1111111 9.852455e-16 0.12287027
1785     1 0.09192668 0.1111111 0.013095104 0.1111111 9.469755e-16 0.12393499
1786     1 0.09110834 0.1111111 0.012600981 0.1111111 9.101920e-16 0.12500762
1787     1 0.09029657 0.1111111 0.012125274 0.1111111 8.748373e-16 0.12608820
1788     1 0.08949131 0.1111111 0.011667314 0.1111111 8.408559e-16 0.12717676
1789     1 0.08869254 0.1111111 0.011226454 0.1111111 8.081944e-16 0.12827334
1790     1 0.08790021 0.1111111 0.010802070 0.1111111 7.768016e-16 0.12937797
1791     1 0.08711428 0.1111111 0.010393561 0.1111111 7.466282e-16 0.13049070
1792     1 0.08633471 0.1111111 0.010000343 0.1111111 7.176268e-16 0.13161154
1793     1 0.08556147 0.1111111 0.009621858 0.1111111 6.897519e-16 0.13274054
1794     1 0.08479450 0.1111111 0.009257564 0.1111111 6.629598e-16 0.13387774
1795     1 0.08403378 0.1111111 0.008906938 0.1111111 6.372084e-16 0.13502316
1796     1 0.08327927 0.1111111 0.008569477 0.1111111 6.124572e-16 0.13617684
1797     1 0.08253092 0.1111111 0.008244695 0.1111111 5.886675e-16 0.13733881
1798     1 0.08178869 0.1111111 0.007932123 0.1111111 5.658018e-16 0.13850911
1799     1 0.08105255 0.1111111 0.007631311 0.1111111 5.438243e-16 0.13968776
1800     1 0.08032245 0.1111111 0.007341822 0.1111111 5.227004e-16 0.14087480
1801     1 0.07959836 0.1111111 0.007063237 0.1111111 5.023971e-16 0.14207027
1802     1 0.07888024 0.1111111 0.006795150 0.1111111 4.828824e-16 0.14327419
1803     1 0.07816805 0.1111111 0.006537171 0.1111111 4.641258e-16 0.14448659
1804     1 0.07746175 0.1111111 0.006288925 0.1111111 4.460977e-16 0.14570751
1805     1 0.07676130 0.1111111 0.006050048 0.1111111 4.287698e-16 0.14693697
1806     1 0.07606665 0.1111111 0.005820192 0.1111111 4.121151e-16 0.14817500
1807     1 0.07537779 0.1111111 0.005599019 0.1111111 3.961072e-16 0.14942165
1808     1 0.07469465 0.1111111 0.005386205 0.1111111 3.807212e-16 0.15067692
1809     1 0.07401721 0.1111111 0.005181438 0.1111111 3.659328e-16 0.15194085
1810     1 0.07334543 0.1111111 0.004984417 0.1111111 3.517188e-16 0.15321348
1811     1 0.07267927 0.1111111 0.004794851 0.1111111 3.380570e-16 0.15449482
1812     1 0.07201869 0.1111111 0.004612461 0.1111111 3.249258e-16 0.15578491
1813     1 0.07136365 0.1111111 0.004436979 0.1111111 3.123046e-16 0.15708377
1814     1 0.07071411 0.1111111 0.004268144 0.1111111 3.001738e-16 0.15839142
1815     1 0.07007004 0.1111111 0.004105706 0.1111111 2.885141e-16 0.15970790
1816     1 0.06943140 0.1111111 0.003949427 0.1111111 2.773073e-16 0.16103323
1817     1 0.06879814 0.1111111 0.003799073 0.1111111 2.665358e-16 0.16236743
1818     1 0.06817024 0.1111111 0.003654422 0.1111111 2.561827e-16 0.16371053
1819     1 0.16371053 0.1111111 0.139591220 0.1111111 2.078186e-15 0.06817024
1820     1 0.16236743 0.1111111 0.134976781 0.1111111 1.997463e-15 0.06879814
1821     1 0.16103323 0.1111111 0.130491747 0.1111111 1.919875e-15 0.06943140
1822     1 0.15970790 0.1111111 0.126134011 0.1111111 1.845301e-15 0.07007004
1823     1 0.15839142 0.1111111 0.121901399 0.1111111 1.773624e-15 0.07071411
1824     1 0.15708377 0.1111111 0.117791673 0.1111111 1.704731e-15 0.07136365
1825     1 0.15578491 0.1111111 0.113802544 0.1111111 1.638514e-15 0.07201869
1826     1 0.15449482 0.1111111 0.109931676 0.1111111 1.574869e-15 0.07267927
1827     1 0.15321348 0.1111111 0.106176697 0.1111111 1.513696e-15 0.07334543
1828     1 0.15194085 0.1111111 0.102535203 0.1111111 1.454899e-15 0.07401721
1829     1 0.15067692 0.1111111 0.099004766 0.1111111 1.398387e-15 0.07469465
1830     1 0.14942165 0.1111111 0.095582940 0.1111111 1.344069e-15 0.07537779
1831     1 0.14817500 0.1111111 0.092267269 0.1111111 1.291861e-15 0.07606665
1832     1 0.14693697 0.1111111 0.089055291 0.1111111 1.241681e-15 0.07676130
1833     1 0.14570751 0.1111111 0.085944539 0.1111111 1.193450e-15 0.07746175
1834     1 0.14448659 0.1111111 0.082932556 0.1111111 1.147093e-15 0.07816805
1835     1 0.14327419 0.1111111 0.080016889 0.1111111 1.102536e-15 0.07888024
1836     1 0.14207027 0.1111111 0.077195100 0.1111111 1.059710e-15 0.07959836
1837     1 0.14087480 0.1111111 0.074464766 0.1111111 1.018548e-15 0.08032245
1838     1 0.13968776 0.1111111 0.071823487 0.1111111 9.789843e-16 0.08105255
1839     1 0.13850911 0.1111111 0.069268882 0.1111111 9.409575e-16 0.08178869
1840     1 0.13733881 0.1111111 0.066798600 0.1111111 9.044078e-16 0.08253092
1841     1 0.13617684 0.1111111 0.064410317 0.1111111 8.692777e-16 0.08327927
1842     1 0.13502316 0.1111111 0.062101741 0.1111111 8.355123e-16 0.08403378
1843     1 0.13387774 0.1111111 0.059870613 0.1111111 8.030584e-16 0.08479450
1844     1 0.13274054 0.1111111 0.057714711 0.1111111 7.718651e-16 0.08556147
1845     1 0.13161154 0.1111111 0.055631847 0.1111111 7.418834e-16 0.08633471
1846     1 0.13049070 0.1111111 0.053619874 0.1111111 7.130663e-16 0.08711428
1847     1 0.12937797 0.1111111 0.051676684 0.1111111 6.853686e-16 0.08790021
1848     1 0.12827334 0.1111111 0.049800210 0.1111111 6.587467e-16 0.08869254
1849     1 0.12717676 0.1111111 0.047988426 0.1111111 6.331590e-16 0.08949131
1850     1 0.12608820 0.1111111 0.046239349 0.1111111 6.085651e-16 0.09029657
1851     1 0.12500762 0.1111111 0.044551039 0.1111111 5.849265e-16 0.09110834
1852     1 0.12393499 0.1111111 0.042921599 0.1111111 5.622061e-16 0.09192668
1853     1 0.12287027 0.1111111 0.041349177 0.1111111 5.403683e-16 0.09275161
1854     1 0.12181343 0.1111111 0.039831962 0.1111111 5.193787e-16 0.09358318
1855     1 0.12076442 0.1111111 0.038368189 0.1111111 4.992044e-16 0.09442144
1856     1 0.11972322 0.1111111 0.036956138 0.1111111 4.798137e-16 0.09526641
1857     1 0.11868978 0.1111111 0.035594131 0.1111111 4.611763e-16 0.09611815
1858     1 0.11766407 0.1111111 0.034280533 0.1111111 4.432627e-16 0.09697668
1859     1 0.11664605 0.1111111 0.033013754 0.1111111 4.260450e-16 0.09784205
1860     1 0.11563569 0.1111111 0.031792246 0.1111111 4.094961e-16 0.09871430
1861     1 0.11463294 0.1111111 0.030614502 0.1111111 3.935900e-16 0.09959346
1862     1 0.11363777 0.1111111 0.029479060 0.1111111 3.783017e-16 0.10047958
1863     1 0.11265013 0.1111111 0.028384496 0.1111111 3.636073e-16 0.10137270
1864     1 0.11167000 0.1111111 0.027329429 0.1111111 3.494837e-16 0.10227286
1865     1 0.11069734 0.1111111 0.026312518 0.1111111 3.359086e-16 0.10318009
1866     1 0.10973210 0.1111111 0.025332459 0.1111111 3.228609e-16 0.10409443
1867     1 0.10877425 0.1111111 0.024387991 0.1111111 3.103200e-16 0.10501593
1868     1 0.10782374 0.1111111 0.023477887 0.1111111 2.982662e-16 0.10594462
1869     1 0.10688055 0.1111111 0.022600959 0.1111111 2.866806e-16 0.10688055
1870     1 0.10594462 0.1111111 0.021756055 0.1111111 2.755450e-16 0.10782374
1871     1 0.10501593 0.1111111 0.020942061 0.1111111 2.648420e-16 0.10877425
1872     1 0.10409443 0.1111111 0.020157894 0.1111111 2.545547e-16 0.10973210
1873     1 0.10318009 0.1111111 0.019402508 0.1111111 2.446670e-16 0.11069734
1874     1 0.10227286 0.1111111 0.018674889 0.1111111 2.351633e-16 0.11167000
1875     1 0.10137270 0.1111111 0.017974057 0.1111111 2.260289e-16 0.11265013
1876     1 0.10047958 0.1111111 0.017299062 0.1111111 2.172492e-16 0.11363777
1877     1 0.09959346 0.1111111 0.016648986 0.1111111 2.088106e-16 0.11463294
1878     1 0.09871430 0.1111111 0.016022941 0.1111111 2.006997e-16 0.11563569
1879     1 0.09784205 0.1111111 0.015420067 0.1111111 1.929039e-16 0.11664605
1880     1 0.09697668 0.1111111 0.014839535 0.1111111 1.854109e-16 0.11766407
1881     1 0.09611815 0.1111111 0.014280542 0.1111111 1.782090e-16 0.11868978
1882     1 0.09526641 0.1111111 0.013742312 0.1111111 1.712868e-16 0.11972322
1883     1 0.09442144 0.1111111 0.013224095 0.1111111 1.646335e-16 0.12076442
1884     1 0.09358318 0.1111111 0.012725168 0.1111111 1.582386e-16 0.12181343
1885     1 0.09275161 0.1111111 0.012244831 0.1111111 1.520921e-16 0.12287027
1886     1 0.09192668 0.1111111 0.011782409 0.1111111 1.461844e-16 0.12393499
1887     1 0.09110834 0.1111111 0.011337250 0.1111111 1.405061e-16 0.12500762
1888     1 0.09029657 0.1111111 0.010908724 0.1111111 1.350484e-16 0.12608820
1889     1 0.08949131 0.1111111 0.010496224 0.1111111 1.298027e-16 0.12717676
1890     1 0.08869254 0.1111111 0.010099162 0.1111111 1.247608e-16 0.12827334
1891     1 0.08790021 0.1111111 0.009716974 0.1111111 1.199147e-16 0.12937797
1892     1 0.08711428 0.1111111 0.009349112 0.1111111 1.152568e-16 0.13049070
1893     1 0.08633471 0.1111111 0.008995050 0.1111111 1.107799e-16 0.13161154
1894     1 0.08556147 0.1111111 0.008654280 0.1111111 1.064768e-16 0.13274054
1895     1 0.08479450 0.1111111 0.008326311 0.1111111 1.023409e-16 0.13387774
1896     1 0.08403378 0.1111111 0.008010670 0.1111111 9.836570e-17 0.13502316
1897     1 0.08327927 0.1111111 0.007706903 0.1111111 9.454487e-17 0.13617684
1898     1 0.08253092 0.1111111 0.007414568 0.1111111 9.087245e-17 0.13733881
1899     1 0.08178869 0.1111111 0.007133242 0.1111111 8.734268e-17 0.13850911
1900     1 0.08105255 0.1111111 0.006862516 0.1111111 8.395002e-17 0.13968776
1901     1 0.08032245 0.1111111 0.006601997 0.1111111 8.068914e-17 0.14087480
1902     1 0.07959836 0.1111111 0.006351305 0.1111111 7.755492e-17 0.14207027
1903     1 0.07888024 0.1111111 0.006110073 0.1111111 7.454244e-17 0.14327419
1904     1 0.07816805 0.1111111 0.005877949 0.1111111 7.164698e-17 0.14448659
1905     1 0.07746175 0.1111111 0.005654594 0.1111111 6.886399e-17 0.14570751
1906     1 0.07676130 0.1111111 0.005439680 0.1111111 6.618909e-17 0.14693697
1907     1 0.07606665 0.1111111 0.005232891 0.1111111 6.361810e-17 0.14817500
1908     1 0.07537779 0.1111111 0.005033923 0.1111111 6.114698e-17 0.14942165
1909     1 0.07469465 0.1111111 0.004842483 0.1111111 5.877184e-17 0.15067692
1910     1 0.07401721 0.1111111 0.004658290 0.1111111 5.648896e-17 0.15194085
1911     1 0.07334543 0.1111111 0.004481072 0.1111111 5.429475e-17 0.15321348
1912     1 0.07267927 0.1111111 0.004310566 0.1111111 5.218577e-17 0.15449482
1913     1 0.07201869 0.1111111 0.004146521 0.1111111 5.015871e-17 0.15578491
1914     1 0.07136365 0.1111111 0.003988694 0.1111111 4.821039e-17 0.15708377
1915     1 0.07071411 0.1111111 0.003836851 0.1111111 4.633775e-17 0.15839142
1916     1 0.07007004 0.1111111 0.003690768 0.1111111 4.453784e-17 0.15970790
1917     1 0.06943140 0.1111111 0.003550226 0.1111111 4.280786e-17 0.16103323
1918     1 0.06879814 0.1111111 0.003415018 0.1111111 4.114506e-17 0.16236743
1919     1 0.06817024 0.1111111 0.003284942 0.1111111 3.954686e-17 0.16371053
1920     1 0.16371053 0.1111111 0.127232926 0.1111111 3.208091e-16 0.06817024
1921     1 0.16236743 0.1111111 0.122968627 0.1111111 3.083479e-16 0.06879814
1922     1 0.16103323 0.1111111 0.118827790 0.1111111 2.963707e-16 0.06943140
1923     1 0.15970790 0.1111111 0.114808138 0.1111111 2.848587e-16 0.07007004
1924     1 0.15839142 0.1111111 0.110907347 0.1111111 2.737939e-16 0.07071411
1925     1 0.15708377 0.1111111 0.107123053 0.1111111 2.631589e-16 0.07136365
1926     1 0.15578491 0.1111111 0.103452858 0.1111111 2.529370e-16 0.07201869
1927     1 0.15449482 0.1111111 0.099894342 0.1111111 2.431121e-16 0.07267927
1928     1 0.15321348 0.1111111 0.096445062 0.1111111 2.336689e-16 0.07334543
1929     1 0.15194085 0.1111111 0.093102563 0.1111111 2.245925e-16 0.07401721
1930     1 0.15067692 0.1111111 0.089864385 0.1111111 2.158686e-16 0.07469465
1931     1 0.14942165 0.1111111 0.086728063 0.1111111 2.074836e-16 0.07537779
1932     1 0.14817500 0.1111111 0.083691134 0.1111111 1.994243e-16 0.07606665
1933     1 0.14693697 0.1111111 0.080751146 0.1111111 1.916780e-16 0.07676130
1934     1 0.14570751 0.1111111 0.077905656 0.1111111 1.842326e-16 0.07746175
1935     1 0.14448659 0.1111111 0.075152238 0.1111111 1.770765e-16 0.07816805
1936     1 0.14327419 0.1111111 0.072488483 0.1111111 1.701983e-16 0.07888024
1937     1 0.14207027 0.1111111 0.069912007 0.1111111 1.635872e-16 0.07959836
1938     1 0.14087480 0.1111111 0.067420451 0.1111111 1.572330e-16 0.08032245
1939     1 0.13968776 0.1111111 0.065011484 0.1111111 1.511256e-16 0.08105255
1940     1 0.13850911 0.1111111 0.062682805 0.1111111 1.452554e-16 0.08178869
1941     1 0.13733881 0.1111111 0.060432146 0.1111111 1.396132e-16 0.08253092
1942     1 0.13617684 0.1111111 0.058257276 0.1111111 1.341902e-16 0.08327927
1943     1 0.13502316 0.1111111 0.056155999 0.1111111 1.289778e-16 0.08403378
1944     1 0.13387774 0.1111111 0.054126156 0.1111111 1.239679e-16 0.08479450
1945     1 0.13274054 0.1111111 0.052165630 0.1111111 1.191526e-16 0.08556147
1946     1 0.13161154 0.1111111 0.050272343 0.1111111 1.145244e-16 0.08633471
1947     1 0.13049070 0.1111111 0.048444258 0.1111111 1.100759e-16 0.08711428
1948     1 0.12937797 0.1111111 0.046679381 0.1111111 1.058002e-16 0.08790021
1949     1 0.12827334 0.1111111 0.044975762 0.1111111 1.016906e-16 0.08869254
1950     1 0.12717676 0.1111111 0.043331493 0.1111111 9.774059e-17 0.08949131
1951     1 0.12608820 0.1111111 0.041744709 0.1111111 9.394404e-17 0.09029657
1952     1 0.12500762 0.1111111 0.040213589 0.1111111 9.029496e-17 0.09110834
1953     1 0.12393499 0.1111111 0.038736358 0.1111111 8.678762e-17 0.09192668
1954     1 0.12287027 0.1111111 0.037311284 0.1111111 8.341652e-17 0.09275161
1955     1 0.12181343 0.1111111 0.035936676 0.1111111 8.017636e-17 0.09358318
1956     1 0.12076442 0.1111111 0.034610890 0.1111111 7.706206e-17 0.09442144
1957     1 0.11972322 0.1111111 0.033332325 0.1111111 7.406873e-17 0.09526641
1958     1 0.11868978 0.1111111 0.032099421 0.1111111 7.119167e-17 0.09611815
1959     1 0.11766407 0.1111111 0.030910661 0.1111111 6.842636e-17 0.09697668
1960     1 0.11664605 0.1111111 0.029764572 0.1111111 6.576847e-17 0.09784205
1961     1 0.11563569 0.1111111 0.028659720 0.1111111 6.321381e-17 0.09871430
1962     1 0.11463294 0.1111111 0.027594713 0.1111111 6.075839e-17 0.09959346
1963     1 0.11363777 0.1111111 0.026568201 0.1111111 5.839834e-17 0.10047958
1964     1 0.11265013 0.1111111 0.025578869 0.1111111 5.612997e-17 0.10137270
1965     1 0.11167000 0.1111111 0.024625446 0.1111111 5.394971e-17 0.10227286
1966     1 0.11069734 0.1111111 0.023706696 0.1111111 5.185413e-17 0.10318009
1967     1 0.10973210 0.1111111 0.022821421 0.1111111 4.983995e-17 0.10409443
1968     1 0.10877425 0.1111111 0.021968461 0.1111111 4.790401e-17 0.10501593
1969     1 0.10782374 0.1111111 0.021146691 0.1111111 4.604327e-17 0.10594462
1970     1 0.10688055 0.1111111 0.020355021 0.1111111 4.425481e-17 0.10688055
1971     1 0.10594462 0.1111111 0.019592396 0.1111111 4.253581e-17 0.10782374
1972     1 0.10501593 0.1111111 0.018857793 0.1111111 4.088359e-17 0.10877425
1973     1 0.10409443 0.1111111 0.018150224 0.1111111 3.929554e-17 0.10973210
1974     1 0.10318009 0.1111111 0.017468731 0.1111111 3.776918e-17 0.11069734
1975     1 0.10227286 0.1111111 0.016812388 0.1111111 3.630211e-17 0.11167000
1976     1 0.10137270 0.1111111 0.016180300 0.1111111 3.489202e-17 0.11265013
1977     1 0.10047958 0.1111111 0.015571599 0.1111111 3.353670e-17 0.11363777
1978     1 0.09959346 0.1111111 0.014985449 0.1111111 3.223403e-17 0.11463294
1979     1 0.09871430 0.1111111 0.014421040 0.1111111 3.098196e-17 0.11563569
1980     1 0.09784205 0.1111111 0.013877589 0.1111111 2.977853e-17 0.11664605
1981     1 0.09697668 0.1111111 0.013354340 0.1111111 2.862184e-17 0.11766407
1982     1 0.09611815 0.1111111 0.012850563 0.1111111 2.751007e-17 0.11868978
1983     1 0.09526641 0.1111111 0.012365552 0.1111111 2.644150e-17 0.11972322
1984     1 0.09442144 0.1111111 0.011898626 0.1111111 2.541443e-17 0.12076442
1985     1 0.09358318 0.1111111 0.011449127 0.1111111 2.442725e-17 0.12181343
1986     1 0.09275161 0.1111111 0.011016420 0.1111111 2.347842e-17 0.12287027
1987     1 0.09192668 0.1111111 0.010599890 0.1111111 2.256644e-17 0.12393499
1988     1 0.09110834 0.1111111 0.010198948 0.1111111 2.168989e-17 0.12500762
1989     1 0.09029657 0.1111111 0.009813020 0.1111111 2.084739e-17 0.12608820
1990     1 0.08949131 0.1111111 0.009441557 0.1111111 2.003761e-17 0.12717676
1991     1 0.08869254 0.1111111 0.009084026 0.1111111 1.925929e-17 0.12827334
1992     1 0.08790021 0.1111111 0.008739915 0.1111111 1.851120e-17 0.12937797
1993     1 0.08711428 0.1111111 0.008408728 0.1111111 1.779216e-17 0.13049070
1994     1 0.08633471 0.1111111 0.008089989 0.1111111 1.710106e-17 0.13161154
1995     1 0.08556147 0.1111111 0.007783237 0.1111111 1.643680e-17 0.13274054
1996     1 0.08479450 0.1111111 0.007488028 0.1111111 1.579835e-17 0.13387774
1997     1 0.08403378 0.1111111 0.007203935 0.1111111 1.518469e-17 0.13502316
1998     1 0.08327927 0.1111111 0.006930545 0.1111111 1.459487e-17 0.13617684
1999     1 0.08253092 0.1111111 0.006667461 0.1111111 1.402796e-17 0.13733881
2000     1 0.08178869 0.1111111 0.006414299 0.1111111 1.348307e-17 0.13850911
2001     1 0.08105255 0.1111111 0.006170690 0.1111111 1.295934e-17 0.13968776
2002     1 0.08032245 0.1111111 0.005936277 0.1111111 1.245596e-17 0.14087480
2003     1 0.07959836 0.1111111 0.005710718 0.1111111 1.197213e-17 0.14207027
2004     1 0.07888024 0.1111111 0.005493682 0.1111111 1.150710e-17 0.14327419
2005     1 0.07816805 0.1111111 0.005284851 0.1111111 1.106013e-17 0.14448659
2006     1 0.07746175 0.1111111 0.005083918 0.1111111 1.063052e-17 0.14570751
2007     1 0.07676130 0.1111111 0.004890586 0.1111111 1.021759e-17 0.14693697
2008     1 0.07606665 0.1111111 0.004704572 0.1111111 9.820711e-18 0.14817500
2009     1 0.07537779 0.1111111 0.004525601 0.1111111 9.439244e-18 0.14942165
2010     1 0.07469465 0.1111111 0.004353408 0.1111111 9.072594e-18 0.15067692
2011     1 0.07401721 0.1111111 0.004187740 0.1111111 8.720186e-18 0.15194085
2012     1 0.07334543 0.1111111 0.004028350 0.1111111 8.381467e-18 0.15321348
2013     1 0.07267927 0.1111111 0.003875004 0.1111111 8.055904e-18 0.15449482
2014     1 0.07201869 0.1111111 0.003727473 0.1111111 7.742988e-18 0.15578491
2015     1 0.07136365 0.1111111 0.003585538 0.1111111 7.442226e-18 0.15708377
2016     1 0.07071411 0.1111111 0.003448990 0.1111111 7.153147e-18 0.15839142
2017     1 0.07007004 0.1111111 0.003317624 0.1111111 6.875296e-18 0.15970790
2018     1 0.06943140 0.1111111 0.003191246 0.1111111 6.608238e-18 0.16103323
2019     1 0.06879814 0.1111111 0.003069667 0.1111111 6.351553e-18 0.16236743
2020     1 0.06817024 0.1111111 0.002952707 0.1111111 6.104839e-18 0.16371053
2021     1 0.16371053 0.1111111 0.115821457 0.1111111 4.952322e-17 0.06817024
2022     1 0.16236743 0.1111111 0.111890589 0.1111111 4.759959e-17 0.06879814
2023     1 0.16103323 0.1111111 0.108076823 0.1111111 4.575067e-17 0.06943140
2024     1 0.15970790 0.1111111 0.104377771 0.1111111 4.397357e-17 0.07007004
2025     1 0.15839142 0.1111111 0.100791017 0.1111111 4.226550e-17 0.07071411
2026     1 0.15708377 0.1111111 0.097314122 0.1111111 4.062378e-17 0.07136365
2027     1 0.15578491 0.1111111 0.093944637 0.1111111 3.904582e-17 0.07201869
2028     1 0.15449482 0.1111111 0.090680099 0.1111111 3.752916e-17 0.07267927
2029     1 0.15321348 0.1111111 0.087518045 0.1111111 3.607141e-17 0.07334543
2030     1 0.15194085 0.1111111 0.084456012 0.1111111 3.467028e-17 0.07401721
2031     1 0.15067692 0.1111111 0.081491545 0.1111111 3.332358e-17 0.07469465
2032     1 0.14942165 0.1111111 0.078622196 0.1111111 3.202919e-17 0.07537779
2033     1 0.14817500 0.1111111 0.075845536 0.1111111 3.078507e-17 0.07606665
2034     1 0.14693697 0.1111111 0.073159151 0.1111111 2.958929e-17 0.07676130
2035     1 0.14570751 0.1111111 0.070560651 0.1111111 2.843995e-17 0.07746175
2036     1 0.14448659 0.1111111 0.068047670 0.1111111 2.733525e-17 0.07816805
2037     1 0.14327419 0.1111111 0.065617868 0.1111111 2.627346e-17 0.07888024
2038     1 0.14207027 0.1111111 0.063268939 0.1111111 2.525292e-17 0.07959836
2039     1 0.14087480 0.1111111 0.060998604 0.1111111 2.427202e-17 0.08032245
2040     1 0.13968776 0.1111111 0.058804624 0.1111111 2.332922e-17 0.08105255
2041     1 0.13850911 0.1111111 0.056684793 0.1111111 2.242304e-17 0.08178869
2042     1 0.13733881 0.1111111 0.054636943 0.1111111 2.155205e-17 0.08253092
2043     1 0.13617684 0.1111111 0.052658945 0.1111111 2.071491e-17 0.08327927
2044     1 0.13502316 0.1111111 0.050748712 0.1111111 1.991027e-17 0.08403378
2045     1 0.13387774 0.1111111 0.048904197 0.1111111 1.913690e-17 0.08479450
2046     1 0.13274054 0.1111111 0.047123394 0.1111111 1.839356e-17 0.08556147
2047     1 0.13161154 0.1111111 0.045404342 0.1111111 1.767910e-17 0.08633471
2048     1 0.13049070 0.1111111 0.043745122 0.1111111 1.699238e-17 0.08711428
2049     1 0.12937797 0.1111111 0.042143858 0.1111111 1.633235e-17 0.08790021
2050     1 0.12827334 0.1111111 0.040598719 0.1111111 1.569795e-17 0.08869254
2051     1 0.12717676 0.1111111 0.039107917 0.1111111 1.508819e-17 0.08949131
2052     1 0.12608820 0.1111111 0.037669708 0.1111111 1.450212e-17 0.09029657
2053     1 0.12500762 0.1111111 0.036282393 0.1111111 1.393881e-17 0.09110834
2054     1 0.12393499 0.1111111 0.034944316 0.1111111 1.339738e-17 0.09192668
2055     1 0.12287027 0.1111111 0.033653862 0.1111111 1.287699e-17 0.09275161
2056     1 0.12181343 0.1111111 0.032409464 0.1111111 1.237680e-17 0.09358318
2057     1 0.12076442 0.1111111 0.031209592 0.1111111 1.189605e-17 0.09442144
2058     1 0.11972322 0.1111111 0.030052763 0.1111111 1.143397e-17 0.09526641
2059     1 0.11868978 0.1111111 0.028937533 0.1111111 1.098984e-17 0.09611815
2060     1 0.11766407 0.1111111 0.027862499 0.1111111 1.056296e-17 0.09697668
2061     1 0.11664605 0.1111111 0.026826299 0.1111111 1.015266e-17 0.09784205
2062     1 0.11563569 0.1111111 0.025827612 0.1111111 9.758300e-18 0.09871430
2063     1 0.11463294 0.1111111 0.024865154 0.1111111 9.379258e-18 0.09959346
2064     1 0.11363777 0.1111111 0.023937680 0.1111111 9.014938e-18 0.10047958
2065     1 0.11265013 0.1111111 0.023043983 0.1111111 8.664769e-18 0.10137270
2066     1 0.11167000 0.1111111 0.022182894 0.1111111 8.328203e-18 0.10227286
2067     1 0.11069734 0.1111111 0.021353278 0.1111111 8.004709e-18 0.10318009
2068     1 0.10973210 0.1111111 0.020554036 0.1111111 7.693781e-18 0.10409443
2069     1 0.10877425 0.1111111 0.019784105 0.1111111 7.394931e-18 0.10501593
2070     1 0.10782374 0.1111111 0.019042454 0.1111111 7.107689e-18 0.10594462
2071     1 0.10688055 0.1111111 0.018328086 0.1111111 6.831604e-18 0.10688055
2072     1 0.10594462 0.1111111 0.017640034 0.1111111 6.566243e-18 0.10782374
2073     1 0.10501593 0.1111111 0.016977367 0.1111111 6.311189e-18 0.10877425
2074     1 0.10409443 0.1111111 0.016339178 0.1111111 6.066043e-18 0.10973210
2075     1 0.10318009 0.1111111 0.015724596 0.1111111 5.830419e-18 0.11069734
2076     1 0.10227286 0.1111111 0.015132776 0.1111111 5.603947e-18 0.11167000
2077     1 0.10137270 0.1111111 0.014562899 0.1111111 5.386272e-18 0.11265013
2078     1 0.10047958 0.1111111 0.014014179 0.1111111 5.177053e-18 0.11363777
2079     1 0.09959346 0.1111111 0.013485850 0.1111111 4.975960e-18 0.11463294
2080     1 0.09871430 0.1111111 0.012977177 0.1111111 4.782678e-18 0.11563569
2081     1 0.09784205 0.1111111 0.012487448 0.1111111 4.596904e-18 0.11664605
2082     1 0.09697668 0.1111111 0.012015975 0.1111111 4.418346e-18 0.11766407
2083     1 0.09611815 0.1111111 0.011562095 0.1111111 4.246723e-18 0.11868978
2084     1 0.09526641 0.1111111 0.011125166 0.1111111 4.081767e-18 0.11972322
2085     1 0.09442144 0.1111111 0.010704570 0.1111111 3.923219e-18 0.12076442
2086     1 0.09358318 0.1111111 0.010299709 0.1111111 3.770829e-18 0.12181343
2087     1 0.09275161 0.1111111 0.009910007 0.1111111 3.624358e-18 0.12287027
2088     1 0.09192668 0.1111111 0.009534908 0.1111111 3.483576e-18 0.12393499
2089     1 0.09110834 0.1111111 0.009173875 0.1111111 3.348263e-18 0.12500762
2090     1 0.09029657 0.1111111 0.008826390 0.1111111 3.218206e-18 0.12608820
2091     1 0.08949131 0.1111111 0.008491954 0.1111111 3.093201e-18 0.12717676
2092     1 0.08869254 0.1111111 0.008170086 0.1111111 2.973052e-18 0.12827334
2093     1 0.08790021 0.1111111 0.007860321 0.1111111 2.857569e-18 0.12937797
2094     1 0.08711428 0.1111111 0.007562211 0.1111111 2.746572e-18 0.13049070
2095     1 0.08633471 0.1111111 0.007275324 0.1111111 2.639887e-18 0.13161154
2096     1 0.08556147 0.1111111 0.006999244 0.1111111 2.537345e-18 0.13274054
2097     1 0.08479450 0.1111111 0.006733570 0.1111111 2.438787e-18 0.13387774
2098     1 0.08403378 0.1111111 0.006477914 0.1111111 2.344057e-18 0.13502316
2099     1 0.08327927 0.1111111 0.006231904 0.1111111 2.253006e-18 0.13617684
2100     1 0.08253092 0.1111111 0.005995180 0.1111111 2.165492e-18 0.13733881
2101     1 0.08178869 0.1111111 0.005767396 0.1111111 2.081378e-18 0.13850911
2102     1 0.08105255 0.1111111 0.005548218 0.1111111 2.000531e-18 0.13968776
2103     1 0.08032245 0.1111111 0.005337325 0.1111111 1.922824e-18 0.14087480
2104     1 0.07959836 0.1111111 0.005134407 0.1111111 1.848135e-18 0.14207027
2105     1 0.07888024 0.1111111 0.004939165 0.1111111 1.776348e-18 0.14327419
2106     1 0.07816805 0.1111111 0.004751312 0.1111111 1.707349e-18 0.14448659
2107     1 0.07746175 0.1111111 0.004570571 0.1111111 1.641030e-18 0.14570751
2108     1 0.07676130 0.1111111 0.004396675 0.1111111 1.577287e-18 0.14693697
2109     1 0.07606665 0.1111111 0.004229367 0.1111111 1.516021e-18 0.14817500
2110     1 0.07537779 0.1111111 0.004068399 0.1111111 1.457134e-18 0.14942165
2111     1 0.07469465 0.1111111 0.003913534 0.1111111 1.400534e-18 0.15067692
2112     1 0.07401721 0.1111111 0.003764542 0.1111111 1.346133e-18 0.15194085
2113     1 0.07334543 0.1111111 0.003621201 0.1111111 1.293845e-18 0.15321348
2114     1 0.07267927 0.1111111 0.003483299 0.1111111 1.243588e-18 0.15449482
2115     1 0.07201869 0.1111111 0.003350631 0.1111111 1.195283e-18 0.15578491
2116     1 0.07136365 0.1111111 0.003223000 0.1111111 1.148855e-18 0.15708377
2117     1 0.07071411 0.1111111 0.003100215 0.1111111 1.104229e-18 0.15839142
2118     1 0.07007004 0.1111111 0.002982094 0.1111111 1.061338e-18 0.15970790
2119     1 0.06943140 0.1111111 0.002868460 0.1111111 1.020112e-18 0.16103323
2120     1 0.06879814 0.1111111 0.002759145 0.1111111 9.804877e-19 0.16236743
2121     1 0.06817024 0.1111111 0.002653984 0.1111111 9.424025e-19 0.16371053
> 
> 
> 
> 
> cleanEx()
> nameEx("countFreeParameters")
> ### * countFreeParameters
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: countFreeParameters
> ### Title: Count how many free parameters in the target object
> ### Aliases: countFreeParameters countFreeParameters-methods
> ###   countFreeParameters,ANY-method countFreeParameters,SimMatrix-method
> ###   countFreeParameters,SymMatrix-method
> ###   countFreeParameters,SimVector-method
> ###   countFreeParameters,SimSet-method countFreeParameters,matrix-method
> ###   countFreeParameters,vector-method
> ###   countFreeParameters,VirtualRSet-method
> ###   countFreeParameters,SimEqualCon-method
> ###   countFreeParameters,SimREqualCon-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("countMACS")
> ### * countMACS
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: countMACS
> ### Title: Count the number of elements in the sufficient statistics
> ### Aliases: countMACS
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("cov2corMod")
> ### * cov2corMod
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cov2corMod
> ### Title: Convert a covariance matrix to a correlation matrix
> ### Aliases: cov2corMod
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("createData")
> ### * createData
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: createData
> ### Title: Create data from model parameters
> ### Aliases: createData
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("createFreeParameters")
> ### * createFreeParameters
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: createFreeParameters
> ### Title: Create a free parameters object from a model specification
> ### Aliases: createFreeParameters
> 
> ### ** Examples
> 
> # No comment out because this function is not public
> 
> # loading <- matrix(0, 6, 2)
> # loading[1:3, 1] <- NA
> # loading[4:6, 2] <- NA
> # loadingValues <- matrix(0, 6, 2)
> # loadingValues[1:3, 1] <- 0.7
> # loadingValues[4:6, 2] <- 0.7
> # LX <- simMatrix(loading, loadingValues)
> # latent.cor <- matrix(NA, 2, 2)
> # diag(latent.cor) <- 1
> # RPH <- symMatrix(latent.cor, 0.5)
> # error.cor <- matrix(0, 6, 6)
> # diag(error.cor) <- 1
> # RTD <- symMatrix(error.cor)
> # indicator.mean <- rep(NA, 6)
> # MX <- simVector(indicator.mean, 0)
> # CFA.Model <- simSetCFA(LX = LX, RPH = RPH, RTD = RTD, MX = MX)
> # free <- createFreeParameters(CFA.Model)
> 
> 
> 
> cleanEx()
> nameEx("createImpliedMACS")
> ### * createImpliedMACS
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: createImpliedMACS
> ### Title: Create model implied mean vector and covariance matrix
> ### Aliases: createImpliedMACS createImpliedMACS-methods
> ###   createImpliedMACS,MatrixSet-method createImpliedMACS,SimRSet-method
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> param <- run(CFA.Model)
> createImpliedMACS(param)
$M
[1] 0 0 0 0 0 0

$CM
      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]
[1,] 1.000 0.490 0.490 0.245 0.245 0.245
[2,] 0.490 1.000 0.490 0.245 0.245 0.245
[3,] 0.490 0.490 1.000 0.245 0.245 0.245
[4,] 0.245 0.245 0.245 1.000 0.490 0.490
[5,] 0.245 0.245 0.245 0.490 1.000 0.490
[6,] 0.245 0.245 0.245 0.490 0.490 1.000

> 
> 
> 
> cleanEx()
> nameEx("defaultStartingValues")
> ### * defaultStartingValues
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: defaultStartingValues
> ### Title: Make ad hoc starting values
> ### Aliases: defaultStartingValues
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("divideObject")
> ### * divideObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: divideObject
> ### Title: Make a division on each element of the object
> ### Aliases: divideObject divideObject-methods divideObject,ANY-method
> ###   divideObject,vector,numeric-method divideObject,matrix,numeric-method
> ###   divideObject,MatrixSet,numeric-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("drawParameters")
> ### * drawParameters
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: drawParameters
> ### Title: Create parameter sets (with or without model misspecification)
> ###   from the data object
> ### Aliases: drawParameters
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("drawParametersMisspec")
> ### * drawParametersMisspec
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: drawParametersMisspec
> ### Title: Create parameter sets (with or without model misspecification)
> ###   from the parameter with or without misspecification set
> ### Aliases: drawParametersMisspec
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("expandMatrices")
> ### * expandMatrices
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: expandMatrices
> ### Title: Expand the set of intercept and covariance matrices into the set
> ###   of intercept/mean and covariance/correlation/variance objects
> ### Aliases: expandMatrices
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("extract")
> ### * extract
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: extract
> ### Title: Extract a part of an object
> ### Aliases: extract extract-methods extract,vector-method
> ###   extract,matrix-method extract,VirtualRSet-method
> ###   extract,data.frame-method
> 
> ### ** Examples
> 
> extract(1:10, c(4, 5))
[1] 4 5
> extract(diag(3), 1, 2:3)
     [,1] [,2]
[1,]    0    0
> 
> 
> 
> cleanEx()
> nameEx("extractLavaanFit")
> ### * extractLavaanFit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: extractLavaanFit
> ### Title: Extract fit indices from the lavaan object
> ### Aliases: extractLavaanFit
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("extractMatrixNames")
> ### * extractMatrixNames
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: extractMatrixNames
> ### Title: Extract a vector of parameter names based on specified rows and
> ###   columns
> ### Aliases: extractMatrixNames
> 
> ### ** Examples
> 
> # The function is not public
> 
> # vec <- c("LY1_1", "LY2_1", "LY3_1", "LY4_2", "LY5_2", "LY6_2", "LY7_3")
> # extractMatrixNames(vec, 5:6, 2)
> 
> 
> 
> cleanEx()
> nameEx("extractOpenMxFit")
> ### * extractOpenMxFit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: extractOpenMxFit
> ### Title: Extract the fit indices reported by the 'OpenMx' result
> ### Aliases: extractOpenMxFit
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("extractVectorNames")
> ### * extractVectorNames
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: extractVectorNames
> ### Title: Extract a vector of parameter names based on specified elements
> ### Aliases: extractVectorNames
> 
> ### ** Examples
> 
> # The function is not public
> 
> #vec <- c("TY1", "TY2", "TY3", "TY4", "TY5", "TY6", "TY7")
> #extractVectorNames(vec, 5:6)
> 
> 
> 
> cleanEx()
> nameEx("fillParam")
> ### * fillParam
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fillParam
> ### Title: Fill in other objects based on the parameter values of current
> ###   objects
> ### Aliases: fillParam
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("findFactorIntercept")
> ### * findFactorIntercept
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findFactorIntercept
> ### Title: Find factor intercept from regression coefficient matrix and
> ###   factor total means
> ### Aliases: findFactorIntercept
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- 0.6
> path[5, 2] <- path[8, 5] <- 0.6
> path[6, 3] <- path[9, 6] <- 0.6
> path[5, 1] <- path[8, 4] <- 0.4
> path[6, 2] <- path[9, 5] <- 0.4
> factorMean <- c(5, 2, 3, 0, 0, 0, 0, 0, 0)
> findFactorIntercept(path, factorMean)
[1]  5.0  2.0  3.0 -3.0 -3.2 -2.6  0.0  0.0  0.0
> 
> 
> 
> cleanEx()
> nameEx("findFactorMean")
> ### * findFactorMean
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findFactorMean
> ### Title: Find factor total means from regression coefficient matrix and
> ###   factor intercept
> ### Aliases: findFactorMean
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- 0.6
> path[5, 2] <- path[8, 5] <- 0.6
> path[6, 3] <- path[9, 6] <- 0.6
> path[5, 1] <- path[8, 4] <- 0.4
> path[6, 2] <- path[9, 5] <- 0.4
> intcept <- c(5, 2, 3, 0, 0, 0, 0, 0, 0)
> findFactorMean(path, intcept)
[1] 5.00 2.00 3.00 3.00 3.20 2.60 1.80 3.12 2.84
> 
> 
> 
> cleanEx()
> nameEx("findFactorResidualVar")
> ### * findFactorResidualVar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findFactorResidualVar
> ### Title: Find factor residual variances from regression coefficient
> ###   matrix, factor (residual) correlations, and total factor variances
> ### Aliases: findFactorResidualVar
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- 0.6
> path[5, 2] <- path[8, 5] <- 0.6
> path[6, 3] <- path[9, 6] <- 0.6
> path[5, 1] <- path[8, 4] <- 0.4
> path[6, 2] <- path[9, 5] <- 0.4
> facCor <- diag(9)
> facCor[1, 2] <- facCor[2, 1] <- 0.4
> facCor[1, 3] <- facCor[3, 1] <- 0.4
> facCor[2, 3] <- facCor[3, 2] <- 0.4
> totalVar <- rep(1, 9)
> findFactorResidualVar(path, facCor, totalVar)
[1] 1.00000 1.00000 1.00000 0.64000 0.28800 0.28800 0.64000 0.29568 0.21888
> 
> 
> 
> cleanEx()
> nameEx("findFactorTotalCov")
> ### * findFactorTotalCov
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findFactorTotalCov
> ### Title: Find factor total covariance from regression coefficient matrix,
> ###   factor residual covariance
> ### Aliases: findFactorTotalCov
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- 0.6
> path[5, 2] <- path[8, 5] <- 0.6
> path[6, 3] <- path[9, 6] <- 0.6
> path[5, 1] <- path[8, 4] <- 0.4
> path[6, 2] <- path[9, 5] <- 0.4
> facCor <- diag(9)
> facCor[1, 2] <- facCor[2, 1] <- 0.4
> facCor[1, 3] <- facCor[3, 1] <- 0.4
> facCor[2, 3] <- facCor[3, 2] <- 0.4
> residualVar <- c(1, 1, 1, 0.64, 0.288, 0.288, 0.64, 0.29568, 0.21888)
> findFactorTotalCov(path, corPsi=facCor, errorVarPsi=residualVar)
       [,1]  [,2]  [,3]   [,4]   [,5]   [,6]    [,7]    [,8]    [,9]
 [1,] 1.000 0.400 0.400 0.6000 0.6400 0.4000 0.36000 0.62400 0.49600
 [2,] 0.400 1.000 0.400 0.2400 0.7600 0.6400 0.14400 0.55200 0.68800
 [3,] 0.400 0.400 1.000 0.2400 0.4000 0.7600 0.14400 0.33600 0.61600
 [4,] 0.600 0.240 0.240 1.0000 0.3840 0.2400 0.60000 0.63040 0.29760
 [5,] 0.640 0.760 0.400 0.3840 1.0000 0.5440 0.23040 0.75360 0.72640
 [6,] 0.400 0.640 0.760 0.2400 0.5440 1.0000 0.14400 0.42240 0.81760
 [7,] 0.360 0.144 0.144 0.6000 0.2304 0.1440 1.00000 0.37824 0.17856
 [8,] 0.624 0.552 0.336 0.6304 0.7536 0.4224 0.37824 1.00000 0.55488
 [9,] 0.496 0.688 0.616 0.2976 0.7264 0.8176 0.17856 0.55488 1.00000
> 
> 
> 
> cleanEx()
> nameEx("findFactorTotalVar")
> ### * findFactorTotalVar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findFactorTotalVar
> ### Title: Find factor total variances from regression coefficient matrix,
> ###   factor (residual) correlations, and factor residual variances
> ### Aliases: findFactorTotalVar
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- 0.6
> path[5, 2] <- path[8, 5] <- 0.6
> path[6, 3] <- path[9, 6] <- 0.6
> path[5, 1] <- path[8, 4] <- 0.4
> path[6, 2] <- path[9, 5] <- 0.4
> facCor <- diag(9)
> facCor[1, 2] <- facCor[2, 1] <- 0.4
> facCor[1, 3] <- facCor[3, 1] <- 0.4
> facCor[2, 3] <- facCor[3, 2] <- 0.4
> residualVar <- c(1, 1, 1, 0.64, 0.288, 0.288, 0.64, 0.29568, 0.21888)
> findFactorTotalVar(path, facCor, residualVar)
[1] 1 1 1 1 1 1 1 1 1
> 
> 
> 
> cleanEx()
> nameEx("findIndIntercept")
> ### * findIndIntercept
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findIndIntercept
> ### Title: Find indicator intercepts from factor loading matrix, total
> ###   factor mean, and indicator mean.
> ### Aliases: findIndIntercept
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- c(0.6, 0.7, 0.8)
> loading[4:6, 2] <- c(0.6, 0.7, 0.8)
> facMean <- c(0.5, 0.2)
> indMean <- rep(1, 6)
> findIndIntercept(loading, facMean, indMean)
[1] 0.70 0.65 0.60 0.88 0.86 0.84
> 
> 
> 
> cleanEx()
> nameEx("findIndMean")
> ### * findIndMean
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findIndMean
> ### Title: Find indicator total means from factor loading matrix, total
> ###   factor mean, and indicator intercept.
> ### Aliases: findIndMean
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- c(0.6, 0.7, 0.8)
> loading[4:6, 2] <- c(0.6, 0.7, 0.8)
> facMean <- c(0.5, 0.2)
> intcept <- rep(0, 6)
> findIndMean(loading, facMean, intcept)
[1] 0.30 0.35 0.40 0.12 0.14 0.16
> 
> 
> 
> cleanEx()
> nameEx("findIndResidualVar")
> ### * findIndResidualVar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findIndResidualVar
> ### Title: Find indicator residual variances from factor loading matrix,
> ###   total factor covariance, and total indicator variances.
> ### Aliases: findIndResidualVar
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- c(0.6, 0.7, 0.8)
> loading[4:6, 2] <- c(0.6, 0.7, 0.8)
> facCov <- matrix(c(1, 0.5, 0.5, 1), 2, 2)
> totalVar <- rep(1, 6)
> findIndResidualVar(loading, facCov, totalVar)
[1] 0.64 0.51 0.36 0.64 0.51 0.36
> 
> 
> 
> cleanEx()
> nameEx("findIndTotalVar")
> ### * findIndTotalVar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findIndTotalVar
> ### Title: Find indicator total variances from factor loading matrix, total
> ###   factor covariance, and indicator residual variances.
> ### Aliases: findIndTotalVar
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- c(0.6, 0.7, 0.8)
> loading[4:6, 2] <- c(0.6, 0.7, 0.8)
> facCov <- matrix(c(1, 0.5, 0.5, 1), 2, 2)
> resVar <- c(0.64, 0.51, 0.36, 0.64, 0.51, 0.36)
> findIndTotalVar(loading, facCov, resVar)
[1] 1 1 1 1 1 1
> 
> 
> 
> cleanEx()
> nameEx("findPossibleFactorCor")
> ### * findPossibleFactorCor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findPossibleFactorCor
> ### Title: Find the appropriate position for freely estimated correlation
> ###   (or covariance) given a regression coefficient matrix
> ### Aliases: findPossibleFactorCor
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- NA
> path[5, 2] <- path[8, 5] <- NA
> path[6, 3] <- path[9, 6] <- NA
> path[5, 1] <- path[8, 4] <- NA
> path[6, 2] <- path[9, 5] <- NA
> findPossibleFactorCor(path)
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
 [1,]    1   NA   NA    0    0    0    0    0    0
 [2,]   NA    1   NA    0    0    0    0    0    0
 [3,]   NA   NA    1    0    0    0    0    0    0
 [4,]    0    0    0    1   NA   NA    0    0    0
 [5,]    0    0    0   NA    1   NA    0    0    0
 [6,]    0    0    0   NA   NA    1    0    0    0
 [7,]    0    0    0    0    0    0    1   NA   NA
 [8,]    0    0    0    0    0    0   NA    1   NA
 [9,]    0    0    0    0    0    0   NA   NA    1
> 
> 
> 
> cleanEx()
> nameEx("findRecursiveSet")
> ### * findRecursiveSet
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findRecursiveSet
> ### Title: Group variables regarding the position in mediation chain
> ### Aliases: findRecursiveSet
> 
> ### ** Examples
> 
> path <- matrix(0, 9, 9)
> path[4, 1] <- path[7, 4] <- NA
> path[5, 2] <- path[8, 5] <- NA
> path[6, 3] <- path[9, 6] <- NA
> path[5, 1] <- path[8, 4] <- NA
> path[6, 2] <- path[9, 5] <- NA
> findRecursiveSet(path)
[[1]]
[1] 1 2 3

[[2]]
[1] 4 5 6

[[3]]
[1] 7 8 9

> 
> 
> 
> cleanEx()
> nameEx("findRowZero")
> ### * findRowZero
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findRowZero
> ### Title: Find rows in a matrix that all elements are zero in non-fixed
> ###   subset rows and columns.
> ### Aliases: findRowZero
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("fitMeasuresChi")
> ### * fitMeasuresChi
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fitMeasuresChi
> ### Title: Find fit indices from the discrepancy values of the target model
> ###   and null models.
> ### Aliases: fitMeasuresChi
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("freeVector")
> ### * freeVector
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: freeVector
> ### Title: Create a free parameters vector with a starting values in a
> ###   vector object
> ### Aliases: freeVector
> 
> ### ** Examples
> 
> # This function is not a public function.
> 
> # freeVector(0, 5)
> 
> 
> 
> cleanEx()
> nameEx("getCutoff")
> ### * getCutoff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: getCutoff
> ### Title: Find cutoff given a priori alpha level
> ### Aliases: getCutoff getCutoff-methods getCutoff,data.frame-method
> ###   getCutoff,matrix-method getCutoff,SimResult-method
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 200)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(5, SimData, SimModel)
> getCutoff(Output, 0.05)
         Chi          AIC          BIC        RMSEA          CFI          TLI 
8.159094e+00 3.244780e+03 3.307448e+03 9.952914e-03 9.994983e-01 9.990594e-01 
        SRMR 
2.870706e-02 
> 
> 
> 
> cleanEx()
> nameEx("getKeywords")
> ### * getKeywords
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: getKeywords
> ### Title: List of all keywords used in the 'simsem' package
> ### Aliases: getKeywords
> 
> ### ** Examples
> 
> # This function is not a public function.
> 
> # getKeywords()
> 
> 
> 
> cleanEx()
> nameEx("getPopulation")
> ### * getPopulation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: getPopulation
> ### Title: Extract the data generation population model underlying an
> ###   object
> ### Aliases: getPopulation getPopulation-methods getPopulation,ANY-method
> 
> ### ** Examples
> 
> # See each class for an example.
> 
> 
> 
> cleanEx()
> nameEx("getPower")
> ### * getPower
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: getPower
> ### Title: Find power in rejecting alternative models based on fit indices
> ###   criteria
> ### Aliases: getPower getPower-methods getPower,data.frame-method
> ###   getPower,matrix-method getPower,SimResult-method
> 
> ### ** Examples
> 
> loading.null <- matrix(0, 6, 1)
> loading.null[1:6, 1] <- NA
> LX.NULL <- simMatrix(loading.null, 0.7)
> RPH.NULL <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model.NULL <- simSetCFA(LY = LX.NULL, RPS = RPH.NULL, RTE = RTD)
> SimData.NULL <- simData(CFA.Model.NULL, 500)
> SimModel <- simModel(CFA.Model.NULL)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output.NULL <- simResult(5, SimData.NULL, SimModel)
> Cut.NULL <- getCutoff(Output.NULL, 0.95)
> 
> u79 <- simUnif(0.7, 0.9)
> loading.alt <- matrix(0, 6, 2)
> loading.alt[1:3, 1] <- NA
> loading.alt[4:6, 2] <- NA
> LX.ALT <- simMatrix(loading.alt, 0.7)
> latent.cor.alt <- matrix(NA, 2, 2)
> diag(latent.cor.alt) <- 1
> RPH.ALT <- symMatrix(latent.cor.alt, "u79")
> CFA.Model.ALT <- simSetCFA(LY = LX.ALT, RPS = RPH.ALT, RTE = RTD)
> SimData.ALT <- simData(CFA.Model.ALT, 500)
> Output.ALT <- simResult(5, SimData.ALT, SimModel)
> getPower(Output.ALT, Cut.NULL)
  Chi   CFI   TLI   AIC   BIC RMSEA  SRMR 
    1     1     1     1     1     1     1 
> Rule.of.thumb <- c(RMSEA=0.05, CFI=0.95, TLI=0.95, SRMR=0.06)
> getPower(Output.ALT, Rule.of.thumb, usedFit=c("RMSEA", "CFI", "TLI", "SRMR"))
  CFI   TLI RMSEA  SRMR 
  0.0   0.4   1.0   0.0 
> 
> 
> 
> cleanEx()
> nameEx("imposeMissing")
> ### * imposeMissing
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: imposeMissing
> ### Title: Impose MAR, MCAR, planned missingness, or attrition on a data
> ###   set
> ### Aliases: imposeMissing
> 
> ### ** Examples
> 
>   data <- matrix(rep(rnorm(10,1,1),19),ncol=19)
>   datac <- cbind(data,rnorm(10,0,1),rnorm(10,5,5))
>  
>   # Imposing Missing with the following arguments produces no missing values
>   imposeMissing(data)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
>   imposeMissing(data,cov=c(1,2))
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
>   imposeMissing(data,pmMCAR=0)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
>   imposeMissing(data,pmMAR=0)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
>   imposeMissing(data,nforms=0)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
> 
>   #Some more usage examples
>   imposeMissing(data,cov=c(1,2),pmMCAR=.1)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433        NA 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316        NA 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247        NA 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,]        NA 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,]        NA 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714        NA
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291        NA 1.4874291 1.4874291        NA
 [8,] 1.7383247 1.7383247        NA 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814        NA 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433        NA 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247        NA 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
>   
>  
>   imposeMissing(data,nforms=3)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462        NA        NA        NA
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433        NA        NA        NA
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714        NA        NA        NA
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,]        NA        NA 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,]        NA        NA 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,]        NA        NA 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808        NA        NA        NA        NA        NA
 [5,] 1.3295078 1.3295078        NA        NA        NA        NA        NA
 [6,] 0.1795316 0.1795316        NA        NA        NA        NA        NA
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,]        NA        NA        NA        NA        NA
 [8,]        NA        NA        NA        NA        NA
 [9,]        NA        NA        NA        NA        NA
[10,]        NA        NA        NA        NA        NA
>   imposeMissing(data,nforms=3,itemGroups=list(c(1,2,3,4,5),c(6,7,8,9,10),c(11,12,13,14,15),c(16,17,18,19)))
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462        NA        NA
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433        NA        NA
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714        NA        NA
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,]        NA        NA        NA 0.3735462 0.3735462 0.3735462 0.3735462
 [2,]        NA        NA        NA 1.1836433 1.1836433 1.1836433 1.1836433
 [3,]        NA        NA        NA 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808        NA        NA        NA        NA
 [5,] 1.3295078 1.3295078 1.3295078        NA        NA        NA        NA
 [6,] 0.1795316 0.1795316 0.1795316        NA        NA        NA        NA
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,]        NA 2.5952808 2.5952808 2.5952808 2.5952808
 [5,]        NA 1.3295078 1.3295078 1.3295078 1.3295078
 [6,]        NA 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291        NA        NA        NA        NA
 [8,] 1.7383247        NA        NA        NA        NA
 [9,] 1.5757814        NA        NA        NA        NA
[10,] 0.6946116        NA        NA        NA        NA
>   imposeMissing(datac,cov=c(20,21),nforms=3)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462        NA        NA        NA
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433        NA        NA        NA
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714        NA        NA        NA
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,]        NA        NA 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,]        NA        NA 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,]        NA        NA 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808        NA        NA        NA        NA        NA
 [5,] 1.3295078 1.3295078        NA        NA        NA        NA        NA
 [6,] 0.1795316 0.1795316        NA        NA        NA        NA        NA
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]       [,20]     [,21]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462  1.51178117  9.594887
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433  0.38984324  8.910682
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 -0.62124058  5.372825
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 -2.21469989 -4.946758
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078  1.12493092  8.099129
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 -0.04493361  4.719356
 [7,]        NA        NA        NA        NA        NA -0.01619026  4.221022
 [8,]        NA        NA        NA        NA        NA  0.94383621 -2.353762
 [9,]        NA        NA        NA        NA        NA  0.82122120  2.609250
[10,]        NA        NA        NA        NA        NA  0.59390132  7.089708
>   imposeMissing(data,twoMethod=c(19,.8))
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462        NA
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433        NA
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714        NA
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808        NA
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078        NA
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316        NA
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291        NA
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247        NA
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
>   imposeMissing(datac,cov=21,prAttr=.1,timePoints=5)
           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
 [1,] 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462 0.3735462
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
 [1,] 0.3735462        NA        NA        NA        NA        NA        NA
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808
 [5,] 1.3295078 1.3295078 1.3295078 1.3295078 1.3295078        NA        NA
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116
          [,15]     [,16]     [,17]     [,18]     [,19]       [,20]     [,21]
 [1,]        NA        NA        NA        NA        NA          NA  9.594887
 [2,] 1.1836433 1.1836433 1.1836433 1.1836433 1.1836433  0.38984324  8.910682
 [3,] 0.1643714 0.1643714 0.1643714 0.1643714 0.1643714 -0.62124058  5.372825
 [4,] 2.5952808 2.5952808 2.5952808 2.5952808 2.5952808 -2.21469989 -4.946758
 [5,]        NA        NA        NA        NA        NA          NA  8.099129
 [6,] 0.1795316 0.1795316 0.1795316 0.1795316 0.1795316 -0.04493361  4.719356
 [7,] 1.4874291 1.4874291 1.4874291 1.4874291 1.4874291 -0.01619026  4.221022
 [8,] 1.7383247 1.7383247 1.7383247 1.7383247 1.7383247  0.94383621 -2.353762
 [9,] 1.5757814 1.5757814 1.5757814 1.5757814 1.5757814  0.82122120  2.609250
[10,] 0.6946116 0.6946116 0.6946116 0.6946116 0.6946116  0.59390132  7.089708
> 
> 
> 
> 
> cleanEx()
> nameEx("indProd")
> ### * indProd
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: indProd
> ### Title: Make a product of indicators using mean centering or double-mean
> ###   centering
> ### Aliases: indProd
> 
> ### ** Examples
> 
> dat <- indProd(attitude[,-1], var1=1:3, var2=4:6)
> 
> 
> 
> cleanEx()
> nameEx("isCorMatrix")
> ### * isCorMatrix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isCorMatrix
> ### Title: Check whether a 'matrix' is a possible correlation matrix
> ### Aliases: isCorMatrix
> 
> ### ** Examples
> 
> # This function is not a public function.
> 
> # isCorMatrix(diag(5))
> 
> 
> 
> cleanEx()
> nameEx("isDefault")
> ### * isDefault
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isDefault
> ### Title: Check whether a vector object is default
> ### Aliases: isDefault
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("isMeanConstraint")
> ### * isMeanConstraint
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isMeanConstraint
> ### Title: Check whether all rownames in a constraint matrix containing
> ###   symbols of means vectors
> ### Aliases: isMeanConstraint
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("isNullObject")
> ### * isNullObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isNullObject
> ### Title: Check whether the object is the 'NULL' type of that class
> ### Aliases: isNullObject isNullObject-methods isNullObject,ANY,ANY-method
> ###   isNullObject,vector-method isNullObject,matrix-method
> ###   isNullObject,SimMatrix-method isNullObject,SymMatrix-method
> ###   isNullObject,SimVector-method isNullObject,SimSet-method
> ###   isNullObject,SimEqualCon-method isNullObject,SimREqualCon-method
> ###   isNullObject,SimMisspec-method isNullObject,VirtualRSet-method
> ###   isNullObject,data.frame-method isNullObject,SimMissing-method
> ###   isNullObject,SimDataDist-method isNullObject,SimFunction-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("isRandom")
> ### * isRandom
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isRandom
> ### Title: Check whether the object contains any random parameters
> ### Aliases: isRandom isRandom-methods isRandom,ANY-method
> ###   isRandom,SimMatrix-method isRandom,SimVector-method
> ###   isRandom,SimSet-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("isVarianceConstraint")
> ### * isVarianceConstraint
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: isVarianceConstraint
> ### Title: Check whether all rownames in a constraint matrix containing
> ###   symbols of variance vectors
> ### Aliases: isVarianceConstraint
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("kStat")
> ### * kStat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kStat
> ### Title: Calculate the _k_-statistic of a variable
> ### Aliases: kStat
> 
> ### ** Examples
> 
> # This function is not a public function.
> 
> # kStat(1:5, 4)
> 
> 
> 
> cleanEx()
> nameEx("kurtosis")
> ### * kurtosis
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kurtosis
> ### Title: Finding excessive kurtosis
> ### Aliases: kurtosis kurtosis-methods kurtosis,vector-method
> 
> ### ** Examples
> 
> kurtosis(1:5)
Excess Kur (g2)              se               z               p 
     -1.2000000       2.1908902      -0.5477226       0.5838824 
> 
> 
> 
> cleanEx()
> nameEx("loadingFromAlpha")
> ### * loadingFromAlpha
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: loadingFromAlpha
> ### Title: Find standardized factor loading from coefficient alpha
> ### Aliases: loadingFromAlpha
> 
> ### ** Examples
> 
>     loadingFromAlpha(0.8, 4)
[1] 0.7071068
> 
> 
> 
> cleanEx()
> nameEx("makeLabels")
> ### * makeLabels
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: makeLabels
> ### Title: Make parameter names for each element in matrices or vectors or
> ###   the name for the whole object
> ### Aliases: makeLabels makeLabels-methods makeLabels,ANY-method
> ###   makeLabels,vector-method makeLabels,matrix-method
> ###   makeLabels,SimParam-method makeLabels,VirtualDist-method
> ###   makeLabels,SimSet-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("matchKeywords")
> ### * matchKeywords
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: matchKeywords
> ### Title: Search for the keywords and check whether the specified text
> ###   match one in the name vector
> ### Aliases: matchKeywords
> 
> ### ** Examples
> 
> # This function is not a public function.
> 
> # matchKeywords("ly", c("LY", "LX"))
> 
> 
> 
> cleanEx()
> nameEx("miPool")
> ### * miPool
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: miPool
> ### Title: Function to pool imputed results
> ### Aliases: miPool
> 
> ### ** Examples
> 
> # No Example
> 
> 
> 
> cleanEx()
> nameEx("miPoolChi")
> ### * miPoolChi
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: miPoolChi
> ### Title: Function to pool chi-square statistics from the result from
> ###   multiple imputation
> ### Aliases: miPoolChi
> 
> ### ** Examples
> 
> miPoolChi(c(89.864, 81.116, 71.500, 49.022, 61.986, 64.422, 55.256, 57.890, 79.416, 63.944), 2)
           F          df1          df2          p.F 
1.981628e+01 2.000000e+00 4.616817e+01 6.122891e-07 
> 
> 
> 
> cleanEx()
> nameEx("miPoolVector")
> ### * miPoolVector
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: miPoolVector
> ### Title: Function to pool imputed results that saved in a matrix format
> ### Aliases: miPoolVector
> 
> ### ** Examples
> 
> param <- matrix(c(0.7, 0.1, 0.5,
+ 					0.75, 0.12, 0.54,
+ 					0.66, 0.11, 0.56,
+ 					0.74, 0.09, 0.55), nrow=4, byrow=TRUE)
> SE <- matrix(c(0.1, 0.01, 0.05,
+ 				0.11, 0.023, 0.055,
+ 				0.10, 0.005, 0.04,
+ 				0.14, 0.012, 0.039), nrow=4, byrow=TRUE)
> nimps <- 4
> miPoolVector(param, SE, nimps)
$coef
[1] 0.7125 0.1050 0.5375

$se
[1] 0.12263598 0.02019488 0.05500985

$FMI.1
[1] 0.1406012 0.5108296 0.2857104

$FMI.2
[1] 0.1517078 0.5783172 0.3216485

> 
> 
> 
> cleanEx()
> nameEx("overlapHist")
> ### * overlapHist
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: overlapHist
> ### Title: Plot overlapping histograms
> ### Aliases: overlapHist
> 
> ### ** Examples
> 
> # This function is not a public function.
> 
> # a <- rnorm(10000, 0, 1)
> # b <- rnorm(10000, 1, 1.5)
> # overlapHist(a, b, main="Example")
> 
> 
> 
> cleanEx()
> nameEx("pValue")
> ### * pValue
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pValue
> ### Title: Find p-values (1 - percentile)
> ### Aliases: pValue pValue-methods pValue,ANY-method
> ###   pValue,numeric,vector-method pValue,numeric,data.frame-method
> ###   pValue,SimModelOut,SimResult-method
> 
> ### ** Examples
> 
> # Compare number with a vector
> pValue(0.5, rnorm(1000, 0, 1))
[1] 0.685
> 
> # Compare numbers with a data frame
> pValue(c(0.5, 0.2), data.frame(rnorm(1000, 0, 1), runif(1000, 0, 1)))
[1] 0.691 0.186
> 
> # Compare an analysis result with a result of simulation study
> library(lavaan)
> loading <- matrix(0, 9, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 3] <- NA
> model <- simParamCFA(LY=loading)
> SimModel <- simModel(model, indLab=paste("x", 1:9, sep=""))
> u2 <- simUnif(-0.2, 0.2)
> loading.trivial <- matrix(NA, 9, 3)
> loading.trivial[is.na(loading)] <- 0
> LY.trivial <- simMatrix(loading.trivial, "u2")
> mis <- simMisspecCFA(LY = LY.trivial)
> out <- run(SimModel, HolzingerSwineford1939)
> Output2 <- runFit(out, HolzingerSwineford1939, 20, mis)
> pValue(out, Output2)
    Chi     AIC     BIC   RMSEA     CFI     TLI    SRMR andRule  orRule 
   0.45    0.00    0.00    0.45    0.40    0.40    0.55    0.00    0.60 
> 
> 
> 
> cleanEx()
> nameEx("plot3DQtile")
> ### * plot3DQtile
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot3DQtile
> ### Title: Build a persepctive plot or contour plot of a quantile of
> ###   predicted values
> ### Aliases: plot3DQtile
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("plotCutoff")
> ### * plotCutoff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotCutoff
> ### Title: Plot sampling distributions of fit indices
> ### Aliases: plotCutoff plotCutoff-methods plotCutoff,data.frame-method
> ###   plotCutoff,SimResult-method
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 200)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(5, SimData, SimModel)
> plotCutoff(Output, 0.05, usedFit=c("RMSEA", "SRMR", "CFI", "TLI"))
> 
> # Varying N
> Output2 <- simResult(NULL, SimData, SimModel, n=seq(50, 100, 10))
> plotCutoff(Output2, 0.05)
Loading required package: SparseM
Package SparseM (0.96) loaded.
	   To cite, see citation("SparseM")


Attaching package: 'SparseM'

The following object(s) are masked from 'package:base':

    backsolve

> 
> # Varying N and pmMCAR
> Output3 <- simResult(NULL, SimData, SimModel, n=seq(50, 100, 10), pmMCAR=c(0, 0.05, 0.1, 0.15))
> plotCutoff(Output3, 0.05)
> 
> 
> 
> cleanEx()

detaching 'package:splines', 'package:quantreg', 'package:SparseM'

> nameEx("plotDist")
> ### * plotDist
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotDist
> ### Title: Plot a distribution of a distribution object or data
> ###   distribution object
> ### Aliases: plotDist plotDist-methods
> 
> ### ** Examples
> 
> gamma11 <- simGamma(1, 1)
> plotDist(gamma11)
> 
> chi <- simChisq(5)
> dataDist <- simDataDist(chi, chi)
> plotDist(dataDist)
Loading required package: pspline
> 
> 
> 
> cleanEx()

detaching 'package:copula', 'package:pspline'

> nameEx("plotMisfit")
> ### * plotMisfit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotMisfit
> ### Title: Plot the population misfit in parameter result object
> ### Aliases: plotMisfit
> 
> ### ** Examples
> 
> u35 <- simUnif(0.3, 0.5)
> u57 <- simUnif(0.5, 0.7)
> u1 <- simUnif(-0.1, 0.1)
> n31 <- simNorm(0.3, 0.1)
> 
> path.BE <- matrix(0, 4, 4)
> path.BE[3, 1:2] <- NA
> path.BE[4, 3] <- NA
> starting.BE <- matrix("", 4, 4)
> starting.BE[3, 1:2] <- "u35"
> starting.BE[4, 3] <- "u57"
> BE <- simMatrix(path.BE, starting.BE)
> 
> residual.error <- diag(4)
> residual.error[1,2] <- residual.error[2,1] <- NA
> RPS <- symMatrix(residual.error, "n31")
> 
> ME <- simVector(rep(NA, 4), 0)
> 
> Path.Model <- simSetPath(RPS = RPS, BE = BE, ME = ME)
> 
> mis.path.BE <- matrix(0, 4, 4)
> mis.path.BE[4, 1:2] <- NA
> mis.BE <- simMatrix(mis.path.BE, "u1")
> Path.Mis.Model <- simMisspecPath(BE = mis.BE, misfitType="rmsea") #, misfitBound=c(0.05, 0.08))
> 
> # The number of replications in actual analysis should be much more than 5
> ParamObject <- simResultParam(20, Path.Model, Path.Mis.Model)
> plotMisfit(ParamObject)
> 
> plotMisfit(ParamObject, misParam=1:2)
> 
> 
> 
> cleanEx()
> nameEx("plotPower")
> ### * plotPower
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotPower
> ### Title: Plot sampling distributions of fit indices that visualize power
> ### Aliases: plotPower plotPower-methods
> ###   plotPower,data.frame,data.frame-method
> ###   plotPower,data.frame,vector-method
> ###   plotPower,SimResult,SimResult-method
> ###   plotPower,SimResult,vector-method
> 
> ### ** Examples
> 
> loading.null <- matrix(0, 6, 1)
> loading.null[1:6, 1] <- NA
> LX.NULL <- simMatrix(loading.null, 0.7)
> RPH.NULL <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model.NULL <- simSetCFA(LY = LX.NULL, RPS = RPH.NULL, RTE = RTD)
> SimData.NULL <- simData(CFA.Model.NULL, 500)
> SimModel <- simModel(CFA.Model.NULL)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output.NULL <- simResult(5, SimData.NULL, SimModel)
> Cut.NULL <- getCutoff(Output.NULL, 0.95)
> 
> u79 <- simUnif(0.7, 0.9)
> loading.alt <- matrix(0, 6, 2)
> loading.alt[1:3, 1] <- NA
> loading.alt[4:6, 2] <- NA
> LX.ALT <- simMatrix(loading.alt, 0.7)
> latent.cor.alt <- matrix(NA, 2, 2)
> diag(latent.cor.alt) <- 1
> RPH.ALT <- symMatrix(latent.cor.alt, "u79")
> CFA.Model.ALT <- simSetCFA(LY = LX.ALT, RPS = RPH.ALT, RTE = RTD)
> SimData.ALT <- simData(CFA.Model.ALT, 500)
> Output.ALT <- simResult(5, SimData.ALT, SimModel)
> getPower(Output.ALT, Cut.NULL)
  Chi   CFI   TLI   AIC   BIC RMSEA  SRMR 
    1     1     1     1     1     1     1 
> Rule.of.thumb <- c(RMSEA=0.05, CFI=0.95, TLI=0.95, SRMR=0.06)
> plotPower(Output.ALT, Output.NULL, alpha=0.05, usedFit=c("RMSEA", "CFI", "TLI", "SRMR"))
> 
> 
> 
> cleanEx()
> nameEx("plotQtile")
> ### * plotQtile
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotQtile
> ### Title: Build a scatterplot with overlaying line of quantiles of
> ###   predicted values
> ### Aliases: plotQtile
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("popDiscrepancy")
> ### * popDiscrepancy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: popDiscrepancy
> ### Title: Find the discrepancy value between two means and covariance
> ###   matrices
> ### Aliases: popDiscrepancy
> 
> ### ** Examples
> 
> m1 <- rep(0, 3)
> m2 <- c(0.1, -0.1, 0.05)
> S1 <- matrix(c(1, 0.6, 0.5, 0.6, 1, 0.4, 0.5, 0.4, 1), 3, 3)
> S2 <- matrix(c(1, 0.55, 0.55, 0.55, 1, 0.55, 0.55, 0.55, 1), 3, 3)
> popDiscrepancy(m1, S1, m2, S2)
         [,1]
[1,] 0.116864
> 
> 
> 
> cleanEx()
> nameEx("popMisfit")
> ### * popMisfit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: popMisfit
> ### Title: Calculate population misfit
> ### Aliases: popMisfit popMisfit-methods popMisfit,ANY,ANY-method
> ###   popMisfit,matrix,matrix-method popMisfit,list,list-method
> ###   popMisfit,SimRSet,SimRSet-method popMisfit,MatrixSet,MatrixSet-method
> ###   popMisfit,SimSet,SimMisspec-method
> 
> ### ** Examples
> 
> u35 <- simUnif(0.3, 0.5)
> u57 <- simUnif(0.5, 0.7)
> u1 <- simUnif(-0.1, 0.1)
> n31 <- simNorm(0.3, 0.1)
> 
> path.BE <- matrix(0, 4, 4)
> path.BE[3, 1:2] <- NA
> path.BE[4, 3] <- NA
> starting.BE <- matrix("", 4, 4)
> starting.BE[3, 1:2] <- "u35"
> starting.BE[4, 3] <- "u57"
> BE <- simMatrix(path.BE, starting.BE)
> 
> residual.error <- diag(4)
> residual.error[1,2] <- residual.error[2,1] <- NA
> RPS <- symMatrix(residual.error, "n31")
> 
> ME <- simVector(rep(NA, 4), 0)
> 
> Path.Model <- simSetPath(RPS = RPS, BE = BE, ME = ME)
> 
> mis.path.BE <- matrix(0, 4, 4)
> mis.path.BE[4, 1:2] <- NA
> mis.BE <- simMatrix(mis.path.BE, "u1")
> Path.Mis.Model <- simMisspecPath(BE = mis.BE, misfitType="rmsea") #, misfitBound=c(0.05, 0.08))
> 
> popMisfit(Path.Model, Path.Mis.Model, fit.measures="rmsea")
     rmsea 
0.07897849 
> 
> 
> 
> cleanEx()
> nameEx("popMisfitMACS")
> ### * popMisfitMACS
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: popMisfitMACS
> ### Title: Find population misfit by sufficient statistics
> ### Aliases: popMisfitMACS
> 
> ### ** Examples
> 
> m1 <- rep(0, 3)
> m2 <- c(0.1, -0.1, 0.05)
> S1 <- matrix(c(1, 0.6, 0.5, 0.6, 1, 0.4, 0.5, 0.4, 1), 3, 3)
> S2 <- matrix(c(1, 0.55, 0.55, 0.55, 1, 0.55, 0.55, 0.55, 1), 3, 3)
> popMisfitMACS(m1, S1, m2, S2)
        f0       srmr 
0.11686397 0.06770032 
> 
> 
> 
> cleanEx()
> nameEx("printIfNotNull")
> ### * printIfNotNull
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: printIfNotNull
> ### Title: Provide basic summary of each object if that object is not NULL.
> ### Aliases: printIfNotNull
> 
> ### ** Examples
> 
> # This function is not public
> 
> # AL <- simVector(rep(NA, 5), "0")
> # printIfNotNull(AL, "Factor mean")
> 
> 
> 
> cleanEx()
> nameEx("reassignNames")
> ### * reassignNames
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: reassignNames
> ### Title: Reassign the name of equality constraint
> ### Aliases: reassignNames
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("reduceConstraint")
> ### * reduceConstraint
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: reduceConstraint
> ### Title: Reduce the model constraint to data generation parameterization
> ###   to analysis model parameterization.
> ### Aliases: reduceConstraint
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("reduceMatrices")
> ### * reduceMatrices
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: reduceMatrices
> ### Title: Reduce the model constraint to data generation parameterization
> ###   to analysis model parameterization.
> ### Aliases: reduceMatrices
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("residualCovariate")
> ### * residualCovariate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residualCovariate
> ### Title: Residual centered all target indicators by covariates
> ### Aliases: residualCovariate
> 
> ### ** Examples
> 
> dat <- residualCovariate(attitude, 2:7, 1)
> 
> 
> 
> cleanEx()
> nameEx("run")
> ### * run
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: run
> ### Title: Run a particular object in 'simsem' package.
> ### Aliases: run run-methods run,ANY-method run,NullSimMatrix-method
> ###   run,NullSymMatrix-method run,NullSimVector-method
> ### Keywords: run
> 
> ### ** Examples
> 
> n02 <- simNorm(0, 0.2)
> run(n02)
[1] -0.1252908
> 
> 
> 
> cleanEx()
> nameEx("runFit")
> ### * runFit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: runFit
> ### Title: Build a result object from analyzing real data
> ### Aliases: runFit runFit-methods runFit,ANY-method runFit,SimModel-method
> ###   runFit,SimModelOut-method
> 
> ### ** Examples
> 
> library(lavaan)
> loading <- matrix(0, 9, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 3] <- NA
> model <- simParamCFA(LY=loading)
> SimModel <- simModel(model, indLab=paste("x", 1:9, sep=""))
> u2 <- simUnif(-0.2, 0.2)
> loading.trivial <- matrix(NA, 9, 3)
> loading.trivial[is.na(loading)] <- 0
> LY.trivial <- simMatrix(loading.trivial, "u2")
> mis <- simMisspecCFA(LY = LY.trivial)
> Output <- runFit(SimModel, HolzingerSwineford1939, 5, mis)
> summary(Output)
RESULT OBJECT
Model Type
[1] "CFA"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi    117.491  131.797  143.242  145.817
      AIC   7057.128 7072.925 7085.563 7088.406
      BIC   7168.341 7184.138 7196.776 7199.619
      RMSEA    0.111    0.121    0.128    0.130
      CFI      0.894    0.881    0.871    0.869
      TLI      0.841    0.822    0.807    0.803
      SRMR     0.075    0.079    0.082    0.083
========= Parameter Estimates and Standard Errors ============
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0. Std.Est
LY1_1            0.932       0.133      0.091                 1.0   0.902
LY2_1            0.359       0.183      0.062                 1.0   0.355
LY3_1            0.416       0.115      0.064                 1.0   0.425
LY4_2            0.793       0.132      0.050                 1.0   0.802
LY5_2            0.819       0.104      0.050                 1.0   0.819
LY6_2            0.855       0.110      0.051                 1.0   0.838
LY7_3            0.645       0.107      0.066                 1.0   0.614
LY8_3            0.680       0.203      0.065                 1.0   0.664
LY9_3            0.683       0.096      0.063                 1.0   0.692
PS2_1            0.448       0.110      0.066                 1.0   0.448
PS3_1            0.446       0.185      0.070                 1.0   0.446
PS3_2            0.242       0.261      0.067                 0.6   0.242
TE1_1            0.185       0.194      0.152                 0.4   0.178
TE2_2            0.833       0.079      0.073                 1.0   0.852
TE3_3            0.773       0.125      0.069                 1.0   0.810
TE4_4            0.331       0.052      0.040                 1.0   0.353
TE5_5            0.318       0.095      0.041                 1.0   0.326
TE6_6            0.302       0.038      0.041                 1.0   0.297
TE7_7            0.676       0.110      0.073                 1.0   0.616
TE8_8            0.538       0.099      0.070                 1.0   0.547
TE9_9            0.498       0.051      0.066                 1.0   0.519
TY1              3.344       0.078      0.110                 1.0   3.250
TY2              4.734       0.118      0.085                 1.0   4.777
TY3              1.489       0.089      0.085                 1.0   1.526
TY4              1.689       0.143      0.075                 1.0   1.723
TY5              2.502       0.176      0.076                 1.0   2.507
TY6              1.153       0.090      0.078                 1.0   1.139
TY7              3.325       0.091      0.090                 1.0   3.169
TY8              4.732       0.183      0.087                 1.0   4.740
TY9              4.603       0.180      0.085                 1.0   4.687
      Std.Est.SD Average.Param Average.Bias Coverage
LY1_1      0.103         0.772        0.161      0.4
LY2_1      0.164         0.424       -0.065      0.2
LY3_1      0.111         0.581       -0.165      0.2
LY4_2      0.063         0.852       -0.058      0.4
LY5_2      0.072         0.855       -0.036      0.6
LY6_2      0.037         0.838        0.017      0.8
LY7_3      0.095         0.570        0.076      0.8
LY8_3      0.127         0.723       -0.044      0.4
LY9_3      0.055         0.665        0.018      0.8
PS2_1      0.110         0.459       -0.010      0.8
PS3_1      0.185         0.471       -0.025      0.6
PS3_2      0.261         0.283       -0.041      0.2
TE1_1      0.186         0.404       -0.219      0.8
TE2_2      0.129         0.821        0.013      1.0
TE3_3      0.110         0.662        0.110      0.8
TE4_4      0.101         0.275        0.056      0.6
TE5_5      0.117         0.269        0.050      0.6
TE6_6      0.062         0.298        0.005      1.0
TE7_7      0.111         0.676        0.000      0.8
TE8_8      0.162         0.477        0.061      0.8
TE9_9      0.077         0.558       -0.060      1.0
TY1        0.221         3.463       -0.119      1.0
TY2        0.273         4.756       -0.022      0.8
TY3        0.103         1.412        0.077      1.0
TY4        0.161         1.782       -0.093      0.4
TY5        0.153         2.514       -0.012      0.6
TY6        0.142         1.160       -0.008      1.0
TY7        0.063         3.279        0.046      0.8
TY8        0.539         4.744       -0.012      0.4
TY9        0.149         4.669       -0.067      0.6
========= Correlation between Fit Indices ============
         Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR
Chi    1.000  0.836  0.836  0.996 -0.988 -0.988  0.921
AIC    0.836  1.000  1.000  0.849 -0.872 -0.872  0.980
BIC    0.836  1.000  1.000  0.849 -0.872 -0.872  0.980
RMSEA  0.996  0.849  0.849  1.000 -0.990 -0.990  0.924
CFI   -0.988 -0.872 -0.872 -0.990  1.000  1.000 -0.946
TLI   -0.988 -0.872 -0.872 -0.990  1.000  1.000 -0.946
SRMR   0.921  0.980  0.980  0.924 -0.946 -0.946  1.000
================== Replications =====================
Number of Replications
[1] 5
Number of Converged Replications
[1] 5
> 
> out <- run(SimModel, HolzingerSwineford1939)
> Output2 <- runFit(out, HolzingerSwineford1939, 5, mis)
> 
> # Bollen-Stine Bootstrap
> Output3 <- runFit(out, HolzingerSwineford1939, 5, modelBoot=TRUE)
> 
> # Bollen-Stine Bootstrap with trivial misspecification
> Output4 <- runFit(out, HolzingerSwineford1939, 5, mis, modelBoot=TRUE)
> 
> # Example with multiple imputation
> library(lavaan)
> loading <- matrix(0, 11, 3)
> loading[1:3, 1] <- NA
> loading[4:7, 2] <- NA
> loading[8:11, 3] <- NA
> path <- matrix(0, 3, 3)
> path[2:3, 1] <- NA
> path[3, 2] <- NA
> errorCov <- diag(NA, 11)
> facCov <- diag(3)
> param <- simParamSEM(LY=loading, BE=path, TE=errorCov, PS=facCov)
> 
> miss <- simMissing(pmMCAR=0.03, numImps=5)
> usedData <- run(miss, PoliticalDemocracy)
> 
> model <- simModel(param, indLab=c(paste("x", 1:3, sep=""), paste("y", 1:8, sep="")))
> out <- run(model, usedData, miss)
Loading required package: Amelia
Loading required package: foreign
## 
## Amelia II: Multiple Imputation
## (Version 1.6.1, built: 2012-03-29)
## Copyright (C) 2005-2012 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 
> output <- runFit(model, usedData, 5, missModel=miss)
> pValue(out, output)
    Chi     AIC     BIC   RMSEA     CFI     TLI    SRMR andRule  orRule 
      0       0       0       0       0       0       0       0       0 
> 
> 
> 
> cleanEx()

detaching 'package:Amelia', 'package:foreign'

> nameEx("runLavaan")
> ### * runLavaan
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: runLavaan
> ### Title: Run data by the model object by the 'lavaan' package
> ### Aliases: runLavaan
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("runMI")
> ### * runMI
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: runMI
> ### Title: Multiply impute and analyze data using lavaan
> ### Aliases: runMI
> 
> ### ** Examples
> 
> ##---- Should be DIRECTLY executable !! ----
> ##-- ==>  Define data, use random,
> ##--	or do  help(data=index)  for the standard data sets.
> 
> ## The function is currently defined as
> function(data.mat,data.model,imps) {
+   #Impute missing data
+   imputed.l<-imputeMissing(data.mat,imps)
+   
+   #Run models on each imputed data set
+   #Does this give results from each dataset in the list?
+   
+   imputed.results<-result.object(imputed.l[[1]],sim.data.model,10)
+ 
+   imputed.results <- lapply(imputed.l,result.object,data.model,1)
+   comb.results<-MIpool(imputed.results,imps)
+   
+   return(comb.results)
+ 
+   }
function (data.mat, data.model, imps) 
{
    imputed.l <- imputeMissing(data.mat, imps)
    imputed.results <- result.object(imputed.l[[1]], sim.data.model, 
        10)
    imputed.results <- lapply(imputed.l, result.object, data.model, 
        1)
    comb.results <- MIpool(imputed.results, imps)
    return(comb.results)
}
> 
> 
> 
> cleanEx()
> nameEx("runMisspec")
> ### * runMisspec
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: runMisspec
> ### Title: Draw actual parameters and model misspecification
> ### Aliases: runMisspec
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("runRep")
> ### * runRep
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: runRep
> ### Title: Run one replication within a big simulation study
> ### Aliases: runRep
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("setOpenMxObject")
> ### * setOpenMxObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: setOpenMxObject
> ### Title: Rearrange starting values for 'OpenMx'
> ### Aliases: setOpenMxObject setOpenMxObject-methods
> ###   setOpenMxObject,ANY,ANY-method setOpenMxObject,vector,vector-method
> ###   setOpenMxObject,matrix,matrix-method
> ###   setOpenMxObject,SimParam,SimRSet-method
> 
> ### ** Examples
> 
> # This function is not public
> 
> # parameter <- c(NA, NA, 0, 0)
> # startingValues <- c(2, 5, 0, 0)
> # setOpenMxObject(parameter, startingValues)
> 
> 
> 
> cleanEx()
> nameEx("setPopulation")
> ### * setPopulation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: setPopulation
> ### Title: Set the data generation population model underlying an object
> ### Aliases: setPopulation setPopulation-methods setPopulation,ANY-method
> 
> ### ** Examples
> 
> # See each class for an example.
> 
> 
> 
> cleanEx()
> nameEx("simBeta")
> ### * simBeta
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simBeta
> ### Title: Create random beta distribution object
> ### Aliases: simBeta
> 
> ### ** Examples
> 
>     b11 <- simBeta(1, 1)
>     run(b11)
[1] 0.7344913
> 
> 
> 
> cleanEx()
> nameEx("simBinom")
> ### * simBinom
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simBinom
> ### Title: Create random binomial distribution object
> ### Aliases: simBinom
> 
> ### ** Examples
> 
>     b55 <- simBinom(5, 0.5)
>     run(b55)
[1] 2
> 	summary(b55)
[1] "Random Binomial Distribution Object."
[1] "Number of trials is 5."
[1] "Probability of success is 0.5."
> 
> 
> 
> cleanEx()
> nameEx("simCauchy")
> ### * simCauchy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simCauchy
> ### Title: Create random Cauchy distribution object
> ### Aliases: simCauchy
> 
> ### ** Examples
> 
>     c02 <- simCauchy(0, 2)
>     run(c02)
[1] 2.20504
> 	summary(c02)
[1] "Random Cauchy Distribution Object."
[1] "Location parameter is 0."
[1] "Scale parameter is 2."
> 
> 
> 
> cleanEx()
> nameEx("simChisq")
> ### * simChisq
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simChisq
> ### Title: Create random chi-squared distribution object
> ### Aliases: simChisq
> 
> ### ** Examples
> 
>     chi5 <- simChisq(5)
>     run(chi5)
[1] 2.424343
> 	summary(chi5)
[1] "Random Chi-squared Distribution Object."
[1] "Degree of freedom is 5."
[1] "Non-centrality parameter is 0."
> 
> 
> 
> cleanEx()
> nameEx("simData")
> ### * simData
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simData
> ### Title: Data object
> ### Aliases: simData simData-methods simData,ANY-method
> ###   simData,SimSet-method simData,SimModelOut-method
> ###   simData,SimRSet-method
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 200)
> summary(SimData)
DATA OBJECT
Model Type
[1] "CFA"
Sample Size
[1] 200
========= Parameters Set ============
SET OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]     [,2]    
[1,] "NA:0.7" "0"     
[2,] "NA:0.7" "0"     
[3,] "NA:0.7" "0"     
[4,] "0"      "NA:0.7"
[5,] "0"      "NA:0.7"
[6,] "0"      "NA:0.7"

RTE: Correlation of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] "1"  "0"  "0"  "0"  "0"  "0" 
[2,] "0"  "1"  "0"  "0"  "0"  "0" 
[3,] "0"  "0"  "1"  "0"  "0"  "0" 
[4,] "0"  "0"  "0"  "1"  "0"  "0" 
[5,] "0"  "0"  "0"  "0"  "1"  "0" 
[6,] "0"  "0"  "0"  "0"  "0"  "1" 

VY: Variance of Indicator.Y 
[1] "NA:1" "NA:1" "NA:1" "NA:1" "NA:1" "NA:1"

TY: Measurement Intercept of Indicator.Y 
[1] "NA:0" "NA:0" "NA:0" "NA:0" "NA:0" "NA:0"

VPS: Variance of Regression.Residual.PSI 
[1] "1" "1"

RPS: Correlation of Regression.Residual.PSI 
     [,1]     [,2]    
[1,] "1"      "NA:0.5"
[2,] "NA:0.5" "1"     

VE: Variance of Factor.ETA 
[1] "1" "1"

AL: Regression Intercept of Factor.ETA 
[1] "0" "0"

ME: mean of Factor.ETA 
[1] "0" "0"
-------------------------- 
Number of free parameters =  19 
=====================================
Adding Misspecification?
[1] "No"
Adding Constraint?
[1] "No"
Maximum Random Sampling Parameters
[1] 100
> run(SimData)
               y1          y2           y3           y4           y5
1   -0.8045405678 -1.07615375  0.057008974 -0.902462922 -0.420303205
2    0.1846928903 -1.52519893 -0.596848908 -0.360271862  0.655075424
3   -0.9818489653 -1.00020156 -1.872460732  0.547424678  0.455643551
4    1.5595324860  0.98242927  1.129591494  1.133175506  0.771936669
5    1.1845695532  1.29080775  1.312506730 -0.614798923 -1.246842377
6   -2.4256570718 -0.52391592 -2.119384992  0.801634881  0.447980202
7   -0.8026409861 -0.01211317  0.886817943  0.874982013  0.264254397
8    0.0563541774  1.26607638 -0.572218116  0.960753031  1.193425123
9    1.4677564715  0.51392041 -0.801413687 -0.485506296  1.285396956
10  -0.2799641994 -0.93132978 -0.102089434  0.318816637 -1.065786453
11   1.1792430190  1.32162096  0.774606605  1.177173143  0.997041766
12   0.2512034453  0.06410751 -0.103496897  0.112998515  1.030275697
13  -0.5563709849  0.67445625 -0.824812638 -1.216554530  0.178167961
14  -1.7843904375  0.36259070 -1.175083029 -1.812722455 -3.445337824
15   1.8844962672 -0.52205666 -0.442225197  1.403045471  0.909652448
16  -0.9452810102 -0.62387834 -0.598349054  0.507410773  1.772555524
17  -0.0831099570  0.47046975  0.001881615 -0.684020271  0.600954470
18   0.0667599058  2.43207667  1.118568015  0.128168047 -0.759673520
19   0.0624300206  0.98647272 -0.269307069  1.547295847 -0.375973318
20   0.3418543450 -0.62490267  1.542665030 -0.535117264  1.106608185
21   1.1985632899  1.64210058  1.382428213 -1.009453441  0.262620519
22  -0.4294336414  0.51578927  1.489116211  1.073752569  0.686141945
23   1.4200746408 -0.52870595  0.120453095 -0.224536426 -0.155962968
24  -0.0705158002 -2.01187265 -1.466254278 -0.516334770 -2.101005185
25   1.3465994213  0.60673251  0.878034808 -0.444133582  0.161716811
26  -1.6017729664  0.05337596 -1.028983927 -0.120399156  1.479385138
27   0.4261412395  0.47207405 -0.760103948  0.564006789 -1.367508121
28  -0.2861057055 -0.70022762  0.212329374 -1.088102173 -0.935558478
29  -0.6774881190  0.42716566 -0.984082865  0.031142318 -1.051034032
30   0.9965878126 -0.44682030 -0.065989857  0.757599491  0.133966644
31   0.6690459148  1.98420225  1.435822722  1.633619512 -0.474452981
32   0.9584993506  1.49351309  1.288455423 -1.539705118 -0.355642036
33   0.1559852255  1.10912317  0.392489723  0.935602005 -0.058764218
34  -0.3086738117 -0.15275306 -0.426789831  0.194940236 -0.036323861
35  -1.7789568229 -0.98729507  0.068901395 -1.217656769 -0.696235716
36  -0.5865292974 -0.35461815  0.237837966 -0.099006066  0.126147956
37  -0.0900499230 -0.68642407 -0.785618330 -0.397217992  1.353802246
38   0.8217290574 -0.08617487  0.766121687 -0.546177050 -0.488701706
39  -0.2473621503 -0.33824834  1.306692499  1.598719049  0.448719261
40   0.7983910651  0.42456011  0.324473731  0.051228612  0.280284611
41  -1.7603689925 -0.17502680  0.636793969  0.686794776  0.965569964
42  -0.9235552750 -0.61617026 -0.384744863 -0.851671459 -0.058583975
43   0.8035345795  0.56088663 -0.263319249  0.754475137  2.033251767
44   0.3159403170  1.43200531  0.576236087 -0.529733049  0.192023403
45  -0.9343279406 -1.97436664 -0.070511142 -0.052742647 -0.164001262
46  -0.3556720991  0.37385555  1.287415951  0.427171005 -2.407145230
47   1.0826342292 -0.14211513  0.539715172  0.835172718 -0.077930462
48  -0.4128817647  0.99913523  1.314070137  0.728565750  0.382448273
49  -0.2157477195 -0.08399579  0.300039152 -0.405477056 -1.002169861
50   0.0619598370  0.10797140  0.213652275  2.446380196  0.397848746
51   0.2265662511  0.14138723  0.249285474 -0.196041332  0.872641544
52  -1.0308668478 -0.53998194 -0.220668169  0.198722579 -0.142478281
53   1.2684252196  0.39667291 -0.881515883  0.486765092 -0.492598325
54  -1.3671094745 -1.43683369  0.863288621 -0.054377978 -2.633850400
55   0.8681587718  0.18662850  0.886601631  2.102684710  0.585945042
56  -0.9306844795  1.71026113  1.650561104  1.847472340  1.439959863
57   0.8775331332  0.24194873  1.423436446 -1.670377316 -1.577584671
58  -0.6623350406 -0.70034460 -1.527115423  0.678702769 -1.585447109
59  -0.3114747365 -0.39640737  1.345515884  1.168227022 -0.064305301
60   0.4693003554  0.14868310 -0.309373532 -0.644550315 -0.222430918
61   1.2892242893  2.28783246 -0.030108233  2.319081697  2.371326500
62   0.7473376784 -0.86750928  0.572901489 -1.397225560  0.947577450
63   0.1075219190  0.23528599  1.437672545 -0.395683617  0.343749379
64  -0.9973491594  0.28584536 -0.403692843  0.063307132  0.507613256
65  -2.3728066858 -0.12220489 -1.354928719  0.340955897  0.515665189
66  -0.2500954183  0.98076769 -0.718728765  0.167447035  1.083731310
67  -1.7929149185 -0.54390514 -0.728723259 -0.963357244 -1.668881689
68   1.7769347604  2.40088430  0.404735210 -0.086789607 -0.039117880
69   0.2179779459  0.64516450 -0.101492435 -0.901905282  0.614526647
70   3.1339534228  1.26386491  1.270944654  0.330862280  1.352746038
71  -0.1259520428  0.19267403  1.246725188  0.845079971  0.699984832
72   0.0405485247 -0.52290120 -1.489294968  0.610526395 -0.661020996
73   0.4754008366  1.02404482  0.897144876  0.058166975 -0.300577340
74  -2.6895868084 -1.59264220 -1.223079580  0.344187484  0.512318372
75  -0.5459615881 -1.94432565 -0.252799729 -1.579852478 -0.616204573
76  -1.1562860290  0.53758634 -0.337650835  1.517225228  0.379865088
77   0.0461554357  1.83816492  0.349334111 -1.529994006 -1.058638868
78  -0.8395362886  0.77015046 -0.941009799  0.261897908  0.930996729
79   0.7735181418  0.28267314  0.892567365 -1.215600937 -0.010304868
80  -1.4055208647 -0.52048203 -0.520647633  0.044516709 -0.157260934
81   0.0877875454 -1.18856748 -0.590889118 -0.082663679 -0.797156263
82  -0.5602149639  0.44049776  0.403835171  0.466589138 -0.377065078
83   0.3477175853 -0.06490563  0.284933429  1.689456383  1.168282918
84  -0.5967279049 -0.86522915 -0.654388508 -1.123550593 -1.395703886
85   0.0067799214  0.84708257  1.138194028 -1.112129607  1.463993425
86   0.3721907535  1.01516030  0.652587552 -1.520379797  1.463838250
87   0.6847116122  0.56301423  1.810765506  0.481769335 -0.151947621
88  -0.0312676297 -0.72967448 -1.144571021  0.905538519  0.648209062
89   1.0223588579 -0.62933490 -0.238992060  1.486648564 -0.672133513
90  -0.8816612780 -0.12459415  0.171656989  0.394706171  0.930677659
91   0.4776656414 -1.35812046  0.318748265  0.100394651 -0.901169766
92   0.5619667249  0.28464579  1.076582903 -0.342022673  1.617624464
93  -0.4304015712  1.27001996  1.168457444  1.558340293  1.243160740
94   0.6634143823  1.34224632  1.356474398 -0.264195189 -0.447691467
95   0.4262455962  0.15540357  0.190310662 -0.295421796  3.519532872
96   0.3247077982  1.38678797 -0.768177285  1.039855697  0.143230420
97  -2.5688579778 -1.45764532  0.404043730 -0.647108311 -0.921581685
98  -0.3711483431 -1.57481049 -0.516172155  0.770821178  0.179842312
99  -0.5181913491 -0.46087164 -1.423157350 -1.225169114 -1.659354417
100 -0.3241931735 -0.27499555  0.061762260  0.026207235 -1.025488759
101 -1.2608123820 -0.70465244 -0.507725421 -0.134951402 -0.713208467
102  1.6045847696  0.60919145 -0.697583513 -0.344886746 -0.403963584
103 -1.4485685714 -2.27845518 -0.805216609  1.013183871 -0.074574886
104  0.2339305241  0.46845124  0.140785418 -0.155752781 -0.573181480
105 -1.8487178826 -1.05105968 -0.681699931 -0.175699031  0.950311805
106 -0.3282497066  0.65716891  1.171006577  0.934752511  1.930606581
107 -0.4343939862  1.31928628  0.448076578  1.392597949  0.391587472
108  0.0674125565  1.01929513 -0.025080675  1.028205339  0.944496848
109  1.4957467584  0.37478111  0.304887067 -0.873472484  0.533807642
110  2.0396040925  0.30108835  0.612602853  1.809915796  0.430701475
111  0.0836251337 -1.31710167 -1.475631644  1.465978243 -0.789000308
112  0.4471490248 -1.01867806 -0.495487362  0.212428221 -0.837182507
113  1.0422762097  1.12828005  1.340459378  1.226758030 -0.279993309
114 -0.8191229322 -0.13248823  0.534646102 -0.705367653 -0.677337795
115 -0.3305742687  0.61397339 -0.652812183  0.189087390  0.593848304
116 -2.1377059370 -0.48465132  0.368575054  0.132528125 -0.035314889
117 -0.2090894150  0.51027631 -0.285563244 -0.207521468 -0.639311014
118  0.8119503946 -0.33094260 -0.878902424 -0.472169073  0.233768693
119  1.0037904106  0.94540176  0.816627915 -0.048920330 -0.362574437
120  0.2201993071  0.15363391 -1.407204502 -0.508200123  1.504739911
121 -0.6192998951 -1.03481872 -1.154258093  0.715174505  0.347166193
122 -0.2059414972  0.53231605  0.338132464  1.596363103  2.785334795
123  0.4925457037 -0.57747645 -1.461444127  0.694848527  0.118499613
124  0.6252206657  1.09499760  0.472616815 -1.177192123 -1.401456154
125 -0.7788719599 -0.72244028  0.640398289  0.259634607  0.270596332
126  0.2753483074  0.97121188 -0.431707474  1.574931372 -0.270360531
127 -0.7992852453  0.64738850  0.486385041 -0.151085350 -0.722390099
128  0.2360446187  0.98780741 -1.532784374 -0.708819152  0.493995339
129  0.1946726104  0.11794660 -0.507478459 -1.207877217 -0.147378071
130 -0.7543560973 -0.19358829 -0.634660190  0.036005974  0.323987148
131  0.0364199431 -0.53394647  1.065937731  0.676364897 -0.219239440
132  0.8016260454  0.54404162 -0.389829562 -1.768305517 -0.230229594
133 -0.1410602527  1.25318139  0.462606717  0.153329550  0.176545122
134 -2.3269769264 -0.54785558 -2.053942030 -0.294801011 -1.610932747
135  0.5857480462  0.11162428  0.378092033 -0.850793701  0.988828103
136 -1.4985027092 -1.96261898 -0.640851643 -0.072579774 -0.014489374
137 -0.1646307300 -0.23488959 -1.501433465  0.009095024  0.420191131
138 -0.5618487081 -0.02751099 -0.482743297 -1.187932677 -0.517261379
139  0.4574846794 -1.27755036 -0.014418680 -0.990067363 -0.621959638
140  0.4427581879  0.48773647 -0.321451474 -0.193359071 -0.787832290
141 -2.8811023589 -1.42864914 -0.564206074 -0.628869108 -1.153407685
142  0.5270371745  1.36502363  1.935619345  0.197721738  0.723895619
143 -0.5481022617 -0.90491534 -2.243432508 -1.306192600 -0.361475697
144  0.2865956512 -1.00185782  0.175457323 -0.441685344 -0.383632346
145 -0.2988841089  0.13693426  1.005093026 -2.565371307 -1.796977620
146 -0.6471168107  0.68646757  0.370749527 -1.016599170 -0.771521601
147  1.5920708177  1.14827500  0.219847298  2.271895307  2.249293223
148 -0.3537815508  0.39353090  0.256750895 -0.209955942  1.175782254
149 -0.0951342086 -2.06625826 -1.532156850  0.693221919 -1.530572183
150 -0.9645588686 -2.12716027 -2.798450984 -0.503440256  0.143875513
151 -1.2920054024  0.91615740 -0.729809290  0.787663374  1.787693060
152 -0.8148269475 -0.03079735 -0.117361701  0.443020711  0.168357382
153 -1.0294529925 -0.50403937  0.372372788  0.693288619 -0.225272356
154 -0.1924206082 -0.09913424 -1.320466904 -0.509336732 -0.694754938
155 -2.5265702502 -1.27944370 -1.352037582 -1.148718189  0.204044661
156 -2.2110491362  0.14570621 -0.919234698  0.036490939 -0.579347648
157  2.4735564571  0.61652626  0.531788231  1.488814554 -0.226698058
158  0.2162123854 -0.54914264 -0.708117382 -0.964431035 -0.007118478
159  0.4181098432 -0.21523175 -0.374396776 -1.574864931 -2.193600951
160  0.8921263490  1.94720865  1.199808905  1.320595024 -0.023451999
161  1.4403901104  1.88825753  1.071807815 -0.258173610 -1.654814358
162 -0.3559374303 -1.36924575 -0.552086500  0.443121082  0.381188528
163  0.1852145141  1.37703245  1.442328834 -0.113670391 -0.510448063
164  0.7791536668  0.81928588  0.777994066  0.893991156  1.232566848
165 -0.4164688586  1.38355608 -1.985362180 -0.301342496 -1.245670312
166  2.0643736589  1.50892036  0.042081009  0.974514474  1.669113883
167 -0.0288257864 -1.10816814 -0.304657714  0.372368640  0.694684849
168 -0.5407691203 -1.21291136 -1.897155155 -0.806299057 -1.751715398
169  0.2195516909  0.73376002 -0.462299695  0.031618946 -0.174979246
170  0.0600798631  1.27659313  0.945174591 -0.996394346 -0.309409682
171  1.5526031710  1.99516318  1.641048935  1.986685756  1.257980323
172 -1.0491658530  0.57119059  0.311701320 -0.186224123  0.922032974
173  1.2005481525  0.23320060  0.613288649 -0.621743377 -0.253861583
174  0.8738445025 -1.13335374  0.197886868  0.115849461 -0.643024436
175  0.2261905333 -0.05979957  0.755267281 -1.436909836 -1.901562877
176 -0.5761764146 -0.39440018  0.911852765 -0.612949986 -0.191230765
177  1.0775405715  0.35572783 -0.019866615  0.242001452  0.983951606
178  1.5401987455  0.94737101  1.899713702  0.202911743  2.230571411
179  0.5955688479  1.29250324  0.409245640  1.887993553  0.920794012
180  0.6880648895 -0.19001521 -0.470446371  2.255087920  1.249070024
181 -1.4568256022 -2.15306330  0.082900476  0.404880890 -0.849702160
182  0.8180751554 -0.12494065 -0.226433199  1.039108508  1.264534294
183  0.0085438960  0.95015610  0.746740187 -1.199500750  0.065679066
184 -0.8940668214 -0.89639078 -1.395100746 -1.851574470  0.049340769
185  0.3770063973 -0.82598548 -0.077718026  0.609599278  1.228258471
186 -0.7713336559 -0.87279879  1.400998933 -0.555717355  0.131552517
187  2.1916399164  1.67997412  1.993896837  0.036039639 -0.433074625
188 -0.7644027282 -0.50832439 -0.744513922 -0.632456117 -0.201423058
189  1.0818416884 -0.71917476  1.372392496 -1.310306184 -0.758836981
190 -0.7123867784  0.32291498 -0.370940781 -0.492459708 -0.908119073
191 -0.7189526528 -1.27177778 -0.176011101  0.640347511  0.103736091
192  0.7583885763 -0.09557949 -0.692839578  0.531354179  0.215634518
193 -0.9704287286 -0.52589547 -1.472212149 -0.786149409  0.777841368
194  1.0111685017 -0.46876166  0.714326936  1.362278118  0.769143961
195 -0.9182525115  0.24633169 -1.615503809  0.346701771 -1.458981555
196 -0.9252375184  0.14194143 -0.068448638 -1.563162896 -0.991772639
197  0.2406860576  0.28524346  0.205569334  2.106344888  1.000259344
198 -1.4337577825 -0.14697860 -0.530798010 -0.407106864 -0.991733735
199 -1.0447500775  2.16919283  0.684209652 -0.615469883 -0.351618750
200  0.0003911315 -0.56261685 -1.389186009  0.482855829 -0.419598035
               y6
1    0.6180292594
2    2.3837518591
3   -0.5212269270
4    0.8620270188
5   -0.5963206302
6    0.5078609421
7    0.7560059736
8    0.0755523079
9    0.3437498957
10   0.8277790695
11   0.6519951487
12   0.2183530296
13  -0.7622672194
14  -1.0837788485
15   1.3074069668
16  -0.2938138623
17  -0.3715209234
18   0.8235061437
19   1.3636021679
20   0.5659299001
21   0.2328136550
22  -0.1785960274
23  -0.3303716169
24  -1.8632142568
25  -0.0472791943
26   0.9918544612
27   0.0365857421
28  -3.1384202905
29   0.3244417113
30   0.3115047955
31   0.2355117511
32  -2.2599809462
33  -0.9697594710
34   0.5124384949
35  -0.9466894918
36  -0.9987866543
37  -0.9858805748
38  -0.7061911584
39   1.6712780213
40   1.2013057555
41  -1.0177945028
42   1.8121359903
43  -1.0758238986
44   0.2602691534
45   0.4160715843
46  -2.1811373349
47  -0.7659919354
48   0.0905282800
49   0.9539121615
50   0.3284151719
51   0.3129508912
52  -0.7349192375
53   0.5990398139
54   0.0706749722
55   1.1537899816
56   2.2754967491
57  -0.7770942330
58  -0.4176790163
59   0.5578826036
60   0.0132791538
61   1.4557820236
62  -0.1614578505
63   1.0553020077
64   0.6572954141
65  -0.0065962895
66  -0.5011396666
67  -1.5871881961
68   1.4584604520
69   0.1442724592
70   1.4164788765
71  -0.9393140531
72  -0.8432634726
73   0.3107646599
74   0.8787032268
75  -0.1206297159
76   0.2355626325
77  -1.4341862530
78  -0.1780377153
79  -0.4228047777
80   0.1800367947
81   0.2762923915
82  -0.9192347075
83   1.3293771747
84  -1.5136484447
85   0.0532982808
86  -0.6395803272
87   0.9024505935
88  -0.8759472927
89   0.5248812368
90   0.5872486206
91  -0.8271764917
92   1.6762625941
93  -0.1260907029
94   0.1758749166
95   2.4085273170
96   0.1276953164
97   0.0387120748
98  -0.8022817056
99   0.3441005526
100 -0.3739782644
101  0.8174960980
102 -0.5973590354
103 -0.0829278468
104  0.5235849919
105  0.1649040059
106  2.7676406794
107 -0.2244604105
108  0.6392133680
109 -0.2851444833
110  1.5954968076
111 -0.5337575235
112 -0.1714677143
113  1.3230356725
114 -0.8265967191
115 -1.2505294045
116  0.5711619042
117 -0.4603102987
118 -0.4902306235
119 -0.3597381126
120 -0.6788897951
121 -0.2960524307
122  0.3744169193
123 -0.1330344756
124 -0.3388926172
125 -0.0736955572
126  0.7569598115
127  0.2420747996
128  0.3718613643
129 -1.2011266096
130 -0.0861716439
131 -0.7827238749
132 -1.3341324966
133  0.2405624650
134  0.7061373572
135  0.0237955037
136 -2.0122030071
137  0.2569017365
138  0.6451132878
139 -0.1854000475
140  0.1425078194
141 -1.0702872302
142 -0.0005046481
143 -1.3558555533
144 -0.5057265862
145 -0.9847451137
146 -1.6523504906
147  0.9426045614
148 -1.1921163188
149 -0.6607215400
150 -0.3718921579
151  0.3472952580
152  0.2766987981
153 -0.5906483904
154 -0.9348732590
155  0.0992055180
156 -0.8121355435
157 -0.8477839774
158 -0.4948894153
159 -1.6476829367
160  2.2083330530
161 -0.7717252908
162  0.4897595541
163  1.8916725586
164 -0.9253124870
165  0.0659688199
166  2.6450185696
167 -0.6547131876
168  0.4594654416
169 -0.9304610979
170 -0.1384007199
171  0.8817207466
172 -0.1425073228
173  0.6730545945
174  0.2774013733
175  1.0687579388
176  0.7227473027
177  0.5396272999
178  1.5551032352
179 -0.9594598042
180  1.3434623849
181 -0.9979190227
182  1.2007442189
183  0.3160171841
184 -0.9341570305
185  0.7917325900
186  0.0265509200
187  0.4427262353
188 -0.2408535448
189 -1.4022884237
190 -1.5768673396
191  0.7078508957
192  0.9055963979
193  0.0234449447
194 -0.0366973321
195 -1.4762230728
196 -0.8230762289
197  1.9785351080
198 -0.5896739751
199  0.8212020981
200  0.3500977547
> 
> # With Misspecification Model
> n01 <- simNorm(0, 0.1)
> error.cor.Mis <- matrix(NA, 6, 6)
> diag(error.cor.Mis) <- 1
> RTD.Mis <- symMatrix(error.cor.Mis, "n01")
> CFA.Model.Mis <- simMisspecCFA(RTD=RTD.Mis)
> SimData <- simData(CFA.Model, 200, misspec=CFA.Model.Mis)
> summary(SimData)
DATA OBJECT
Model Type
[1] "CFA"
Sample Size
[1] 200
========= Parameters Set ============
SET OF MODEL MATRICES
Model Type
[1] "CFA"
-- Endogeneous Variable --

LY: Loading of Indicator.Y on Factor.ETA 
     [,1]     [,2]    
[1,] "NA:0.7" "0"     
[2,] "NA:0.7" "0"     
[3,] "NA:0.7" "0"     
[4,] "0"      "NA:0.7"
[5,] "0"      "NA:0.7"
[6,] "0"      "NA:0.7"

RTE: Correlation of Measurement.Error.EPSILON 
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,] "1"  "0"  "0"  "0"  "0"  "0" 
[2,] "0"  "1"  "0"  "0"  "0"  "0" 
[3,] "0"  "0"  "1"  "0"  "0"  "0" 
[4,] "0"  "0"  "0"  "1"  "0"  "0" 
[5,] "0"  "0"  "0"  "0"  "1"  "0" 
[6,] "0"  "0"  "0"  "0"  "0"  "1" 

VY: Variance of Indicator.Y 
[1] "NA:1" "NA:1" "NA:1" "NA:1" "NA:1" "NA:1"

TY: Measurement Intercept of Indicator.Y 
[1] "NA:0" "NA:0" "NA:0" "NA:0" "NA:0" "NA:0"

VPS: Variance of Regression.Residual.PSI 
[1] "1" "1"

RPS: Correlation of Regression.Residual.PSI 
     [,1]     [,2]    
[1,] "1"      "NA:0.5"
[2,] "NA:0.5" "1"     

VE: Variance of Factor.ETA 
[1] "1" "1"

AL: Regression Intercept of Factor.ETA 
[1] "0" "0"

ME: mean of Factor.ETA 
[1] "0" "0"
-------------------------- 
Number of free parameters =  19 
=====================================
Adding Misspecification?
[1] "Yes"
Adding Constraint?
[1] "No"
Maximum Random Sampling Parameters
[1] 100
> run(SimData)
              y1           y2            y3          y4            y5
1    0.310020825 -0.345899382  1.8123879306 -0.34326028  1.0658688701
2    0.335506346  1.318523686  0.8434819458  0.44801752  1.5461676121
3   -1.132483101  0.217147334 -1.0254883629 -0.15853308  0.7433163068
4   -0.419300107  0.134239695 -0.0447513423  1.12840822  1.0523633318
5   -0.028513223 -1.652978377  0.0750363919  1.65883057 -0.0926169753
6    0.006318933 -0.704186687 -1.8147112214  0.21886781  0.3215200833
7    1.135431363  0.946516333  0.7683064905  0.72878296  1.9804177373
8   -1.143169040 -0.038772706 -1.1061440089  0.27112284  1.3879963966
9   -0.984405564 -0.605474580 -1.4498906591  0.63892629  0.3163259710
10  -0.806225011 -0.441869768  0.3230280450  0.23400418  0.1452400548
11   0.064939093  1.459169471 -0.1873405497 -0.21831465  0.1654414922
12   0.624647070 -0.922153549  0.1992993077 -0.98803796 -0.4997015596
13   0.824110335  0.025799864 -1.3263230766 -0.56434188  0.4097367384
14   1.707908654  3.319916841  1.1284675124  1.41092753  1.6135782618
15  -0.510020221 -0.128291052  0.1570524387  0.67283472 -0.3897724573
16   0.417899513  0.225044632 -0.3907797890  0.15179286 -0.5613695593
17  -0.677631690  1.566427752 -0.4273748437  1.00158371  0.7982875014
18  -1.448297929 -1.427924286  0.3367410375  1.58999488  2.2737916019
19  -0.954369496 -0.017401046 -1.3185728288 -0.74733791 -0.0439828180
20  -1.546106084 -0.256509229 -1.1225857814  0.17634875 -1.7941212719
21   0.380444741  0.002802138  1.0886217239  0.06716056  0.4480224812
22  -1.022804130 -1.834722241 -0.3316122024  0.12112624  0.5800292571
23   0.545140977  0.759815240 -0.2036692683  0.27951375  1.0734314663
24  -1.105248773 -0.660164244 -0.7784816839 -0.01494612  0.9156364281
25  -2.454260384 -0.906499544 -1.8639188052 -0.06114785 -1.3447165032
26   0.553796141 -0.860783346 -0.0803869221 -1.43932926  0.8751117999
27   3.580683474  2.316965063  3.3156422945  1.01161425 -0.0786741743
28  -0.004594863 -1.047200913 -1.4244510069 -1.56031918 -1.1000025407
29  -0.229204737 -1.121323068 -1.3735852812 -1.07192931  0.5521645152
30   0.722518830 -1.087937294 -0.5839266867 -1.95534592 -0.7950657367
31   0.384642783  0.274749618  0.5343877902 -1.08081056 -1.8473082870
32   0.990200311  0.065109814  0.1227527518  1.40210684  1.2310813072
33   0.953752961  1.264542763  1.6624161825 -1.71575853 -2.0126393959
34  -0.321175077 -1.700880116  0.8899653825  0.43096654  0.1438285686
35  -0.720529110 -1.124595226 -0.3300756642 -1.26151331 -1.0656456027
36   0.349235743  0.003848763  0.6967217972  0.31041680 -1.2417759905
37   1.084215481  0.950267453 -0.1654479394 -0.99811095  1.7849912435
38   1.346700863  1.636870727  1.3214568840  1.01576001  2.1134519551
39   0.523596496  1.486208591  0.3285972831  0.45080607  1.0965664833
40  -1.096155117 -0.178316826 -0.4279677418  0.24672744 -0.0796817059
41  -0.106632369 -0.343155433  0.2271187826  0.01824684 -0.3882349371
42   0.356350567  1.009448722 -0.4336542736  0.81804715  1.2168117040
43  -0.762939689  0.301448554 -1.3914705353  0.81108162  0.8484466416
44  -0.645079376  0.982601628 -0.4779978529  0.87920064 -0.3662172535
45  -1.080070602 -1.963256822 -1.8290507922 -0.16386395 -0.6669719470
46  -0.129377786 -0.616315991  0.2455551820 -0.02188195 -1.0999850790
47  -1.332409795 -0.422345195 -0.7523721373 -0.56154346 -0.0005282294
48  -0.245046996 -0.622011189 -1.6844861519 -0.72164378 -0.7595069789
49   0.133878212 -0.241536197 -0.2034534062  0.44910944 -1.0979554760
50   0.217767268  1.030060934 -0.6546208444 -0.71191811 -0.6372109332
51  -1.017531821  0.139300186 -1.6566711792  0.62732286  0.0735219340
52   1.223895322  1.605632366 -0.2721916733 -0.48210568  0.1675932996
53  -1.194715618 -0.395240236 -0.6629751999  0.13835639 -0.1998861957
54  -0.378058530 -0.870606030 -0.1106753262 -0.59145306 -0.3685266495
55   1.876800554  0.727320311  1.9305231574  1.01504763  0.2931352770
56   0.355915431  1.667392945  2.3279705788 -0.26699834  0.0866130640
57   1.489016123 -0.034359524  1.3900005346  0.19079917  0.4579506893
58   1.551939432  2.783109720  2.0409089744  0.66442398  0.4849478164
59  -0.796405070  0.248664914  0.1218659961 -1.47614438 -0.6056958232
60   0.738119247  1.511616216  0.4036966819  1.70884248  1.9456741316
61   0.600909613  0.757293945  1.8606126528  0.93192433  0.0655582448
62  -2.086548557  1.176546820 -0.5217724060  0.96839945  1.0843332762
63   0.186272074 -0.255046224  1.4183597399  1.23321978  0.2331142654
64   0.870318211 -0.532617993  0.9144902783  0.01282129 -0.3950214490
65   0.425995933 -1.030588241  0.5298933979 -0.81731179 -0.5095705181
66  -0.536749385 -0.717112975 -0.9181549561 -1.00607776 -1.4892026372
67   1.808162990  0.086678628 -0.0669929636  0.75778658  1.3097465471
68   1.689130859  0.659531105  1.4719781696  0.17698520  1.7114730819
69   1.508067710  0.905174961  1.3952507375  2.58267557  1.8291853243
70  -0.479009734 -0.306830661  0.0039804251  0.38321706  0.3566023354
71  -0.313156686 -0.282733669 -0.4253655394 -0.45621797  0.9579749453
72  -0.815742545  1.331070192 -0.9000145316  0.65572984 -0.0992401354
73   1.103897692  0.890822757  0.0065677935  0.40748473  0.8262161012
74   2.527327086  0.195943706  0.9443848824  0.83999678  0.4541195869
75   0.024563063  0.161177670 -0.0473171338  0.32240688  0.8908071596
76   0.224447118  1.618431556 -0.0306077669  1.44543386  0.9465477106
77  -0.645678781  0.953307884  0.4754561313 -0.91420330  0.1866399554
78   0.439363088  1.065649523  0.1448226520  0.06345299  0.7179600861
79   0.840300155 -1.068169121  0.5573872841  2.16863511  1.4360811986
80   1.333975819  2.055210240  1.7422302654  2.94637669  3.3857892054
81   0.185659697  0.313298386 -0.7198966967 -0.21374096 -0.0065658993
82  -0.873199827  0.870936040 -0.3725563785 -0.46782962 -1.9722932193
83  -0.877563902  1.271416152 -1.5833880559  0.18237317  1.6709882743
84   0.423650826 -0.456248467  0.9382664113  0.53649243 -0.8440517746
85   1.269017422  1.301030312  0.0409185482 -0.38809513  0.3325878724
86   0.192015768 -0.924334958 -0.0766083538  0.85586397  1.5025212217
87   1.425034782  1.308555629  1.1560905497  0.38540900  0.4704581008
88  -2.256058725  0.421607992 -0.8865469555 -1.04376663 -1.3204611881
89  -0.360712062 -1.986901982  1.0589359722 -1.41170033 -0.9545403396
90   0.499500007  1.472538068  0.4368652634  1.35209314  0.9142566271
91   0.346788098  0.706884928 -0.2220860532  1.70616057 -0.4868957247
92  -1.755400196 -1.052392031 -0.1847246788  0.52352018 -1.2007944062
93  -1.359293193 -1.063624682 -1.5598815512 -0.57795509 -0.0467322012
94  -0.681215793  0.975981847 -0.8765188813  0.10774948 -0.5245360856
95   0.415155160  1.196912368 -1.1744541894  0.93086925  0.4216209188
96   1.668478153 -0.804207137  0.3723982986 -1.00171621 -0.9257819043
97   0.774591639  1.117549634  1.1579448572  1.36948984 -0.3660588271
98   0.877845451 -0.124911365  1.3260626963  0.31847139 -0.8350835573
99   0.086563679 -1.049607585  0.8182820309  1.16172348  0.1696784570
100  0.449248762  0.612313555 -0.9951094881 -0.15108928  0.2894140133
101 -0.324724926  0.547351535 -0.2617464621  0.68505156 -0.6607950192
102 -1.225456248  1.418832944  0.2148873606 -0.06700420 -0.7945985380
103  1.261283737 -1.059976631  0.2343420133  1.87926064  1.1404341627
104 -1.209219278  0.006124173 -0.9299516027 -0.84334517 -0.7220325464
105 -0.334076011  0.259168682 -0.4534424000  1.86145978  1.1846433535
106  0.611838513  1.441873511  0.2369235880 -1.92553327 -0.6608053861
107  0.194655465 -0.013920609  0.6336421091  0.46744421  1.2537953115
108 -1.834724698 -1.986610015  0.4690023788  0.84731488  0.5760924622
109 -0.323513484 -0.723148255  0.0252457954 -2.50320607 -1.0906622703
110  0.259518175  0.634316908  1.0051704085 -0.03393793 -0.6312711582
111 -0.741174450  0.918996407 -0.5229105304 -1.05494563 -0.7449630659
112  0.816567967 -0.106633949  1.1519904787  1.93755128  1.0981347267
113  0.272954017 -1.221790665 -0.5193445903 -0.14370002 -1.3881039054
114 -0.295394606 -0.817859472 -1.6829758553 -0.94336763 -1.2633579354
115 -2.562876296 -1.816797319 -0.0623438845  0.61543898  0.3110845474
116  0.225518018 -1.412183667 -0.3894308618 -0.68406941 -0.0241436787
117 -0.484634898 -0.249610035 -2.3769399391 -0.22626843  0.8532176413
118  2.438942114  1.405686725 -0.0001931225 -1.60115105 -1.8856807379
119 -0.729062287 -1.319052054 -0.8630850052  0.70631959  0.1738192269
120 -1.884152366 -1.096903823  0.3505628172  1.59751727 -0.4909781653
121  0.038852313  0.839307608  0.5841643102 -0.40186853  0.3399992839
122  0.680077452 -2.751647722 -0.4598583390 -1.27626500  0.3984148043
123 -0.319360622  1.333786017 -1.6795232308  0.08256865  0.7256875659
124  0.057877329  0.101616604 -0.2312194698 -0.69617734  0.7070432774
125 -0.096521591 -0.978436413 -0.7103392467 -0.30948545  1.5961913534
126 -0.881919088 -2.471881819 -1.6924686660 -0.54861905 -1.0077949269
127  0.957682744 -0.748708839 -0.8175367568 -0.27324910  0.3795089673
128 -0.978403248 -0.562565395  0.9323577319 -0.20592448 -1.4483778402
129  1.419153877  0.440696624  1.6721581714 -0.31674435  0.2690737707
130  1.882379450  1.265439120  2.5692366002  0.62520930 -0.0624739986
131  1.340161136  0.839420057  0.1788998136  1.24980927  0.9319578708
132 -1.575939074 -0.199646107 -0.5197879911  0.12607981 -1.5411633234
133  0.058309669 -1.260602438  0.1681418943 -0.64405472 -0.7865100270
134  0.296933136 -0.150678466 -1.2746839915  0.31034817  0.0366466437
135 -0.693388738 -0.718227618 -1.3051681797 -0.36726940 -0.8445595918
136 -0.308218025 -1.119301689 -1.2559067205 -0.64498175 -1.5403772733
137  0.620746997  0.171852719  0.6003464279  1.16351656 -0.4113394236
138 -1.518029973  1.183800335 -0.9499120939  1.27387921  0.1404349714
139 -0.269172065  0.499832372  0.6066276262  0.68068720  0.0940217511
140 -1.502733844 -1.360555214 -0.6183211399  0.54127408 -0.9012056909
141 -0.020416472 -1.226535287 -0.3413941502  0.14827995  0.2108122522
142 -1.953981783 -0.536352278 -2.0728859820 -1.14418724 -0.0360589293
143 -0.306873504 -0.121545450 -1.2602347309 -0.91229739 -0.3792384843
144  0.352855250  2.110790947 -0.2296185213 -1.36432980 -0.2547739540
145  0.697810233 -1.073113478 -0.8101301793 -1.38913758 -0.0132664712
146 -0.986796732 -0.526643949 -0.6826953259 -0.65870360 -0.2163805208
147 -0.367073873 -1.252325823 -0.6596516713 -1.23918100 -0.6456142352
148 -0.666981071 -0.435761193 -1.3051235612  0.16620764 -1.7731746027
149 -1.513298163 -1.212897149  0.0812464639 -0.72059439 -1.0124850510
150  1.366725110  0.799851423  2.1277018666  1.10114756  1.1999324078
151  1.472352551  0.350094503 -0.3975231484 -1.72335542 -0.8860511227
152 -3.225521488 -1.502301829 -0.1945819575  0.45456842  0.5993679387
153 -0.696713959 -1.568049604 -1.2425350014 -1.32537877 -0.4879251578
154 -1.481504374  0.528035886 -0.5311579798  0.64499291 -0.6476077302
155  0.968535243 -0.771431792 -0.7506232091 -0.56469778 -0.9148226818
156 -1.053187416  1.717186505  0.1654106674  0.03079016 -0.7602648909
157  0.778993449  0.849207393  1.0216461132 -1.02209601 -1.0202839093
158  1.112412017  0.560989806 -0.5632996624  0.99281891  0.2344852091
159 -0.072714216 -0.528981073  1.1785135910  0.96051928  0.0788777011
160  1.531018747  0.964043532  0.7985078776  0.60606083  0.8789754103
161  0.263295000  0.712091179  0.3759530945  0.50596058 -0.5903738719
162  0.270643763  0.309141429 -0.4313363115 -0.03922605  2.1062354053
163 -1.136576278 -0.218297560  0.6268599668  0.41803919  0.0072990871
164  0.712067502  1.174067257  0.3871139912  0.39601431  0.0105803098
165 -0.371149945  0.298834058 -0.6414699443  0.12665737  0.0001596950
166  0.073996407  0.987856629 -0.1873290142 -0.64834218 -1.2965939670
167 -2.670997958  0.084907403 -1.0293920035  0.03045715 -0.8115058757
168  0.457690997  0.857946321  0.2345793150 -0.83141933 -0.9885424355
169  0.316271934  0.017391844 -0.3037404630 -0.15739407 -0.9909986107
170 -1.058610617  1.425819365  0.1725383303  1.17334572  0.3302254592
171 -0.586841983 -0.918837667 -0.3706447445  0.29688265  0.2136294687
172  1.363404537  0.664327395 -0.7241515129 -0.89488673 -1.1198349413
173 -0.299745303 -1.293994605 -1.1925624593 -1.13457225 -0.4606250998
174  0.708855279  0.968223032  0.7469687944  0.50769475  2.1696284080
175  0.253813640  0.008947227 -0.6986818210 -1.04767162  0.1048269594
176 -1.050618135  0.539954565 -0.6750233672 -1.44127307 -2.0454589483
177  0.080006572  0.795198101 -0.2802539293 -0.93378636 -1.5863742852
178 -0.359397057  1.668350576 -0.9522843787 -0.16422353 -0.4293920611
179 -0.186890408 -0.494112989  0.4023205125  1.03245483  2.1203043917
180  0.760213665  0.582168896  0.6580121380 -1.27553708 -0.6982532924
181  1.100688270 -1.203045200  1.4473032596  0.06661078 -0.8552076777
182 -1.764941047 -0.493702830 -1.9189640641 -0.34482101 -0.8757530918
183  1.920160584 -0.289997827  1.3252699102  0.96785471 -0.3873156890
184  1.777218113  0.175780316  1.8060983945 -1.77624637 -0.4458384503
185 -0.267201307  0.973403813  0.8814153531  0.52575847  0.1496141960
186  0.384472102  0.421017516  1.6337727652  1.66977029  1.1117794962
187  0.039659775 -0.298574526  0.5388751670  1.42609702 -0.5350613825
188  0.810465525  0.105008075 -0.2799078603 -1.43031846 -0.2088758033
189  0.897928167 -1.558841238 -1.6997873710 -0.33525530  0.5318894214
190  0.016885559 -0.119480420 -0.7388971646 -0.35555522 -0.5224106424
191 -0.870455121 -2.470985149 -0.1124242064 -0.38267764 -0.2574371120
192  0.402901693  0.757590850 -0.7682410577  0.72470870 -0.3382878110
193 -0.903217760 -1.911822469 -1.1996956499  0.12983574 -0.5344953363
194 -0.951884425 -0.519802492 -2.2221336356  0.07206109 -0.9327954972
195 -0.447689422 -0.714894777 -0.7659633216 -0.17708854 -0.0383111363
196  0.270148190  0.629490041  0.1304935672  1.16528764  1.4121564451
197  1.254957799  1.143624256  1.2082239591 -0.58384469 -0.6034150352
198 -1.006868702 -0.322100650 -0.3027236776 -0.63627368  0.2386344547
199  1.398689981  0.311210388  1.3700804874  0.01873503  0.2302247049
200 -0.627349402 -0.574605609 -0.0256743851 -0.44229065 -0.4749974602
              y6
1    1.175134426
2    0.627126002
3    0.035694078
4    1.112114255
5    1.070418891
6   -0.153146894
7    1.497029050
8    1.036992556
9    1.662034834
10   2.480193623
11   0.370167479
12  -1.163791364
13   0.497050911
14   1.513958027
15  -0.142587921
16  -0.911124540
17   0.632192319
18  -0.152585402
19   0.824424126
20   0.134299972
21   1.387083215
22   2.636029973
23  -0.473402978
24   0.246518529
25  -0.220223737
26   1.175939279
27  -0.040298943
28  -0.669598642
29  -0.797097133
30  -1.527352970
31   0.459747584
32   1.704689203
33  -0.418726677
34  -0.629576676
35  -0.712407421
36   0.250300702
37   1.548788505
38   1.686635159
39   1.431915167
40  -2.043745281
41  -1.408122885
42  -0.504485670
43   0.028794479
44   0.724225850
45   0.247255402
46  -0.070575572
47  -0.793238227
48   0.312177493
49  -1.818990106
50  -0.738989116
51   1.672172809
52   0.531573385
53   0.125576295
54  -1.159728742
55   0.828999192
56  -0.056208313
57  -0.567794370
58  -0.401394187
59  -1.395769940
60   1.892355176
61   0.768374327
62   0.360648013
63  -0.349958844
64  -0.532169177
65   0.960414635
66  -1.605178424
67  -0.790515938
68   2.927389249
69   0.209258060
70   0.605851909
71  -0.020228323
72   0.547530499
73   1.453682623
74   1.185778670
75   0.228483191
76   0.304419015
77  -0.172814466
78  -0.358157326
79   0.693967373
80   3.066824852
81   0.271804989
82   0.233560724
83   0.988489261
84  -2.126022154
85   0.202165870
86  -0.328415710
87   0.718263422
88   1.100438525
89  -1.250608591
90   1.645328334
91  -1.033154285
92  -0.219962190
93   0.101486837
94  -1.163977545
95   0.658887950
96  -1.188970716
97   1.452529438
98  -0.445601751
99  -0.489187943
100 -0.179471944
101 -1.120728142
102 -0.207138982
103  1.123303303
104 -1.702257557
105  1.680593647
106 -0.854847152
107  0.327482561
108  1.272083691
109 -0.738112261
110  0.257527543
111 -0.358895006
112 -0.410836555
113 -0.263706751
114 -2.096444854
115 -0.344426265
116 -0.060382020
117 -0.912900448
118 -0.771780289
119 -0.531236992
120 -0.398104525
121 -0.045887654
122 -1.338170410
123  2.866117522
124  0.029145561
125  0.170026220
126 -1.701015736
127 -0.647351563
128 -0.021222006
129  0.073760671
130 -0.425954012
131  0.510419320
132 -0.823374162
133 -0.728487407
134  0.441768895
135 -0.364979494
136 -1.518055091
137  1.091770256
138  0.027827951
139  0.815276053
140 -1.163123373
141 -0.228748206
142  0.813166908
143 -0.330187674
144  0.515736233
145 -0.629125666
146 -1.008030844
147 -1.107332682
148 -1.678950073
149  0.729945450
150  0.320626879
151 -1.140350743
152 -1.085843852
153 -0.424726748
154  0.772831379
155  0.577895484
156  0.936042331
157 -1.490896300
158  1.254127913
159  1.172834901
160 -0.374668410
161 -0.181512252
162  2.125087633
163 -0.157814984
164  1.185896258
165 -0.063619338
166 -1.459841849
167 -0.715805430
168 -2.339688732
169 -1.740016820
170  0.194800367
171  0.993655421
172 -1.491317551
173  0.705392470
174  0.929783889
175  0.465881934
176 -0.246598654
177  0.379734636
178  0.707608218
179  0.244384889
180 -0.177180533
181 -0.019467529
182  1.058091911
183 -0.142583161
184 -0.863901628
185  0.686257325
186  0.918665536
187 -0.451879143
188  0.009160055
189 -0.911020288
190 -0.539468379
191  0.183052245
192  0.803107907
193 -1.618569427
194 -2.455909720
195 -0.606051616
196  0.684313334
197 -1.637075745
198 -0.089590054
199 -0.483292338
200  0.652379610
> 
> 
> 
> cleanEx()
> nameEx("simDataDist")
> ### * simDataDist
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simDataDist
> ### Title: Create a data distribution object.
> ### Aliases: simDataDist
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(5, SimData, SimModel)
> #summary(Output)
> 
> 
> 
> cleanEx()
> nameEx("simEqualCon")
> ### * simEqualCon
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simEqualCon
> ### Title: Equality Constraint Object
> ### Aliases: simEqualCon
> 
> ### ** Examples
> 
> # Example 1: Single-group, one constraint
> constraint <- matrix(0, 3, 2)
> constraint[1,] <- c(1, 1)
> constraint[2,] <- c(2, 1)
> constraint[3,] <- c(3, 1)
> rownames(constraint) <- rep("LY", 3)
> equal.loading <- simEqualCon(constraint, modelType="SEM.exo")
> 
> # Example 2: Multiple-group, one constraint
> group.con <- matrix(0, 2, 3)
> group.con[1,] <- c(1, 2, 1)
> group.con[2,] <- c(2, 2, 1)
> rownames(group.con) <- rep("BE", 2)
> equal.path <- simEqualCon(group.con, modelType="Path")
> 
> # Example 3: Single-group, multiple constraints
> constraint1 <- matrix(1, 3, 2)
> constraint1[,1] <- 1:3
> rownames(constraint1) <- rep("LY", 3)
> constraint2 <- matrix(2, 3, 2)
> constraint2[,1] <- 4:6
> rownames(constraint2) <- rep("LY", 3)
> constraint3 <- matrix(3, 2, 2)
> constraint3[,1] <- 7:8
> rownames(constraint3) <- rep("LY", 2)
> equal.loading2 <- simEqualCon(constraint1, constraint2, constraint3, modelType="SEM")
> summary(equal.loading2)
CONSTRAINT OBJECT
Model Type
[1] "SEM"
-------------Constraint----------------
1.
   Group Row Column
LY    NA   1      1
LY    NA   2      1
LY    NA   3      1
---------------------------------------
2.
   Group Row Column
LY    NA   4      2
LY    NA   5      2
LY    NA   6      2
---------------------------------------
3.
   Group Row Column
LY    NA   7      3
LY    NA   8      3
---------------------------------------
> 
> 
> 
> cleanEx()
> nameEx("simExp")
> ### * simExp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simExp
> ### Title: Create random exponential distribution object
> ### Aliases: simExp
> 
> ### ** Examples
> 
>     exp2 <- simExp(2)
>     run(exp2)
[1] 0.3775909
> 	summary(exp2)
[1] "Random Exponential Distribution Object."
[1] "Rate parameter is 2."
> 
> 
> 
> cleanEx()
> nameEx("simF")
> ### * simF
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simF
> ### Title: Create random F distribution object
> ### Aliases: simF
> 
> ### ** Examples
> 
>     f27 <- simF(2, 7)
>     run(f27)
[1] 0.09450995
> 	summary(f27)
[1] "Random F Distribution Object."
[1] "Numerator degree of freedom is 2."
[1] "Denominator degree of freedom is 7."
[1] "Non-centrality parameter is 0."
> 
> 
> 
> cleanEx()
> nameEx("simFunction")
> ### * simFunction
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simFunction
> ### Title: Create function object
> ### Aliases: simFunction
> 
> ### ** Examples
> 
> 
> n65 <- simNorm(0.6, 0.05)
> u35 <- simUnif(0.3, 0.5)
> u68 <- simUnif(0.6, 0.8)
> u2 <- simUnif(-0.2, 0.2)
> n1 <- simNorm(0, 0.1)
> 
> loading <- matrix(0, 9, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 3] <- NA
> loading.start <- matrix("", 9, 3)
> loading.start[1:3, 1] <- 0.7
> loading.start[4:6, 2] <- 0.7
> loading.start[7:9, 3] <- "u68"
> LY <- simMatrix(loading, loading.start)
> 
> RTE <- symMatrix(diag(9))
> 
> factor.cor <- diag(3)
> factor.cor[1, 2] <- factor.cor[2, 1] <- NA
> RPS <- symMatrix(factor.cor, 0.5)
> 
> path <- matrix(0, 3, 3)
> path[3, 1:2] <- NA
> path.start <- matrix(0, 3, 3)
> path.start[3, 1] <- "n65"
> path.start[3, 2] <- "u35"
> BE <- simMatrix(path, path.start)
> 
> datGen <- simSetSEM(BE=BE, LY=LY, RPS=RPS, RTE=RTE)
> 
> loading.trivial <- matrix(NA, 9, 3)
> loading.trivial[is.na(loading)] <- 0
> LY.trivial <- simMatrix(loading.trivial, "u2")
> 
> error.cor.trivial <- matrix(NA, 9, 9)
> diag(error.cor.trivial) <- 0
> RTE.trivial <- symMatrix(error.cor.trivial, "n1")
> 
> misGen <- simMisspecSEM(LY = LY.trivial, RTE = RTE.trivial)
> 
> Data.Mis <- simData(datGen, 300, misspec=misGen)
> 
> loading <- matrix(0, 12, 4)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 4] <- NA
> loading[10:12, 3] <- NA
> 
> path <- matrix(0, 4, 4)
> path[4, 1:3] <- NA
> 
> analysis <- simParamSEM(BE=path, LY=loading)
> 
> Model <- simModel(analysis)
> 
> fun <- simFunction(indProd, var1=paste("y", 1:3, sep=""), var2=paste("y", 4:6, sep=""), namesProd=paste("y", 10:12, sep=""))
> 
> # Real simulation will need more than just 10 replications
> Output <- simResult(10, Data.Mis, Model, objFunction=fun)
Error in solve.default(E) : 
  system is computationally singular: reciprocal condition number = 2.80345e-26
Warning in estimateVCOV(lavaanModel, samplestats = lavaanSampleStats, options = lavaanOptions,  :
  lavaan WARNING: could not compute standard errors!

> summary(Output)
RESULT OBJECT
Model Type
[1] "SEM"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi    178.213  178.550  178.820  178.881
      AIC   9519.072 9634.792 9727.367 9748.197
      BIC   9674.631 9790.351 9882.926 9903.756
      RMSEA    0.095    0.095    0.095    0.095
      CFI      0.897    0.897    0.897    0.897
      TLI      0.859    0.858    0.858    0.858
      SRMR     0.065    0.065    0.066    0.066
========= Parameter Estimates and Standard Errors ============
        Estimate Average Estimate SD Average SE Power (Not equal 0) Std Est
LY1_1              0.674       0.136      0.056               1.000   0.677
LY2_1              0.771       0.144      0.055               1.000   0.766
LY3_1              0.601       0.122      0.056               1.000   0.613
LY4_2              0.728       0.226      0.056               1.000   0.718
LY5_2              0.718       0.185      0.055               1.000   0.719
LY6_2              0.638       0.185      0.056               1.000   0.634
LY10_3             0.573       0.187      0.118               1.000   0.538
LY11_3             0.627       0.233      0.108               1.000   0.575
LY12_3             0.494       0.203      0.089               1.000   0.481
LY7_4              0.291       0.117      0.076               0.889   0.762
LY8_4              0.293       0.173      0.063               0.889   0.700
LY9_4              0.278       0.163      0.072               0.889   0.683
BE4_1              2.298       2.483      4.082               0.889   0.606
BE4_2              1.688       1.803      2.818               0.778   0.413
BE4_3             -0.023       0.146      0.302               0.000  -0.001
PS2_1              0.496       0.122      0.058               1.000   0.496
PS3_1              0.068       0.162      0.084               0.333   0.068
PS3_2              0.097       0.137      0.079               0.556   0.097
TE1_1              0.516       0.164      0.055               1.000   0.529
TE2_2              0.402       0.226      0.051               0.889   0.395
TE3_3              0.588       0.155      0.056               1.000   0.611
TE4_4              0.451       0.318      0.062               0.667   0.446
TE5_5              0.453       0.279      0.058               0.889   0.451
TE6_6              0.571       0.233      0.057               1.000   0.569
TE7_7              0.395       0.264      0.043               0.889   0.394
TE8_8              0.471       0.239      0.049               0.889   0.484
TE9_9              0.500       0.255      0.050               1.000   0.504
TE10_10            0.773       0.217      0.156               0.889   0.689
TE11_11            0.723       0.235      0.140               0.889   0.637
TE12_12            0.753       0.171      0.097               1.000   0.738
TY1               -0.003       0.052      0.057               0.111  -0.002
TY2                0.037       0.049      0.058               0.111   0.037
TY3                0.008       0.057      0.057               0.000   0.009
TY4               -0.005       0.054      0.058               0.000  -0.004
TY5                0.009       0.071      0.058               0.111   0.010
TY6               -0.013       0.061      0.058               0.000  -0.013
TY7               -0.020       0.042      0.058               0.000  -0.021
TY8                0.023       0.057      0.057               0.000   0.024
TY9               -0.026       0.063      0.058               0.111  -0.026
TY10               0.000       0.000      0.061               0.000   0.000
TY11               0.000       0.000      0.062               0.000   0.000
TY12               0.000       0.000      0.059               0.000   0.000
        Std Est SD
LY1_1        0.121
LY2_1        0.145
LY3_1        0.122
LY4_2        0.210
LY5_2        0.189
LY6_2        0.180
LY10_3       0.155
LY11_3       0.191
LY12_3       0.186
LY7_4        0.172
LY8_4        0.170
LY9_4        0.181
BE4_1        0.099
BE4_2        0.181
BE4_3        0.049
PS2_1        0.122
PS3_1        0.162
PS3_2        0.137
TE1_1        0.176
TE2_2        0.226
TE3_3        0.152
TE4_4        0.306
TE5_5        0.273
TE6_6        0.241
TE7_7        0.257
TE8_8        0.251
TE9_9        0.255
TE10_10      0.173
TE11_11      0.227
TE12_12      0.180
TY1          0.051
TY2          0.049
TY3          0.058
TY4          0.054
TY5          0.070
TY6          0.061
TY7          0.043
TY8          0.057
TY9          0.063
TY10         0.000
TY11         0.000
TY12         0.000
========= Correlation between Fit Indices ============
         Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR
Chi    1.000 -0.588 -0.588  0.996 -0.666 -0.666  0.712
AIC   -0.588  1.000  1.000 -0.573 -0.117 -0.117 -0.419
BIC   -0.588  1.000  1.000 -0.573 -0.117 -0.117 -0.419
RMSEA  0.996 -0.573 -0.573  1.000 -0.676 -0.676  0.678
CFI   -0.666 -0.117 -0.117 -0.676  1.000  1.000 -0.354
TLI   -0.666 -0.117 -0.117 -0.676  1.000  1.000 -0.354
SRMR   0.712 -0.419 -0.419  0.678 -0.354 -0.354  1.000
================== Replications =====================
Number of Replications
[1] 10
Number of Converged Replications
[1] 9
NOTE: The data generation model is not the same as the analysis model. See the summary of the population underlying data generation by the summaryPopulation function.
> 
> 
> 
> cleanEx()
> nameEx("simGamma")
> ### * simGamma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simGamma
> ### Title: Create random gamma distribution object
> ### Aliases: simGamma
> 
> ### ** Examples
> 
>     g11 <- simGamma(1, 1)
>     run(g11)
[1] 0.1551414
> 	summary(g11)
[1] "Random Gamma Distribution Object."
[1] "Shape parameter (alpha) is 1."
[1] "Rate parameter (beta) is 1."
> 
> 
> 
> cleanEx()
> nameEx("simGeom")
> ### * simGeom
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simGeom
> ### Title: Create random geometric distribution object
> ### Aliases: simGeom
> 
> ### ** Examples
> 
>     geom5 <- simGeom(0.05)
>     run(geom5)
[1] 13
> 	summary(geom5)
[1] "Random Geometric Distribution Object."
[1] "Probability of successes is 0.05."
> 
> 
> 
> cleanEx()
> nameEx("simHyper")
> ### * simHyper
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simHyper
> ### Title: Create random hypergeometric distribution object
> ### Aliases: simHyper
> 
> ### ** Examples
> 
>     hyp <- simHyper(20, 5, 10)
>     run(hyp)
[1] 9
> 	summary(hyp)
[1] "Random Hypergeometric Distribution Object."
[1] "The number of successes is 20."
[1] "The number of failures is 5."
[1] "The number of drawns is 10."
> 
> 
> 
> cleanEx()
> nameEx("simLnorm")
> ### * simLnorm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simLnorm
> ### Title: Create random log normal distribution object
> ### Aliases: simLnorm
> 
> ### ** Examples
> 
>     lognorm <- simLnorm(0, exp(1))
>     run(lognorm)
[1] 0.1821585
> 	summary(lognorm)
[1] "Random Log Normal Distribution Object."
[1] "Mean in log scale is 0."
[1] "Standard deviation in log scale is 2.72."
> 
> 
> 
> cleanEx()
> nameEx("simLogis")
> ### * simLogis
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simLogis
> ### Title: Create random logistic distribution object
> ### Aliases: simLogis
> 
> ### ** Examples
> 
>     logis <- simLogis(0, 1)
>     run(logis)
[1] -1.017531
> 	summary(logis)
[1] "Random Logistic Distribution Object."
[1] "Location parameter is 0."
[1] "Scale parameter is 1."
> 
> 
> 
> cleanEx()
> nameEx("simMatrix")
> ### * simMatrix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simMatrix
> ### Title: Create simMatrix that save free parameters and starting values,
> ###   as well as fixed values
> ### Aliases: simMatrix
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]  [,2] 
[1,] "0.7" ""   
[2,] "0.7" ""   
[3,] "0.7" ""   
[4,] ""    "0.7"
[5,] ""    "0.7"
[6,] ""    "0.7"
> run(LX)
     [,1] [,2]
[1,]  0.7  0.0
[2,]  0.7  0.0
[3,]  0.7  0.0
[4,]  0.0  0.7
[5,]  0.0  0.7
[6,]  0.0  0.7
> 
> n65 <- simNorm(0.6, 0.05)
> LY <- simMatrix(loading, "n65")
> summary(LY)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]                  [,2]                 
[1,] "rnorm(1, 0.6, 0.05)" ""                   
[2,] "rnorm(1, 0.6, 0.05)" ""                   
[3,] "rnorm(1, 0.6, 0.05)" ""                   
[4,] ""                    "rnorm(1, 0.6, 0.05)"
[5,] ""                    "rnorm(1, 0.6, 0.05)"
[6,] ""                    "rnorm(1, 0.6, 0.05)"
> run(LY)
          [,1]      [,2]
[1,] 0.5686773 0.0000000
[2,] 0.6091822 0.0000000
[3,] 0.5582186 0.0000000
[4,] 0.0000000 0.6797640
[5,] 0.0000000 0.6164754
[6,] 0.0000000 0.5589766
> 
> start <- matrix(0, 6, 2)
> start[1:3, 1] <- 0.7
> start[4:6, 2] <- 0.7
> ST <- simMatrix(value=start)
> 
> 
> 
> cleanEx()
> nameEx("simMissing")
> ### * simMissing
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simMissing
> ### Title: Construct a SimMissing object to create data with missingness
> ###   and analyze missing data.
> ### Aliases: simMissing
> 
> ### ** Examples
> 
> 	#Example of imposing 10% MCAR missing in all variables with no imputations (FIML method)
> 	Missing <- simMissing(pmMCAR=0.1)
> 	summary(Missing)
MISSING OBJECT
The method of missing data handling: Maximum Likelihood 
Covariates (will not impose any missing values): none 
Proportion of MCAR: 0.1 
> 	
> 	loading <- matrix(0, 6, 1)
> 	loading[1:6, 1] <- NA
> 	LX <- simMatrix(loading, 0.7)
> 	RPH <- symMatrix(diag(1))
> 	RTD <- symMatrix(diag(6))
> 	CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> 	SimData <- simData(CFA.Model, 500)
> 	SimModel <- simModel(CFA.Model)
> 	
> 	#Create data
> 	dat <- run(SimData)
> 	
> 	#Impose missing
> 	dat <- run(Missing, dat)
> 	
> 	#Analyze data
> 	out <- run(SimModel, dat)
> 	summary(out)
MODEL ANALYSIS RESULT OBJECT
Fit Indices
            Chi              df          pvalue    baseline.Chi     baseline.df 
          4.992           9.000           0.835         848.384          15.000 
baseline.pvalue             CFI             TLI             AIC             BIC 
          0.000           1.000           1.008        6959.092        7034.955 
          RMSEA  RMSEA.ci.lower  RMSEA.ci.upper            SRMR 
          0.000           0.000           0.030           0.011 
========= Parameter Estimates and Standard Errors ============
      Estimate    SE      z     p       Std Est
LY1_1    0.722 0.044 16.505 0.000  7.247259e-01
LY2_1    0.685 0.045 15.331 0.000  6.818594e-01
LY3_1    0.726 0.048 15.206 0.000  6.882229e-01
LY4_1    0.688 0.047 14.772 0.000  6.680860e-01
LY5_1    0.747 0.047 15.755 0.000  7.064281e-01
LY6_1    0.632 0.044 14.222 0.000  6.472463e-01
TE1_1    0.471 0.041 11.583 0.000  4.747724e-01
TE2_2    0.540 0.044 12.347 0.000  5.350677e-01
TE3_3    0.586 0.048 12.144 0.000  5.263492e-01
TE4_4    0.588 0.047 12.418 0.000  5.536611e-01
TE5_5    0.560 0.048 11.729 0.000  5.009594e-01
TE6_6    0.554 0.043 12.815 0.000  5.810722e-01
TY1      0.000 0.046  0.000 1.000  2.148851e-05
TY2      0.023 0.046  0.490 0.624  2.260657e-02
TY3     -0.005 0.049 -0.100 0.920 -4.645960e-03
TY4      0.037 0.048  0.781 0.435  3.616270e-02
TY5      0.052 0.049  1.052 0.293  4.897779e-02
TY6      0.006 0.045  0.127 0.899  5.874597e-03
Converged
[1] TRUE
> 	
> 	#Example to create simMissing object for 3 forms design at 3 timepoints with 10 imputations
> 	Missing <- simMissing(nforms=3, timePoints=3, numImps=10)
> 
> 
> 
> 
> cleanEx()
> nameEx("simMisspecCFA")
> ### * simMisspecCFA
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simMisspecCFA
> ### Title: Set of model misspecification for CFA model.
> ### Aliases: simMisspecCFA
> 
> ### ** Examples
> 
> n01 <- simNorm(0, 0.1)
> error.cor.Mis <- matrix(NA, 6, 6)
> diag(error.cor.Mis) <- 1
> RTD.Mis <- symMatrix(error.cor.Mis, "n01")
> CFA.Model.Mis <- simMisspecCFA(RTD=RTD.Mis)
> 
> 
> 
> cleanEx()
> nameEx("simMisspecPath")
> ### * simMisspecPath
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simMisspecPath
> ### Title: Set of model misspecification for Path analysis model.
> ### Aliases: simMisspecPath
> 
> ### ** Examples
> 
> u1 <- simUnif(-0.1, 0.1)
> mis.path.GA <- matrix(0, 2, 2)
> mis.path.GA[2, 1:2] <- NA
> mis.GA <- simMatrix(mis.path.GA, "u1")
> Path.Mis.Model <- simMisspecPath(GA = mis.GA, exo=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("simMisspecSEM")
> ### * simMisspecSEM
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simMisspecSEM
> ### Title: Set of model misspecification for SEM model.
> ### Aliases: simMisspecSEM
> 
> ### ** Examples
> 
> u2 <- simUnif(-0.2, 0.2)
> n1 <- simNorm(0, 0.1)
> loading.X.trivial <- matrix(NA, 6, 2)
> loading.X.trivial[is.na(loading.X.trivial)] <- 0
> LX.trivial <- simMatrix(loading.X.trivial, "u2")
> error.cor.X.trivial <- matrix(NA, 6, 6)
> diag(error.cor.X.trivial) <- 0
> RTD.trivial <- symMatrix(error.cor.X.trivial, "n1")
> error.cor.Y.trivial <- matrix(NA, 2, 2)
> diag(error.cor.Y.trivial) <- 0
> RTE.trivial <- symMatrix(error.cor.Y.trivial, "n1")
> RTH.trivial <- simMatrix(matrix(NA, 6, 2), "n1")
> SEM.Mis.Model <- simMisspecSEM(LX = LX.trivial, RTE = RTE.trivial, RTD = RTD.trivial, RTH = RTH.trivial, exo=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("simModel")
> ### * simModel
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simModel
> ### Title: Create simModel from model specification and be ready for data
> ###   analysis.
> ### Aliases: simModel simModel-methods simModel,ANY-method
> ###   simModel,SimSet-method simModel,SimParam-method
> ###   simModel,SimModelOut-method
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> CFA.Model <- simSetCFA(LX = LX, RPH = RPH, RTD = RTD)
> SimModel <- simModel(CFA.Model)
> 
> library(lavaan)
> loading <- matrix(0, 9, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:9, 3] <- NA
> HS.Model <- simParamCFA(LX = loading)
> SimModel <- simModel(HS.Model, indLab=paste("x", 1:9, sep=""))
> out <- run(SimModel, HolzingerSwineford1939)
> summary(out)
MODEL ANALYSIS RESULT OBJECT
Fit Indices
            Chi              df          pvalue    baseline.Chi     baseline.df 
         85.306          24.000           0.000         918.852          36.000 
baseline.pvalue             CFI             TLI             AIC             BIC 
          0.000           0.931           0.896        7535.490        7646.703 
          RMSEA  RMSEA.ci.lower  RMSEA.ci.upper            SRMR 
          0.092           0.071           0.114           0.060 
========= Parameter Estimates and Standard Errors ============
      Estimate    SE      z p   Std Est
LY1_1    0.900 0.081 11.127 0 0.7718808
LY2_1    0.498 0.077  6.429 0 0.4235991
LY3_1    0.656 0.074  8.817 0 0.5811320
LY4_2    0.990 0.057 17.474 0 0.8515822
LY5_2    1.102 0.063 17.576 0 0.8550653
LY6_2    0.917 0.054 17.082 0 0.8380100
LY7_3    0.619 0.070  8.903 0 0.5695144
LY8_3    0.731 0.066 11.090 0 0.7230441
LY9_3    0.670 0.065 10.305 0 0.6650091
PS2_1    0.459 0.064  7.189 0 0.4585082
PS3_1    0.471 0.073  6.461 0 0.4705332
PS3_2    0.283 0.069  4.117 0 0.2829833
TE1_1    0.549 0.114  4.833 0 0.4042000
TE2_2    1.134 0.102 11.146 0 0.8205638
TE3_3    0.844 0.091  9.317 0 0.6622856
TE4_4    0.371 0.048  7.778 0 0.2748077
TE5_5    0.446 0.058  7.642 0 0.2688633
TE6_6    0.356 0.043  8.277 0 0.2977393
TE7_7    0.799 0.081  9.823 0 0.6756533
TE8_8    0.488 0.074  6.573 0 0.4772072
TE9_9    0.566 0.071  8.003 0 0.5577629
TY1      4.036 0.105 38.398 0 3.4630482
TY2      5.590 0.103 54.322 0 4.7555391
TY3      1.594 0.099 16.126 0 1.4119762
TY4      2.071 0.088 23.611 0 1.7821807
TY5      3.239 0.097 33.332 0 2.5140601
TY6      1.269 0.083 15.328 0 1.1601697
TY7      3.566 0.094 38.078 0 3.2788058
TY8      4.796 0.088 54.518 0 4.7442674
TY9      4.704 0.087 53.963 0 4.6692496
Converged
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("simNbinom")
> ### * simNbinom
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simNbinom
> ### Title: Create random negative binomial distribution object
> ### Aliases: simNbinom
> 
> ### ** Examples
> 
>     nbinom <- simNbinom(5, 0.25)
>     run(nbinom)
[1] 14
> 	summary(nbinom)
[1] "Random Negative Binomial Distribution Object."
[1] "The target number of successful trials is 5."
[1] "The probability of successes is 0.25."
> 
> 
> 
> cleanEx()
> nameEx("simNorm")
> ### * simNorm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simNorm
> ### Title: Create random normal distribution object
> ### Aliases: simNorm
> 
> ### ** Examples
> 
>     n02 <- simNorm(0, 0.2)
>     run(n02)
[1] -0.1252908
> 	summary(n02)
[1] "Random Normal Distribution Object."
[1] "Mean is 0."
[1] "Standard deviation is 0.2."
> 
> 
> 
> cleanEx()
> nameEx("simParamCFA")
> ### * simParamCFA
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simParamCFA
> ### Title: Create a set of matrices of parameters for analyzing data that
> ###   belongs to CFA model.
> ### Aliases: simParamCFA
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> CFA.Model <- simParamCFA(LX = loading)
> 
> 
> 
> cleanEx()
> nameEx("simParamPath")
> ### * simParamPath
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simParamPath
> ### Title: Create a set of matrices of parameters for analyzing data that
> ###   belongs to Path analysis model
> ### Aliases: simParamPath
> 
> ### ** Examples
>  
> path <- matrix(0, 4, 4)
> path[3, 1:2] <- NA
> path[4, 3] <- NA
> model <- simParamPath(BE=path)
> 
> exoPath <- matrix(NA, 3, 2)
> model2 <- simParamPath(GA=exoPath, exo=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("simParamSEM")
> ### * simParamSEM
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simParamSEM
> ### Title: Create a set of matrices of parameters for analyzing data that
> ###   belongs to SEM model
> ### Aliases: simParamSEM
> 
> ### ** Examples
> 
> loading <- matrix(0, 8, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:8, 3] <- NA
> path <- matrix(0, 3, 3)
> path[3, 1:2] <- NA
> SEM.model <- simParamSEM(BE=path, LY=loading)
> 
> loading.X <- matrix(0, 6, 2)
> loading.X[1:3, 1] <- NA
> loading.X[4:6, 2] <- NA
> loading.Y <- matrix(NA, 2, 1)
> path.GA <- matrix(NA, 1, 2)
> BE <- as.matrix(0)
> SEM.Exo.model <- simParamSEM(GA=path.GA, BE=BE, LX=loading.X, LY=loading.Y, exo=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("simPois")
> ### * simPois
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simPois
> ### Title: Create random Poisson distribution object
> ### Aliases: simPois
> 
> ### ** Examples
> 
>     pois5 <- simPois(5)
>     run(pois5)
[1] 4
> 	summary(pois5)
[1] "Random Poisson Distribution Object."
[1] "Lambda parameter (mean and variance) is 5."
> 
> 
> 
> cleanEx()
> nameEx("simResult")
> ### * simResult
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simResult
> ### Title: Create simResult.
> ### Aliases: simResult
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(5, SimData, SimModel)
> summary(Output)
RESULT OBJECT
Model Type
[1] "CFA"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi     11.899   12.033   12.139   12.164
      AIC   7514.252 7539.068 7558.920 7563.387
      BIC   7590.115 7614.931 7634.783 7639.249
      RMSEA    0.025    0.026    0.026    0.027
      CFI      0.997    0.997    0.997    0.997
      TLI      0.996    0.996    0.995    0.995
      SRMR     0.014    0.014    0.014    0.014
========= Parameter Estimates and Standard Errors ============
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0. Std.Est
LY1_1            0.706       0.026      0.042                 1.0   0.704
LY2_1            0.710       0.022      0.042                 1.0   0.701
LY3_1            0.710       0.038      0.042                 1.0   0.705
LY4_1            0.708       0.053      0.041                 1.0   0.718
LY5_1            0.687       0.044      0.042                 1.0   0.687
LY6_1            0.718       0.046      0.041                 1.0   0.724
TE1_1            0.508       0.036      0.038                 1.0   0.505
TE2_2            0.522       0.041      0.039                 1.0   0.508
TE3_3            0.509       0.046      0.039                 1.0   0.502
TE4_4            0.467       0.027      0.036                 1.0   0.484
TE5_5            0.526       0.065      0.039                 1.0   0.526
TE6_6            0.466       0.041      0.036                 1.0   0.475
TY1             -0.047       0.042      0.045                 0.2  -0.047
TY2             -0.024       0.057      0.045                 0.2  -0.023
TY3             -0.035       0.058      0.045                 0.2  -0.034
TY4             -0.012       0.069      0.044                 0.2  -0.012
TY5             -0.016       0.028      0.045                 0.0  -0.016
TY6             -0.011       0.024      0.044                 0.0  -0.011
      Std.Est.SD Average.Param Average.Bias Coverage
LY1_1      0.017          0.70        0.006      1.0
LY2_1      0.018          0.70        0.010      1.0
LY3_1      0.031          0.70        0.010      1.0
LY4_1      0.032          0.70        0.008      1.0
LY5_1      0.045          0.70       -0.013      1.0
LY6_1      0.034          0.70        0.018      1.0
TE1_1      0.024          0.51       -0.002      1.0
TE2_2      0.025          0.51        0.012      1.0
TE3_3      0.043          0.51       -0.001      1.0
TE4_4      0.046          0.51       -0.043      0.8
TE5_5      0.061          0.51        0.016      0.8
TE6_6      0.049          0.51       -0.044      0.8
TY1        0.043          0.00       -0.047      0.8
TY2        0.055          0.00       -0.024      0.8
TY3        0.058          0.00       -0.035      0.8
TY4        0.069          0.00       -0.012      0.8
TY5        0.027          0.00       -0.016      1.0
TY6        0.025          0.00       -0.011      1.0
========= Correlation between Fit Indices ============
         Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR
Chi    1.000 -0.023 -0.023  0.951 -0.946 -1.000  0.978
AIC   -0.023  1.000  1.000 -0.289  0.259  0.001  0.137
BIC   -0.023  1.000  1.000 -0.289  0.259  0.001  0.137
RMSEA  0.951 -0.289 -0.289  1.000 -0.994 -0.947  0.867
CFI   -0.946  0.259  0.259 -0.994  1.000  0.944 -0.862
TLI   -1.000  0.001  0.001 -0.947  0.944  1.000 -0.980
SRMR   0.978  0.137  0.137  0.867 -0.862 -0.980  1.000
================== Replications =====================
Number of Replications
[1] 5
Number of Converged Replications
[1] 5
> 
> # Specify Sample Size by n
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(NULL, SimData, SimModel, n=seq(50, 100, 10))
> summary(Output)
RESULT OBJECT
Model Type
[1] "CFA"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi     16.078   17.488   18.616   18.870
      AIC   1461.944 1503.136 1536.089 1543.504
      BIC   1507.889 1549.555 1582.887 1590.387
      RMSEA    0.097    0.111    0.123    0.125
      CFI      0.958    0.947    0.937    0.935
      TLI      0.931    0.911    0.896    0.892
      SRMR     0.055    0.058    0.060    0.060
========= Parameter Estimates and Standard Errors ============
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0. Std.Est
LY1_1            0.614       0.185      0.105               1.000   0.638
LY2_1            0.672       0.078      0.110               1.000   0.686
LY3_1            0.660       0.110      0.108               1.000   0.682
LY4_1            0.708       0.116      0.107               1.000   0.727
LY5_1            0.671       0.113      0.111               1.000   0.672
LY6_1            0.659       0.115      0.119               1.000   0.628
TE1_1            0.496       0.090      0.095               1.000   0.580
TE2_2            0.504       0.072      0.103               1.000   0.527
TE3_3            0.483       0.052      0.098               1.000   0.528
TE4_4            0.431       0.063      0.093               1.000   0.468
TE5_5            0.529       0.059      0.105               1.000   0.542
TE6_6            0.648       0.072      0.124               1.000   0.601
TY1             -0.085       0.177      0.110               0.167  -0.097
TY2             -0.018       0.184      0.115               0.167  -0.019
TY3             -0.052       0.171      0.113               0.167  -0.049
TY4             -0.015       0.131      0.114               0.000  -0.012
TY5             -0.006       0.062      0.116               0.000  -0.005
TY6             -0.017       0.203      0.122               0.167  -0.015
      Std.Est.SD Average.Param Average.Bias Coverage r_coef.n r_se.n
LY1_1      0.124          0.70       -0.086    0.833    0.539 -0.574
LY2_1      0.056          0.70       -0.028    1.000    0.123 -0.822
LY3_1      0.086          0.70       -0.040    1.000    0.828 -0.980
LY4_1      0.072          0.70        0.008    1.000   -0.045 -0.975
LY5_1      0.086          0.70       -0.029    1.000    0.655 -0.923
LY6_1      0.076          0.70       -0.041    1.000    0.583 -0.995
TE1_1      0.141          0.51       -0.014    0.833    0.314 -0.161
TE2_2      0.074          0.51       -0.006    1.000    0.747 -0.551
TE3_3      0.111          0.51       -0.027    1.000   -0.820 -0.940
TE4_4      0.109          0.51       -0.079    0.833    0.345 -0.868
TE5_5      0.106          0.51        0.019    1.000    0.155 -0.669
TE6_6      0.096          0.51        0.138    1.000    0.408 -0.889
TY1        0.181          0.00       -0.085    0.833    0.516 -0.252
TY2        0.194          0.00       -0.018    0.833   -0.067 -0.846
TY3        0.184          0.00       -0.052    0.833   -0.283 -0.971
TY4        0.129          0.00       -0.015    1.000    0.136 -0.880
TY5        0.062          0.00       -0.006    1.000   -0.174 -0.962
TY6        0.205          0.00       -0.017    0.833    0.209 -0.919
========= Correlation between Fit Indices ============
         Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR      n
Chi    1.000 -0.159 -0.159  0.990 -0.906 -0.975  0.672 -0.153
AIC   -0.159  1.000  1.000 -0.185  0.212  0.305 -0.678  0.999
BIC   -0.159  1.000  1.000 -0.185  0.212  0.305 -0.678  0.999
RMSEA  0.990 -0.185 -0.185  1.000 -0.939 -0.951  0.649 -0.184
CFI   -0.906  0.212  0.212 -0.939  1.000  0.883 -0.617  0.215
TLI   -0.975  0.305  0.305 -0.951  0.883  1.000 -0.780  0.294
SRMR   0.672 -0.678 -0.678  0.649 -0.617 -0.780  1.000 -0.665
n     -0.153  0.999  0.999 -0.184  0.215  0.294 -0.665  1.000
================== Replications =====================
Number of Replications
[1] 6
Number of Converged Replications
[1] 6
NOTE: The sample size is varying.
> 
> # Specify both sample size and percent missing completely at random
> Output <- simResult(NULL, SimData, SimModel, n=seq(50, 100, 10), pmMCAR=c(0, 0.1, 0.2))
> summary(Output)
RESULT OBJECT
Model Type
[1] "CFA"
========= Fit Indices Cutoffs ============
           Alpha
Fit Indices      0.1     0.05     0.01    0.001
      Chi     14.951   19.072   19.859   20.036
      AIC   1389.808 1433.308 1522.123 1542.107
      BIC   1435.374 1480.201 1569.017 1589.000
      RMSEA    0.085    0.124    0.125    0.125
      CFI      0.964    0.931    0.914    0.910
      TLI      0.940    0.885    0.856    0.850
      SRMR     0.061    0.064    0.067    0.068
========= Parameter Estimates and Standard Errors ============
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0. Std.Est
LY1_1            0.663       0.136      0.111               1.000   0.687
LY2_1            0.706       0.101      0.118               1.000   0.700
LY3_1            0.707       0.124      0.116               1.000   0.707
LY4_1            0.689       0.133      0.116               1.000   0.698
LY5_1            0.663       0.120      0.117               1.000   0.677
LY6_1            0.698       0.109      0.120               1.000   0.682
TE1_1            0.470       0.116      0.101               1.000   0.518
TE2_2            0.511       0.083      0.113               1.000   0.507
TE3_3            0.482       0.069      0.109               1.000   0.496
TE4_4            0.483       0.142      0.108               1.000   0.504
TE5_5            0.508       0.108      0.109               1.000   0.536
TE6_6            0.550       0.123      0.117               1.000   0.529
TY1             -0.022       0.157      0.116               0.056  -0.026
TY2              0.011       0.138      0.123               0.056   0.010
TY3             -0.005       0.120      0.122               0.056  -0.001
TY4             -0.045       0.130      0.121               0.056  -0.044
TY5             -0.002       0.127      0.119               0.000  -0.005
TY6             -0.010       0.128      0.124               0.056  -0.010
      Std.Est.SD Average.Param Average.Bias Coverage r_coef.n r_se.n
LY1_1      0.101          0.70       -0.037    0.944    0.419 -0.613
LY2_1      0.061          0.70        0.006    1.000   -0.380 -0.732
LY3_1      0.073          0.70        0.007    0.944    0.193 -0.640
LY4_1      0.095          0.70       -0.011    0.944   -0.082 -0.717
LY5_1      0.076          0.70       -0.037    0.944    0.589 -0.622
LY6_1      0.082          0.70       -0.002    1.000    0.385 -0.832
TE1_1      0.128          0.51       -0.040    0.833    0.301 -0.159
TE2_2      0.085          0.51        0.001    1.000    0.588 -0.424
TE3_3      0.099          0.51       -0.028    1.000    0.207 -0.490
TE4_4      0.133          0.51       -0.027    0.833   -0.028 -0.495
TE5_5      0.096          0.51       -0.002    1.000    0.237 -0.261
TE6_6      0.112          0.51        0.040    0.944    0.215 -0.438
TY1        0.165          0.00       -0.022    0.944    0.287 -0.508
TY2        0.139          0.00        0.011    0.944   -0.172 -0.809
TY3        0.126          0.00       -0.005    0.944   -0.097 -0.698
TY4        0.127          0.00       -0.045    0.944    0.078 -0.813
TY5        0.136          0.00       -0.002    1.000    0.163 -0.613
TY6        0.128          0.00       -0.010    0.944    0.352 -0.844
      r_coef.pmMCAR r_se.pmMCAR
LY1_1         0.158       0.378
LY2_1         0.280       0.421
LY3_1         0.121       0.520
LY4_1        -0.341       0.407
LY5_1        -0.070       0.276
LY6_1        -0.019       0.071
TE1_1        -0.106       0.345
TE2_2        -0.022       0.468
TE3_3         0.080       0.573
TE4_4         0.401       0.471
TE5_5        -0.350       0.029
TE6_6        -0.486      -0.173
TY1           0.072       0.318
TY2           0.017       0.339
TY3           0.227       0.382
TY4          -0.294       0.212
TY5          -0.059       0.029
TY6           0.043      -0.020
========= Correlation between Fit Indices ============
          Chi    AIC    BIC  RMSEA    CFI    TLI   SRMR      n pmMCAR
Chi     1.000  0.062  0.062  0.943 -0.880 -0.973  0.626  0.018 -0.035
AIC     0.062  1.000  1.000  0.118 -0.024 -0.042 -0.558  0.931 -0.346
BIC     0.062  1.000  1.000  0.117 -0.024 -0.042 -0.557  0.933 -0.341
RMSEA   0.943  0.118  0.117  1.000 -0.913 -0.905  0.488  0.019 -0.182
CFI    -0.880 -0.024 -0.024 -0.913  1.000  0.858 -0.538  0.010  0.009
TLI    -0.973 -0.042 -0.042 -0.905  0.858  1.000 -0.651  0.003  0.048
SRMR    0.626 -0.558 -0.557  0.488 -0.538 -0.651  1.000 -0.467  0.401
n       0.018  0.931  0.933  0.019  0.010  0.003 -0.467  1.000  0.000
pmMCAR -0.035 -0.346 -0.341 -0.182  0.009  0.048  0.401  0.000  1.000
================== Replications =====================
Number of Replications
[1] 18
Number of Converged Replications
[1] 18
NOTE: The sample size is varying.
NOTE: The percent of MCAR is varying.
> 
> # Use distribution object on sample size and percent completely at random
> n <- simUnif(100, 500)
> pmMCAR <- simUnif(0, 0.1)
> Output <- simResult(5, SimData, SimModel, n=n, pmMCAR=pmMCAR)
> 
> 
> 
> 
> cleanEx()
> nameEx("simResultParam")
> ### * simResultParam
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simResultParam
> ### Title: The constructor of the parameter result object
> ### Aliases: simResultParam
> 
> ### ** Examples
> 
> u35 <- simUnif(0.3, 0.5)
> u57 <- simUnif(0.5, 0.7)
> u1 <- simUnif(-0.1, 0.1)
> n31 <- simNorm(0.3, 0.1)
> 
> path.BE <- matrix(0, 4, 4)
> path.BE[3, 1:2] <- NA
> path.BE[4, 3] <- NA
> starting.BE <- matrix("", 4, 4)
> starting.BE[3, 1:2] <- "u35"
> starting.BE[4, 3] <- "u57"
> BE <- simMatrix(path.BE, starting.BE)
> 
> residual.error <- diag(4)
> residual.error[1,2] <- residual.error[2,1] <- NA
> RPS <- symMatrix(residual.error, "n31")
> 
> ME <- simVector(rep(NA, 4), 0)
> 
> Path.Model <- simSetPath(RPS = RPS, BE = BE, ME = ME)
> 
> mis.path.BE <- matrix(0, 4, 4)
> mis.path.BE[4, 1:2] <- NA
> mis.BE <- simMatrix(mis.path.BE, "u1")
> Path.Mis.Model <- simMisspecPath(BE = mis.BE, misfitType="rmsea")
> 
> # The number of replications in actual analysis should be much more than 5
> ParamObject <- simResultParam(5, Path.Model, Path.Mis.Model)
> 
> # Specify the range of misfits to select the set of misspecified parameters
> Path.Mis.Model2 <- simMisspecPath(BE = mis.BE, misfitType="rmsea", misfitBound=c(0.05, 0.08))
> ParamObject2 <- simResultParam(5, Path.Model, Path.Mis.Model2)
> 
> # Find the maximum misspecification for each actual parameter
> Path.Mis.Model3 <- simMisspecPath(BE = mis.BE, misfitType="rmsea", optMisfit="max", numIter=10)
> ParamObject3 <- simResultParam(5, Path.Model, Path.Mis.Model3)
> 
> 
> 
> cleanEx()
> nameEx("simSetCFA")
> ### * simSetCFA
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simSetCFA
> ### Title: Create a set of matrices of parameter and parameter values to
> ###   generate and analyze data that belongs to CFA model.
> ### Aliases: simSetCFA
> 
> ### ** Examples
> 
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> loadingValues[1:3, 1] <- 0.7
> loadingValues[4:6, 2] <- 0.7
> LX <- simMatrix(loading, loadingValues)
> summary(LX)
[1] "Random Full Matrix Object."
[1] "Free/Fixed Parameters:"
     [,1] [,2]
[1,]   NA    0
[2,]   NA    0
[3,]   NA    0
[4,]    0   NA
[5,]    0   NA
[6,]    0   NA
[1] "Parameter/Starting Values:"
     [,1]  [,2] 
[1,] "0.7" ""   
[2,] "0.7" ""   
[3,] "0.7" ""   
[4,] ""    "0.7"
[5,] ""    "0.7"
[6,] ""    "0.7"
> 
> latent.cor <- matrix(NA, 2, 2)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> 
> error.cor <- matrix(0, 6, 6)
> diag(error.cor) <- 1
> RTD <- symMatrix(error.cor)
> 
> CFA.Model <- simSetCFA(LX = LX, RPH = RPH, RTD = RTD)
> 
> 
> 
> cleanEx()
> nameEx("simSetPath")
> ### * simSetPath
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simSetPath
> ### Title: Create a set of matrices of parameter and parameter values to
> ###   generate and analyze data that belongs to Path analysis model
> ### Aliases: simSetPath
> 
> ### ** Examples
>  
> u35 <- simUnif(0.3, 0.5)
> u57 <- simUnif(0.5, 0.7)
> u1 <- simUnif(-0.1, 0.1)
> n31 <- simNorm(0.3, 0.1)
> 
> path.BE <- matrix(0, 4, 4)
> path.BE[3, 1:2] <- NA
> path.BE[4, 3] <- NA
> starting.BE <- matrix("", 4, 4)
> starting.BE[3, 1:2] <- "u35"
> starting.BE[4, 3] <- "u57"
> BE <- simMatrix(path.BE, starting.BE)
> 
> residual.error <- diag(4)
> residual.error[1,2] <- residual.error[2,1] <- NA
> RPS <- symMatrix(residual.error, "n31")
> 
> Path.Model <- simSetPath(RPS = RPS, BE = BE)
> 
> u35 <- simUnif(0.3, 0.5)
> u57 <- simUnif(0.5, 0.7)
> u1 <- simUnif(-0.1, 0.1)
> n31 <- simNorm(0.3, 0.1)
> 
> path.GA <- matrix(0, 2, 2)
> path.GA[1, 1:2] <- NA
> GA <- simMatrix(path.GA, "u35")
> 
> path.BE <- matrix(0, 2, 2)
> path.BE[2, 1] <- NA
> BE <- simMatrix(path.BE, "u57")
> 
> exo.cor <- matrix(NA, 2, 2)
> diag(exo.cor) <- 1
> RPH <- symMatrix(exo.cor, "n31")
> 
> RPS <- symMatrix(diag(2))
> 
> Path.Exo.Model <- simSetPath(RPS = RPS, BE = BE, RPH = RPH, GA = GA, exo=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("simSetSEM")
> ### * simSetSEM
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simSetSEM
> ### Title: Create a set of matrices of parameter and parameter values to
> ###   generate and analyze data that belongs to SEM model
> ### Aliases: simSetSEM
> 
> ### ** Examples
> 
> u35 <- simUnif(0.3, 0.5)
> u68 <- simUnif(0.6, 0.8)
> n65 <- simNorm(0.6, 0.05)
> loading <- matrix(0, 8, 3)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loading[7:8, 3] <- NA
> loading.start <- matrix("", 8, 3)
> loading.start[1:3, 1] <- 0.7
> loading.start[4:6, 2] <- 0.7
> loading.start[7:8, 3] <- "u68"
> LY <- simMatrix(loading, loading.start)
> 
> RTE <- symMatrix(diag(8))
> 
> factor.cor <- diag(3)
> factor.cor[1, 2] <- factor.cor[2, 1] <- NA
> RPS <- symMatrix(factor.cor, 0.5)
> 
> path <- matrix(0, 3, 3)
> path[3, 1:2] <- NA
> path.start <- matrix(0, 3, 3)
> path.start[3, 1] <- "n65"
> path.start[3, 2] <- "u35"
> BE <- simMatrix(path, path.start)
> 
> SEM.model <- simSetSEM(BE=BE, LY=LY, RPS=RPS, RTE=RTE)
> 
> loading.X <- matrix(0, 6, 2)
> loading.X[1:3, 1] <- NA
> loading.X[4:6, 2] <- NA
> LX <- simMatrix(loading.X, 0.7)
> 
> loading.Y <- matrix(NA, 2, 1)
> LY <- simMatrix(loading.Y, "u68")
> 
> RTD <- symMatrix(diag(6))
> 
> RTE <- symMatrix(diag(2))
> 
> factor.K.cor <- matrix(NA, 2, 2)
> diag(factor.K.cor) <- 1
> RPH <- symMatrix(factor.K.cor, 0.5)
> 
> RPS <- symMatrix(as.matrix(1))
> 
> path.GA <- matrix(NA, 1, 2)
> path.GA.start <- matrix(c("n65", "u35"), ncol=2)
> GA <- simMatrix(path.GA, path.GA.start)
> 
> BE <- simMatrix(as.matrix(0))
> 
> SEM.Exo.model <- simSetSEM(GA=GA, BE=BE, LX=LX, LY=LY, RPH=RPH, RPS=RPS, RTD=RTD, RTE=RTE, exo=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("simT")
> ### * simT
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simT
> ### Title: Create random t distribution object
> ### Aliases: simT
> 
> ### ** Examples
> 
>     nct82 <- simT(8, ncp=2)
>     run(nct82)
[1] 1.399685
> 	summary(nct82)
[1] "Random t Distribution Object."
[1] "Degree of freedom is 8."
[1] "Non-centrality parameter is 2."
> 
> 
> 
> cleanEx()
> nameEx("simUnif")
> ### * simUnif
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simUnif
> ### Title: Create random uniform distribution object
> ### Aliases: simUnif
> 
> ### ** Examples
> 
> u1 <- simUnif(-0.1, 0.1)
> run(u1)
[1] -0.04689827
> summary(u1)
[1] "Random Uniform Distribution Object."
[1] "Minimum is -0.1."
[1] "Maximum is 0.1."
> 
> 
> 
> cleanEx()
> nameEx("simVector")
> ### * simVector
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simVector
> ### Title: Create simVector that save free parameters and starting values,
> ###   as well as fixed values
> ### Aliases: simVector
> 
> ### ** Examples
> 
> factor.mean <- rep(NA, 4)
> AL <- simVector(factor.mean, 0)
> 
> n02 <- simNorm(0, 0.2)
> factor.start <- rep("n02", 4)
> KA <- simVector(factor.mean, factor.start)
> 
> start <- c(2, 0, 0, 1)
> VE <- simVector(value=start)
> 
> 
> 
> cleanEx()
> nameEx("simWeibull")
> ### * simWeibull
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simWeibull
> ### Title: Create random Weibull distribution object
> ### Aliases: simWeibull
> 
> ### ** Examples
> 
>     exWeibull <- simWeibull(2, 100)
>     run(exWeibull)
[1] 115.1568
> 	summary(exWeibull)
[1] "Random Weibull Distribution Object."
[1] "Shape parameter is 2."
[1] "Scale parameter is 100."
> 
> 
> 
> cleanEx()
> nameEx("skew")
> ### * skew
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: skew
> ### Title: Finding skewness
> ### Aliases: skew skew-methods skew,vector-method
> 
> ### ** Examples
> 
> skew(1:5)
skew (g1)        se         z         p 
 0.000000  1.095445  0.000000  1.000000 
> 
> 
> 
> cleanEx()
> nameEx("standardize")
> ### * standardize
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: standardize
> ### Title: Standardize the parameter estimates within an object
> ### Aliases: standardize standardize-methods standardize,ANY-method
> ###   standardize,SimModelOut-method standardize,SimRSet-method
> 
> ### ** Examples
> 
> # This function is not public.
> 
> # loading <- matrix(0, 6, 2)
> # loading[1:3, 1] <- NA
> # loading[4:6, 2] <- NA
> # loadingValues <- matrix(0, 6, 2)
> # loadingValues[1:3, 1] <- 0.7
> # loadingValues[4:6, 2] <- 0.7
> # LX <- simMatrix(loading, loadingValues)
> # summary(LX)
> # latent.cor <- matrix(NA, 2, 2)
> # diag(latent.cor) <- 1
> # PH <- symMatrix(latent.cor, 0.5)
> # error.cor <- matrix(0, 6, 6)
> # diag(error.cor) <- 1
> # TD <- symMatrix(error.cor)
> # CFA.Model <- simSetCFA(LX = LX, PH = PH, TD = TD)
> # SimData <- simData(CFA.Model, 200)
> # SimModel <- simModel(CFA.Model)
> # standardize(run(SimModel, run(SimData)))
> 
> # loading <- matrix(0, 6, 2)
> # loading[1:3, 1] <- NA
> # loading[4:6, 2] <- NA
> # loadingValues <- matrix(0, 6, 2)
> # loadingValues[1:3, 1] <- 0.7
> # loadingValues[4:6, 2] <- 0.7
> # LX <- simMatrix(loading, loadingValues)
> # summary(LX)
> # latent.cor <- matrix(NA, 2, 2)
> # diag(latent.cor) <- 1
> # PH <- symMatrix(latent.cor, 0.5)
> # error.cor <- matrix(0, 6, 6)
> # diag(error.cor) <- 1
> # TD <- symMatrix(error.cor)
> # CFA.Model <- simSetCFA(LX = LX, PH = PH, TD = TD)
> # set <- reduceMatrices(run(CFA.Model))
> 
> 
> 
> cleanEx()
> nameEx("startingValues")
> ### * startingValues
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: startingValues
> ### Title: Find starting values by averaging random numbers
> ### Aliases: startingValues startingValues-methods
> ###   startingValues,ANY-method startingValues,SimMatrix-method
> ###   startingValues,SimVector-method startingValues,SimSet-method
> 
> ### ** Examples
> 
> # This function is not public
> 
> #u89 <- simUnif(0.8, 0.9)
> #loading <- matrix(0, 6, 2)
> #loading[1:3, 1] <- NA
> #loading[4:6, 2] <- NA
> #loadingValues <- matrix(0, 6, 2)
> #LX <- simMatrix(loading, "u89")
> #startingValues(LX, 10)
> 
> #u89 <- simUnif(0.8, 0.9)
> #loading <- matrix(0, 6, 2)
> #loading[1:3, 1] <- NA
> #loading[4:6, 2] <- NA
> #loadingValues <- matrix(0, 6, 2)
> #LX <- simMatrix(loading, "u89")
> #latent.cor <- matrix(NA, 2, 2)
> #diag(latent.cor) <- 1
> #PH <- symMatrix(latent.cor, 0.5)
> #error.cor <- matrix(0, 6, 6)
> #diag(error.cor) <- 1
> #TD <- symMatrix(error.cor)
> #CFA.Model <- simSetCFA(LX = LX, PH = PH, TD = TD)
> #result <- startingValues(CFA.Model, 10)
> #summary(result)
> 
> 
> 
> cleanEx()
> nameEx("subtractObject")
> ### * subtractObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: subtractObject
> ### Title: Make a subtraction of each element in an object
> ### Aliases: subtractObject subtractObject-methods
> ###   subtractObject,ANY,ANY-method subtractObject,SimRSet,SimRSet-method
> 
> ### ** Examples
> 
> # This function is not public
> 
> #u89 <- simUnif(0.8, 0.9)
> #loading <- matrix(0, 6, 2)
> #loading[1:3, 1] <- NA
> #loading[4:6, 2] <- NA
> #loadingValues <- matrix(0, 6, 2)
> #LX <- simMatrix(loading, "u89")
> #startingValues(LX, 10)
> 
> #u89 <- simUnif(0.8, 0.9)
> #loading <- matrix(0, 6, 2)
> #loading[1:3, 1] <- NA
> #loading[4:6, 2] <- NA
> #loadingValues <- matrix(0, 6, 2)
> #LX <- simMatrix(loading, "u89")
> #latent.cor <- matrix(NA, 2, 2)
> #diag(latent.cor) <- 1
> #PH <- symMatrix(latent.cor, 0.5)
> #error.cor <- matrix(0, 6, 6)
> #diag(error.cor) <- 1
> #TD <- symMatrix(error.cor)
> #CFA.Model <- simSetCFA(LX = LX, PH = PH, TD = TD)
> #result <- startingValues(CFA.Model, 10)
> #summary(result)
> 
> 
> 
> cleanEx()
> nameEx("summaryParam")
> ### * summaryParam
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summaryParam
> ### Title: Provide summary of parameter estimates and standard error across
> ###   replications
> ### Aliases: summaryParam summaryParam-methods summaryParam,ANY-method
> ###   summaryParam,SimResult-method summaryParam,SimModelOut-method
> ###   summaryParam,SimModelMIOut-method
> 
> ### ** Examples
> 
> showClass("SimResult")
Class "SimResult" [package "simsem"]

Slots:
                                                                        
Name:   modelType       nRep       coef         se        fit  converged
Class:  character    numeric data.frame data.frame data.frame     vector
                                                                        
Name:  paramValue       FMI1       FMI2    stdCoef       seed          n
Class: data.frame data.frame data.frame data.frame    numeric     vector
                            
Name:      pmMCAR      pmMAR
Class:     vector     vector
> loading <- matrix(0, 6, 1)
> loading[1:6, 1] <- NA
> LX <- simMatrix(loading, 0.7)
> RPH <- symMatrix(diag(1))
> RTD <- symMatrix(diag(6))
> CFA.Model <- simSetCFA(LY = LX, RPS = RPH, RTE = RTD)
> SimData <- simData(CFA.Model, 500)
> SimModel <- simModel(CFA.Model)
> # We make the examples running only 5 replications to save time.
> # In reality, more replications are needed.
> Output <- simResult(5, SimData, SimModel)
> summaryParam(Output)
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0.     Std.Est
LY1_1       0.70617392  0.02632084 0.04170003                 1.0  0.70369655
LY2_1       0.70950261  0.02202627 0.04212368                 1.0  0.70095240
LY3_1       0.71040091  0.03764679 0.04182034                 1.0  0.70527823
LY4_1       0.70795573  0.05322649 0.04062185                 1.0  0.71810121
LY5_1       0.68697684  0.04421547 0.04183965                 1.0  0.68738618
LY6_1       0.71756184  0.04565351 0.04076849                 1.0  0.72383557
TE1_1       0.50835147  0.03611067 0.03847747                 1.0  0.50457420
TE2_2       0.52155750  0.04075516 0.03934573                 1.0  0.50841134
TE3_3       0.50892906  0.04558754 0.03869509                 1.0  0.50183172
TE4_4       0.46742701  0.02669592 0.03607111                 1.0  0.48351273
TE5_5       0.52571869  0.06464558 0.03922000                 1.0  0.52588737
TE6_6       0.46572295  0.04058423 0.03621606                 1.0  0.47512288
TY1        -0.04717826  0.04197696 0.04487778                 0.2 -0.04730833
TY2        -0.02411250  0.05686125 0.04527260                 0.2 -0.02290608
TY3        -0.03457255  0.05763459 0.04504030                 0.2 -0.03433061
TY4        -0.01165663  0.06935717 0.04404377                 0.2 -0.01214792
TY5        -0.01591134  0.02757372 0.04470062                 0.0 -0.01572420
TY6        -0.01083889  0.02438384 0.04431291                 0.0 -0.01133479
      Std.Est.SD Average.Param Average.Bias Coverage
LY1_1 0.01721093          0.70  0.006173922      1.0
LY2_1 0.01783240          0.70  0.009502606      1.0
LY3_1 0.03063711          0.70  0.010400910      1.0
LY4_1 0.03197510          0.70  0.007955725      1.0
LY5_1 0.04490084          0.70 -0.013023164      1.0
LY6_1 0.03426359          0.70  0.017561844      1.0
TE1_1 0.02433406          0.51 -0.001648534      1.0
TE2_2 0.02527818          0.51  0.011557500      1.0
TE3_3 0.04268899          0.51 -0.001070943      1.0
TE4_4 0.04579649          0.51 -0.042572991      0.8
TE5_5 0.06064147          0.51  0.015718693      0.8
TE6_6 0.04881015          0.51 -0.044277049      0.8
TY1   0.04322582          0.00 -0.047178260      0.8
TY2   0.05500702          0.00 -0.024112496      0.8
TY3   0.05755595          0.00 -0.034572554      0.8
TY4   0.06923763          0.00 -0.011656635      0.8
TY5   0.02711972          0.00 -0.015911335      1.0
TY6   0.02493686          0.00 -0.010838890      1.0
> summaryParam(Output, detail=TRUE)
      Estimate.Average Estimate.SD Average.SE Power..Not.equal.0.     Std.Est
LY1_1       0.70617392  0.02632084 0.04170003                 1.0  0.70369655
LY2_1       0.70950261  0.02202627 0.04212368                 1.0  0.70095240
LY3_1       0.71040091  0.03764679 0.04182034                 1.0  0.70527823
LY4_1       0.70795573  0.05322649 0.04062185                 1.0  0.71810121
LY5_1       0.68697684  0.04421547 0.04183965                 1.0  0.68738618
LY6_1       0.71756184  0.04565351 0.04076849                 1.0  0.72383557
TE1_1       0.50835147  0.03611067 0.03847747                 1.0  0.50457420
TE2_2       0.52155750  0.04075516 0.03934573                 1.0  0.50841134
TE3_3       0.50892906  0.04558754 0.03869509                 1.0  0.50183172
TE4_4       0.46742701  0.02669592 0.03607111                 1.0  0.48351273
TE5_5       0.52571869  0.06464558 0.03922000                 1.0  0.52588737
TE6_6       0.46572295  0.04058423 0.03621606                 1.0  0.47512288
TY1        -0.04717826  0.04197696 0.04487778                 0.2 -0.04730833
TY2        -0.02411250  0.05686125 0.04527260                 0.2 -0.02290608
TY3        -0.03457255  0.05763459 0.04504030                 0.2 -0.03433061
TY4        -0.01165663  0.06935717 0.04404377                 0.2 -0.01214792
TY5        -0.01591134  0.02757372 0.04470062                 0.0 -0.01572420
TY6        -0.01083889  0.02438384 0.04431291                 0.0 -0.01133479
      Std.Est.SD Average.Param Average.Bias Coverage     Rel.Bias    Std.Bias
LY1_1 0.01721093          0.70  0.006173922      1.0  0.008819889  0.23456401
LY2_1 0.01783240          0.70  0.009502606      1.0  0.013575151  0.43142149
LY3_1 0.03063711          0.70  0.010400910      1.0  0.014858443  0.27627612
LY4_1 0.03197510          0.70  0.007955725      1.0  0.011365322  0.14946927
LY5_1 0.04490084          0.70 -0.013023164      1.0 -0.018604520 -0.29453865
LY6_1 0.03426359          0.70  0.017561844      1.0  0.025088348  0.38467678
TE1_1 0.02433406          0.51 -0.001648534      1.0 -0.003232420 -0.04565227
TE2_2 0.02527818          0.51  0.011557500      1.0  0.022661764  0.28358371
TE3_3 0.04268899          0.51 -0.001070943      1.0 -0.002099888 -0.02349201
TE4_4 0.04579649          0.51 -0.042572991      0.8 -0.083476453 -1.59473773
TE5_5 0.06064147          0.51  0.015718693      0.8  0.030820967  0.24315187
TE6_6 0.04881015          0.51 -0.044277049      0.8 -0.086817743 -1.09099137
TY1   0.04322582          0.00 -0.047178260      0.8         -Inf -1.12390842
TY2   0.05500702          0.00 -0.024112496      0.8           NA -0.42405849
TY3   0.05755595          0.00 -0.034572554      0.8           NA -0.59985776
TY4   0.06923763          0.00 -0.011656635      0.8           NA -0.16806675
TY5   0.02711972          0.00 -0.015911335      1.0           NA -0.57704712
TY6   0.02493686          0.00 -0.010838890      1.0           NA -0.44451120
      Rel.SE.Bias
LY1_1  0.58429697
LY2_1  0.91242903
LY3_1  0.11086071
LY4_1 -0.23681152
LY5_1 -0.05373273
LY6_1 -0.10700201
TE1_1  0.06554279
TE2_2 -0.03458287
TE3_3 -0.15119152
TE4_4  0.35118448
TE5_5 -0.39330732
TE6_6 -0.10763229
TY1    0.06910508
TY2   -0.20380581
TY3   -0.21851963
TY4   -0.36497166
TY5    0.62113145
TY6    0.81730627
> 
> 
> 
> cleanEx()
> nameEx("summaryPopulation")
> ### * summaryPopulation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summaryPopulation
> ### Title: Summarize the data generation population model underlying an
> ###   object
> ### Aliases: summaryPopulation summaryPopulation-methods
> ###   summaryPopulation,ANY-method
> 
> ### ** Examples
> 
> # See each class for an example.
> 
> 
> 
> cleanEx()
> nameEx("summaryShort")
> ### * summaryShort
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summaryShort
> ### Title: Provide short summary of an object.
> ### Aliases: summaryShort summaryShort-methods summaryShort,ANY-method
> ###   summaryShort,vector-method summaryShort,matrix-method
> 
> ### ** Examples
> 
> u89 <- simUnif(0.8, 0.9)
> loading <- matrix(0, 6, 2)
> loading[1:3, 1] <- NA
> loading[4:6, 2] <- NA
> loadingValues <- matrix(0, 6, 2)
> LX <- simMatrix(loading, "u89")
> summaryShort(LX)
     [,1]                    [,2]                   
[1,] "NA:runif(1, 0.8, 0.9)" "0"                    
[2,] "NA:runif(1, 0.8, 0.9)" "0"                    
[3,] "NA:runif(1, 0.8, 0.9)" "0"                    
[4,] "0"                     "NA:runif(1, 0.8, 0.9)"
[5,] "0"                     "NA:runif(1, 0.8, 0.9)"
[6,] "0"                     "NA:runif(1, 0.8, 0.9)"
> 
> 
> 
> cleanEx()
> nameEx("symMatrix")
> ### * symMatrix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: symMatrix
> ### Title: Create symmetric simMatrix that save free parameters and
> ###   starting values, as well as fixed values
> ### Aliases: symMatrix
> 
> ### ** Examples
> 
> latent.cor <- matrix(NA, 3, 3)
> diag(latent.cor) <- 1
> RPH <- symMatrix(latent.cor, 0.5)
> 
> u46 <- simUnif(0.4, 0.6)
> factor.cor <- matrix(NA, 4, 4)
> diag(factor.cor) <- 1
> factor.cor.start <- matrix("u46", 4, 4)
> factor.cor.start[1, 2] <- factor.cor.start[2, 1] <- "0.5"
> RPS <- symMatrix(factor.cor, factor.cor.start)
> 
> start <- diag(4)
> start[1, 2] <- 0.5
> start[2, 1] <- 0.5
> ST <- symMatrix(value=start)
> 
> 
> 
> cleanEx()
> nameEx("tagHeaders")
> ### * tagHeaders
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tagHeaders
> ### Title: Tag names to each element
> ### Aliases: tagHeaders tagHeaders-methods tagHeaders,ANY-method
> ###   tagHeaders,VirtualRSet-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("toFunction")
> ### * toFunction
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: toFunction
> ### Title: Export the distribution object to a function command in text
> ###   that can be evaluated directly.
> ### Aliases: toFunction toFunction-methods toFunction,ANY-method
> 
> ### ** Examples
> 
> u2 <- simUnif(-0.2, 0.2)
> toFunction(u2)
[1] "runif(1, -0.2, 0.2)"
> 
> 
> 
> cleanEx()
> nameEx("toSimSet")
> ### * toSimSet
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: toSimSet
> ### Title: Transform the analysis model object into the object for data
> ###   generation
> ### Aliases: toSimSet toSimSet-methods toSimSet,ANY-method
> ###   toSimSet,SimRSet-method toSimSet,SimModelOut-method
> 
> ### ** Examples
> 
> # This function is not public.
> 
> # library(lavaan)
> # hs <- HolzingerSwineford1939
> # loading <- matrix(0, 9, 3)
> # loading[1:3, 1] <- NA
> # loading[4:6, 2] <- NA
> # loading[7:9, 3] <- NA
> # model <- simParamCFA(LY=loading)
> # SimModel <- simModel(model, indLab=paste("x", 1:9, sep=""))
> # out <- run(SimModel, hs)
> # set <- toSimSet(out)
> 
> 
> 
> cleanEx()
> nameEx("validateCovariance")
> ### * validateCovariance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: validateCovariance
> ### Title: Validate whether all elements provides a good covariance matrix
> ### Aliases: validateCovariance
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("validateObject")
> ### * validateObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: validateObject
> ### Title: Validate whether the drawn parameters are good.
> ### Aliases: validateObject
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("validatePath")
> ### * validatePath
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: validatePath
> ### Title: Validate whether the regression coefficient (or loading) matrix
> ###   is good
> ### Aliases: validatePath
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("vectorizeObject")
> ### * vectorizeObject
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: vectorizeObject
> ### Title: Change an object to a vector with labels
> ### Aliases: vectorizeObject vectorizeObject-methods
> ###   vectorizeObject,ANY,ANY-method vectorizeObject,vector,vector-method
> ###   vectorizeObject,matrix,matrix-method
> ###   vectorizeObject,VirtualRSet,SimLabels-method
> ###   vectorizeObject,MatrixSet,SimGenLabels-method
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("weightedMean")
> ### * weightedMean
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: weightedMean
> ### Title: Calculate the weighted mean of a variable
> ### Aliases: weightedMean
> 
> ### ** Examples
> 
> # This function is not public
> 
> # weightedMean(1:5, c(1,1,1,1,2))
> 
> 
> 
> cleanEx()
> nameEx("writeLavaanCode")
> ### * writeLavaanCode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: writeLavaanCode
> ### Title: Write a lavaan code given the matrices of free parameter
> ### Aliases: writeLavaanCode
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("writeLavaanConstraint")
> ### * writeLavaanConstraint
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: writeLavaanConstraint
> ### Title: Write a lavaan code for a given set of equality constraints
> ### Aliases: writeLavaanConstraint
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("writeLavaanIndividualConstraint")
> ### * writeLavaanIndividualConstraint
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: writeLavaanIndividualConstraint
> ### Title: Write a lavaan code for a given equality constraint for each
> ###   parameter
> ### Aliases: writeLavaanIndividualConstraint
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> cleanEx()
> nameEx("writeLavaanNullCode")
> ### * writeLavaanNullCode
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: writeLavaanNullCode
> ### Title: Write a lavaan code for a null model
> ### Aliases: writeLavaanNullCode
> 
> ### ** Examples
> 
> # No example
> 
> 
> 
> ### * <FOOTER>
> ###
> cat("Time elapsed: ", proc.time() - get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  68.95 0.38 69.47 NA NA 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
